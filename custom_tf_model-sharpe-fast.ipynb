{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lesbian-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "incorporated-anxiety",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41f459b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, models, optimizers\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv2D, Flatten, Dense, LSTM, ConvLSTM2D, MaxPool2D, Dropout, Conv1D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "offensive-merchant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dae60f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86f4cad1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'inputs_train.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_64252/3869279746.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minputs_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"inputs_train.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0minputs_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"inputs_test.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'inputs_train.npy'"
     ]
    }
   ],
   "source": [
    "inputs_train = np.load(\"inputs_train.npy\")\n",
    "inputs_test = np.load(\"inputs_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = np.transpose(inputs_train, (0, 2,3,1))\n",
    "inputs_test = np.transpose(inputs_test, (0, 2,3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = inputs_train.reshape(inputs_train.shape[:2] + (inputs_train.shape[2]*inputs_train.shape[3],))\n",
    "inputs_test = inputs_test.reshape(inputs_test.shape[:2] + (inputs_test.shape[2]*inputs_test.shape[3],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6052538",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_timeframes.csv').iloc[59:]\n",
    "test = pd.read_csv('test_timeframes.csv').iloc[59:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = [train, test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9326d1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = inputs_train[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b9f610",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train.shape, train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e56c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "batch_size = 32\n",
    "stop_limit = 0.004\n",
    "price_limit = 0.004\n",
    "margin_size = 50\n",
    "time_limit = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hungry-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "# model.add(LSTM(64, input_shape = img.shape, return_sequences=True, dropout=0.2))\n",
    "model.add(LSTM(32, input_shape = img.shape, dropout=0.5))\n",
    "# model.add(LSTM(32, dropout=0.2))\n",
    "model.add(Dense(3, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "protective-medium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.Sequential()\n",
    "\n",
    "# model.add(Conv2D(32, (5, 1),padding ='Same', activation='relu', input_shape = img.shape))\n",
    "# model.add(Conv2D(32, (5, 1),padding = 'Same', activation ='relu'))\n",
    "# model.add(MaxPool2D((2, 1)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(64,(3, 1),padding = 'Same', activation ='relu'))\n",
    "# model.add(Conv2D(64, (3, 1),padding = 'Same', activation ='relu'))\n",
    "# model.add(MaxPool2D(pool_size=(2, 1), strides=(2, 1)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256, activation = \"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(3, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "broken-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model('profit_model/', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "convertible-gossip",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 32)                6784      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 6,883\n",
      "Trainable params: 6,883\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "composite-devon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_closes_train = tf.convert_to_tensor([[df[0].iloc[i+j:i+j+time_limit]['close_1min'].tolist() for j in range(batch_size)] for i in range(len(df[0])-buffer)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "technological-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_closes_test = tf.convert_to_tensor([[df[1].iloc[i+j:i+j+time_limit]['close_1min'].tolist() for j in range(batch_size)] for i in range(len(df[1])-buffer)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cellular-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spread_train = tf.convert_to_tensor([df[0].iloc[i:i+1]['spread'].tolist() for i in range(len(df[0])-buffer)])\n",
    "all_spread_test = tf.convert_to_tensor([df[1].iloc[i:i+1]['spread'].tolist() for i in range(len(df[1])-buffer)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "israeli-postcard",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_closes_train = np.save('all_closes_train', all_closes_train.numpy())\n",
    "all_closes_test = np.save('all_closes_test', all_closes_test.numpy())\n",
    "all_spread_train = np.save('all_spread_train', all_spread_train.numpy())\n",
    "all_spread_test = np.save('all_spread_test', all_spread_test.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acceptable-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_closes_train = tf.convert_to_tensor(np.load('all_closes_train.npy'))\n",
    "all_closes_test = tf.convert_to_tensor(np.load('all_closes_test.npy'))\n",
    "all_spread_train = tf.convert_to_tensor(np.load('all_spread_train.npy'))\n",
    "all_spread_test = tf.convert_to_tensor(np.load('all_spread_test.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "laden-contributor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([72603, 32, 60])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_closes_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da4a290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_wrapper(idx, stop_limit, price_limit, margin_size):  \n",
    "    def custom_loss(y_true, y_pred):\n",
    "        margin = ((y_pred[:,:1] - 0.5) * 2)\n",
    "        margin *= margin_size\n",
    "        direction = tf.sign(margin)\n",
    "        stop_loss = y_pred[:,1:2] * direction * -1 * stop_limit\n",
    "        price_target = y_pred[:,2:3] * direction * 1 * price_limit\n",
    "        \n",
    "        idx = y_true[0][1]\n",
    "        df_name = y_true[0][0]\n",
    "        batch_size = y_pred.shape[0]\n",
    "        closes = tf.cond(df_name == tf.constant(0), lambda: tf.gather(all_closes_train, idx), lambda: tf.gather(all_closes_test, idx))\n",
    "        closes = closes[:,:batch_size]\n",
    "        spread = tf.cond(df_name == tf.constant(0), lambda: tf.gather(all_spread_train, idx), lambda: tf.gather(all_spread_test, idx))\n",
    "        close1 = closes[:,:1]\n",
    "        close2 = tf.zeros_like(closes[:,:1])\n",
    "        lower_bound = tf.minimum(stop_loss, price_target)\n",
    "        upper_bound = tf.maximum(stop_loss, price_target)\n",
    "        i = tf.constant(0)\n",
    "        def while_condition(i, close2): \n",
    "            return tf.less(i, tf.constant(closes.shape[1]))\n",
    "        def body(i, close2):\n",
    "            s = tf.slice(closes, [0, i], [closes.shape[0], 1])\n",
    "            diff = (s  - close1) * direction\n",
    "            cond = tf.logical_or(tf.less(diff, lower_bound), tf.greater(diff, upper_bound))\n",
    "            close2 = tf.where(tf.logical_and(tf.equal(close2, 0), cond), s, close2)\n",
    "            return [tf.add(i, 1), close2]\n",
    "        r = tf.while_loop(while_condition, body, [i, close2], parallel_iterations=closes.shape[1], swap_memory=True)#, shape_invariants=[0, close2])\n",
    "            \n",
    "        close2 = tf.where(tf.equal(close2, 0), closes[:,-1:], close2)\n",
    "\n",
    "        diff = close2 - close1\n",
    "        profit = 100 * (margin * (diff - (spread*direction))) /  close1\n",
    "        sharpe = (252 ** 0.5) * tf.reduce_mean(profit) / tf.math.reduce_std(profit)\n",
    "        return -sharpe\n",
    "    return custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "supreme-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profit(data, y_preds, margin_lower_limit=0):\n",
    "    idx = 0\n",
    "    profits = []\n",
    "    while idx < len(y_preds) - 1:\n",
    "        margin = ((y_preds[idx][0] - 0.5) * 2)\n",
    "        margin *= margin_size\n",
    "        if abs(margin) < margin_lower_limit:\n",
    "            idx += 1\n",
    "        else:\n",
    "            direction = np.sign(margin)\n",
    "            stop_loss = y_preds[idx][1] * direction * -1 * stop_limit\n",
    "            price_target = y_preds[idx][2] * direction * 1 * price_limit\n",
    "\n",
    "            start_idx = idx\n",
    "            close1 =  data.iloc[idx]['close_1min']\n",
    "            spread = data.iloc[idx]['spread']\n",
    "            idx += 1\n",
    "            new_i = idx\n",
    "            while new_i < len(data) - 1 and new_i - start_idx < time_limit:\n",
    "                close2 = data.iloc[new_i]['close_1min']\n",
    "                diff = (close2 - close1) \n",
    "                if min(stop_loss, price_limit) < diff * direction < max(stop_loss, price_limit):\n",
    "                    break\n",
    "                new_i += 1\n",
    "            profit = 100 * (margin * (diff - (spread*direction))) /  close1\n",
    "#             print(profit)\n",
    "            profits.append(profit)\n",
    "#             break\n",
    "    return profits\n",
    "\n",
    "# data = df[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "stone-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "\n",
    "class IntervalEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=10):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "#             score = np.mean(custom_metric_wrapper(idx, stop_limit, price_limit, margin_size, time_limit)(tf.convert_to_tensor(self.y_val), tf.convert_to_tensor(y_pred)))\n",
    "#             profits = get_profit(df[1], y_pred)\n",
    "#             profits_0 = get_profit(df[1], y_pred, 0)\n",
    "            print(np.min(y_pred, axis=0))\n",
    "            print(np.mean(y_pred, axis=0))\n",
    "            print(np.max(y_pred, axis=0))\n",
    "#             print(\"interval evaluation - epoch: {:d} - score: {:.6f} -- score_0: {:.6f}\".format(epoch, profits, profits_0))\n",
    "           \n",
    "buffer = (batch_size+time_limit) + 1000\n",
    "ival = IntervalEvaluation(validation_data=(inputs_test[:-buffer], np.array([[1, i] for i in range(len(test)-buffer)])), interval=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "instant-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "    loss=custom_loss_wrapper(idx, stop_limit, price_limit, margin_size),\n",
    "#     metrics=[custom_metric_wrapper(idx, stop_limit, price_limit, margin_size, time_limit)],\n",
    "    run_eagerly=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "452981fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8742 - val_loss: 4.1423\n",
      "[0.48914224 0.31304204 0.19939837]\n",
      "[0.5189687  0.5019916  0.49515387]\n",
      "[1.         0.7742817  0.65772843]\n",
      "Epoch 1001/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8501 - val_loss: 4.3225\n",
      "Epoch 1002/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5471 - val_loss: 4.4495\n",
      "Epoch 1003/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9910 - val_loss: 6.2454\n",
      "[0.4554989  0.31073052 0.13269937]\n",
      "[0.5167454 0.5010154 0.4895994]\n",
      "[1.         0.6897696  0.61536425]\n",
      "Epoch 1004/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6758 - val_loss: 4.3489\n",
      "Epoch 1005/10000\n",
      "2268/2268 [==============================] - 22s 9ms/step - loss: 0.7593 - val_loss: 4.4479\n",
      "Epoch 1006/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7522 - val_loss: 4.3373\n",
      "[0.48922542 0.3858668  0.15567222]\n",
      "[0.52052677 0.5021785  0.48994482]\n",
      "[1.         0.71997297 0.5898793 ]\n",
      "Epoch 1007/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8408 - val_loss: 4.6093\n",
      "Epoch 1008/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.8439 - val_loss: 4.3193\n",
      "Epoch 1009/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7632 - val_loss: 4.1104\n",
      "[0.5003147  0.376352   0.12879917]\n",
      "[0.5272361  0.5043619  0.48595703]\n",
      "[1.        0.702178  0.6255856]\n",
      "Epoch 1010/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7919 - val_loss: 4.3532\n",
      "Epoch 1011/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7588 - val_loss: 3.8421\n",
      "Epoch 1012/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.8728 - val_loss: 4.5348\n",
      "[0.5043981  0.38324058 0.18766385]\n",
      "[0.5301295  0.5012746  0.49003544]\n",
      "[1.         0.74513215 0.6026312 ]\n",
      "Epoch 1013/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6964 - val_loss: 4.4413\n",
      "Epoch 1014/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8062 - val_loss: 4.1030\n",
      "Epoch 1015/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9537 - val_loss: 6.1135\n",
      "[0.47467914 0.34346807 0.16993123]\n",
      "[0.5214636 0.4993714 0.4889106]\n",
      "[1.         0.70531917 0.62015647]\n",
      "Epoch 1016/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7209 - val_loss: 6.2241\n",
      "Epoch 1017/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7516 - val_loss: 6.2119\n",
      "Epoch 1018/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7407 - val_loss: 6.1764\n",
      "[0.49812672 0.30100155 0.11986807]\n",
      "[0.5246527  0.49547678 0.48464423]\n",
      "[1.         0.67092097 0.6638866 ]\n",
      "Epoch 1019/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6858 - val_loss: 3.4948\n",
      "Epoch 1020/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9136 - val_loss: 4.0494\n",
      "Epoch 1021/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8889 - val_loss: 4.3134\n",
      "[0.5021011  0.31121737 0.12843576]\n",
      "[0.53111637 0.4936984  0.48350883]\n",
      "[1.        0.6149769 0.6445197]\n",
      "Epoch 1022/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9173 - val_loss: 4.3092\n",
      "Epoch 1023/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7940 - val_loss: 5.3180\n",
      "Epoch 1024/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5858 - val_loss: 4.1386\n",
      "[0.50128484 0.3079638  0.13918641]\n",
      "[0.53131026 0.49623632 0.482216  ]\n",
      "[1.         0.6084547  0.63993776]\n",
      "Epoch 1025/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5928 - val_loss: 3.1682\n",
      "Epoch 1026/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7426 - val_loss: 3.7342\n",
      "Epoch 1027/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7705 - val_loss: 4.1459\n",
      "[0.5015922  0.30595678 0.13750419]\n",
      "[0.5313889  0.49741128 0.4840601 ]\n",
      "[1.        0.6544485 0.6289003]\n",
      "Epoch 1028/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7083 - val_loss: 4.3216\n",
      "Epoch 1029/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7504 - val_loss: 6.2337\n",
      "Epoch 1030/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8823 - val_loss: 4.2550\n",
      "[0.50201386 0.34193528 0.11960471]\n",
      "[0.5311221  0.5026841  0.48300257]\n",
      "[1.         0.67753017 0.64578515]\n",
      "Epoch 1031/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8507 - val_loss: 4.4139\n",
      "Epoch 1032/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9344 - val_loss: 3.6065\n",
      "Epoch 1033/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8081 - val_loss: 4.2776\n",
      "[0.50196934 0.30999362 0.13825083]\n",
      "[0.5299756  0.50417835 0.48610532]\n",
      "[1.        0.7508613 0.5895794]\n",
      "Epoch 1034/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9011 - val_loss: 2.8211\n",
      "Epoch 1035/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5436 - val_loss: 4.2291\n",
      "Epoch 1036/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8622 - val_loss: 4.4942\n",
      "[0.5023791  0.33779383 0.14764777]\n",
      "[0.5305691  0.50537413 0.4882615 ]\n",
      "[1.        0.7583196 0.6061216]\n",
      "Epoch 1037/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7763 - val_loss: 4.2018\n",
      "Epoch 1038/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8807 - val_loss: 6.1195\n",
      "Epoch 1039/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8923 - val_loss: 6.0478\n",
      "[0.4885359  0.40156695 0.1727288 ]\n",
      "[0.52119684 0.50486404 0.49103177]\n",
      "[1.        0.7697463 0.6141473]\n",
      "Epoch 1040/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5079 - val_loss: 4.3508\n",
      "Epoch 1041/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8053 - val_loss: 4.0436\n",
      "Epoch 1042/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6708 - val_loss: 3.7806\n",
      "[0.5001383  0.4304315  0.18025458]\n",
      "[0.5244181  0.5050397  0.49043512]\n",
      "[1.        0.7665558 0.5569551]\n",
      "Epoch 1043/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7639 - val_loss: 5.7470\n",
      "Epoch 1044/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7956 - val_loss: 6.0560\n",
      "Epoch 1045/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8236 - val_loss: 4.4173\n",
      "[0.4876164  0.29881334 0.22092554]\n",
      "[0.52158606 0.50050414 0.4948359 ]\n",
      "[1.        0.7772527 0.692758 ]\n",
      "Epoch 1046/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7814 - val_loss: 5.9933\n",
      "Epoch 1047/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7912 - val_loss: 6.1230\n",
      "Epoch 1048/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6215 - val_loss: 4.0875\n",
      "[0.0030207  0.24430227 0.21173525]\n",
      "[0.5120864 0.5001194 0.4986867]\n",
      "[1.         0.73426914 0.7970747 ]\n",
      "Epoch 1049/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7837 - val_loss: 4.2490\n",
      "Epoch 1050/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6481 - val_loss: 3.9672\n",
      "Epoch 1051/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5826 - val_loss: 5.7781\n",
      "[0.2908248  0.31063688 0.22081077]\n",
      "[0.51015306 0.5000828  0.49838236]\n",
      "[1.         0.6898093  0.60396045]\n",
      "Epoch 1052/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7956 - val_loss: 3.8692\n",
      "Epoch 1053/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8033 - val_loss: 4.2280\n",
      "Epoch 1054/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8902 - val_loss: 4.3542\n",
      "[0.3664474  0.33897984 0.17928126]\n",
      "[0.51555276 0.49969774 0.49841526]\n",
      "[1.         0.6774557  0.55863625]\n",
      "Epoch 1055/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6869 - val_loss: 3.5948\n",
      "Epoch 1056/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7526 - val_loss: 4.1993\n",
      "Epoch 1057/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7673 - val_loss: 2.9520\n",
      "[0.38803953 0.31229836 0.17898157]\n",
      "[0.50936735 0.49960077 0.49876046]\n",
      "[1.        0.6724216 0.5672199]\n",
      "Epoch 1058/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7403 - val_loss: 5.8173\n",
      "Epoch 1059/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8162 - val_loss: 4.3442\n",
      "Epoch 1060/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8567 - val_loss: 4.2600\n",
      "[0.42728147 0.34595317 0.2530133 ]\n",
      "[0.51293296 0.49951148 0.49962154]\n",
      "[1.        0.6220787 0.5686432]\n",
      "Epoch 1061/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8319 - val_loss: 5.3613\n",
      "Epoch 1062/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8179 - val_loss: 4.4282\n",
      "Epoch 1063/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8143 - val_loss: 4.4190\n",
      "[0.4797731  0.34803474 0.25295243]\n",
      "[0.50870246 0.49952438 0.49961895]\n",
      "[1.         0.62261134 0.574659  ]\n",
      "Epoch 1064/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8146 - val_loss: 3.9933\n",
      "Epoch 1065/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5485 - val_loss: 6.0415\n",
      "Epoch 1066/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6005 - val_loss: 4.0627\n",
      "[0.4415044  0.36640716 0.25393745]\n",
      "[0.51024836 0.49945712 0.49964   ]\n",
      "[1.         0.6290837  0.57224506]\n",
      "Epoch 1067/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7858 - val_loss: 6.0980\n",
      "Epoch 1068/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7899 - val_loss: 6.0184\n",
      "Epoch 1069/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7687 - val_loss: 3.8069\n",
      "[0.46309707 0.35795152 0.25587368]\n",
      "[0.5088356  0.49945068 0.4996044 ]\n",
      "[1.         0.61785454 0.560108  ]\n",
      "Epoch 1070/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8486 - val_loss: 3.7010\n",
      "Epoch 1071/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9246 - val_loss: 3.8098\n",
      "Epoch 1072/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7591 - val_loss: 6.0660\n",
      "[0.46404466 0.3511153  0.24093452]\n",
      "[0.5065209  0.499496   0.49951053]\n",
      "[1.         0.62428    0.55595815]\n",
      "Epoch 1073/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6832 - val_loss: 3.8165\n",
      "Epoch 1074/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7093 - val_loss: 3.9941\n",
      "Epoch 1075/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6486 - val_loss: 4.2803\n",
      "[0.40909648 0.36531666 0.23437443]\n",
      "[0.5120029  0.49951887 0.49947628]\n",
      "[1.        0.6190828 0.5567585]\n",
      "Epoch 1076/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8089 - val_loss: 4.0710\n",
      "Epoch 1077/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7492 - val_loss: 4.3114\n",
      "Epoch 1078/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.5609 - val_loss: 4.1532\n",
      "[0.4594686 0.3601808 0.2391622]\n",
      "[0.5126625  0.49958986 0.4992284 ]\n",
      "[1.         0.62122965 0.5612789 ]\n",
      "Epoch 1079/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7436 - val_loss: 4.2773\n",
      "Epoch 1080/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8230 - val_loss: 4.2627\n",
      "Epoch 1081/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7139 - val_loss: 5.8014\n",
      "[0.46571448 0.36387575 0.22170043]\n",
      "[0.5101177  0.49953303 0.49890977]\n",
      "[1.         0.60565746 0.58195126]\n",
      "Epoch 1082/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7723 - val_loss: 4.0885\n",
      "Epoch 1083/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.9134 - val_loss: 5.9549\n",
      "Epoch 1084/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7571 - val_loss: 6.0053\n",
      "[0.47509095 0.3631562  0.18083614]\n",
      "[0.50975335 0.4996589  0.49882203]\n",
      "[1.        0.6499586 0.5667737]\n",
      "Epoch 1085/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6719 - val_loss: 5.1685\n",
      "Epoch 1086/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7472 - val_loss: 4.1771\n",
      "Epoch 1087/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8747 - val_loss: 4.1317\n",
      "[0.36307663 0.35970542 0.1845864 ]\n",
      "[0.51701003 0.4996469  0.49833143]\n",
      "[1.         0.69326377 0.5615824 ]\n",
      "Epoch 1088/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8527 - val_loss: 3.4629\n",
      "Epoch 1089/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6453 - val_loss: 4.9407\n",
      "Epoch 1090/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7756 - val_loss: 4.2613\n",
      "[0.38956758 0.38832593 0.23454711]\n",
      "[0.51741165 0.4996818  0.4989762 ]\n",
      "[1.        0.6855246 0.5629972]\n",
      "Epoch 1091/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8280 - val_loss: 3.5728\n",
      "Epoch 1092/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8114 - val_loss: 4.8480\n",
      "Epoch 1093/10000\n",
      "2268/2268 [==============================] - 24s 11ms/step - loss: 0.7618 - val_loss: 5.9750\n",
      "[0.29262185 0.38950664 0.26070434]\n",
      "[0.5078626  0.49960107 0.4988305 ]\n",
      "[1.         0.61088884 0.553571  ]\n",
      "Epoch 1094/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8218 - val_loss: 5.8363\n",
      "Epoch 1095/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7483 - val_loss: 4.0272\n",
      "Epoch 1096/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7092 - val_loss: 5.4025\n",
      "[0.10633603 0.39020035 0.25142646]\n",
      "[0.511118   0.49964556 0.49884444]\n",
      "[1.        0.6114797 0.5368943]\n",
      "Epoch 1097/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6480 - val_loss: 3.7556\n",
      "Epoch 1098/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8113 - val_loss: 4.0119\n",
      "Epoch 1099/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6248 - val_loss: 4.2888\n",
      "[0.46158087 0.3835457  0.21061528]\n",
      "[0.51515394 0.49983564 0.498408  ]\n",
      "[1.        0.6638638 0.5484903]\n",
      "Epoch 1100/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7753 - val_loss: 5.6055\n",
      "Epoch 1101/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7448 - val_loss: 4.3817\n",
      "Epoch 1102/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8735 - val_loss: 4.0129\n",
      "[0.44875368 0.38718086 0.24857861]\n",
      "[0.51241446 0.49975443 0.4985279 ]\n",
      "[1.         0.66563237 0.55329555]\n",
      "Epoch 1103/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5532 - val_loss: 4.5821\n",
      "Epoch 1104/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9813 - val_loss: 6.0648\n",
      "Epoch 1105/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8010 - val_loss: 4.4552\n",
      "[0.49005222 0.36317658 0.23904699]\n",
      "[0.51351345 0.49977073 0.4988815 ]\n",
      "[1.         0.65960693 0.5442506 ]\n",
      "Epoch 1106/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9476 - val_loss: 4.1663\n",
      "Epoch 1107/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6363 - val_loss: 3.1716\n",
      "Epoch 1108/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7273 - val_loss: 4.2238\n",
      "[0.50049525 0.39669484 0.24059457]\n",
      "[0.51129746 0.50018406 0.498913  ]\n",
      "[1.         0.72754514 0.56364304]\n",
      "Epoch 1109/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9196 - val_loss: 5.9662\n",
      "Epoch 1110/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7056 - val_loss: 4.1740\n",
      "Epoch 1111/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8379 - val_loss: 5.4098\n",
      "[0.47079942 0.39632726 0.25310403]\n",
      "[0.5089204  0.5001489  0.49897388]\n",
      "[1.         0.716967   0.59033906]\n",
      "Epoch 1112/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6473 - val_loss: 3.9589\n",
      "Epoch 1113/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7391 - val_loss: 4.2741\n",
      "Epoch 1114/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6334 - val_loss: 3.9330\n",
      "[0.50054353 0.39098865 0.27358013]\n",
      "[0.50939816 0.500268   0.4991367 ]\n",
      "[1.         0.70669097 0.5618808 ]\n",
      "Epoch 1115/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9261 - val_loss: 4.0092\n",
      "Epoch 1116/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6670 - val_loss: 4.2428\n",
      "Epoch 1117/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8922 - val_loss: 6.0003\n",
      "[0.49540517 0.39400452 0.27076712]\n",
      "[0.5051345  0.50025564 0.49918756]\n",
      "[1.         0.73268735 0.5740895 ]\n",
      "Epoch 1118/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6975 - val_loss: 4.7574\n",
      "Epoch 1119/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.8827 - val_loss: 5.0335\n",
      "Epoch 1120/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7441 - val_loss: 4.3976\n",
      "[0.5024563  0.39595652 0.2463474 ]\n",
      "[0.5125281  0.5002237  0.49911156]\n",
      "[1.        0.7345869 0.6027627]\n",
      "Epoch 1121/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5508 - val_loss: 4.0517\n",
      "Epoch 1122/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8208 - val_loss: 4.0253\n",
      "Epoch 1123/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9536 - val_loss: 6.0017\n",
      "[0.40663457 0.37762108 0.27159792]\n",
      "[0.5055447 0.5001149 0.4988281]\n",
      "[1.         0.7202408  0.57871825]\n",
      "Epoch 1124/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8812 - val_loss: 3.7403\n",
      "Epoch 1125/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7828 - val_loss: 4.5027\n",
      "Epoch 1126/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6396 - val_loss: 4.0254\n",
      "[0.46386373 0.38649285 0.24413607]\n",
      "[0.5110192  0.5000611  0.49869215]\n",
      "[1.         0.7245354  0.57003385]\n",
      "Epoch 1127/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9559 - val_loss: 3.9185\n",
      "Epoch 1128/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7895 - val_loss: 4.1901\n",
      "Epoch 1129/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8368 - val_loss: 4.0336\n",
      "[0.49398214 0.3640241  0.21363333]\n",
      "[0.51296926 0.500039   0.49834737]\n",
      "[1.         0.70448387 0.59627223]\n",
      "Epoch 1130/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8470 - val_loss: 6.1218\n",
      "Epoch 1131/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7859 - val_loss: 6.0251\n",
      "Epoch 1132/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6544 - val_loss: 5.8098\n",
      "[0.48876643 0.2956129  0.21874142]\n",
      "[0.5112557  0.49980623 0.4986564 ]\n",
      "[1.         0.71209484 0.65353924]\n",
      "Epoch 1133/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7626 - val_loss: 4.1763\n",
      "Epoch 1134/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7196 - val_loss: 4.7608\n",
      "Epoch 1135/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7647 - val_loss: 4.8932\n",
      "[0.46901512 0.34282267 0.2005218 ]\n",
      "[0.51294124 0.500179   0.4983579 ]\n",
      "[1.         0.73320043 0.57954174]\n",
      "Epoch 1136/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7596 - val_loss: 3.7181\n",
      "Epoch 1137/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6798 - val_loss: 4.0222\n",
      "Epoch 1138/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8238 - val_loss: 4.5086\n",
      "[0.47670892 0.355123   0.22016513]\n",
      "[0.5202342  0.499129   0.49837452]\n",
      "[1.         0.73368204 0.62130904]\n",
      "Epoch 1139/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7922 - val_loss: 6.0744\n",
      "Epoch 1140/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8153 - val_loss: 4.2529\n",
      "Epoch 1141/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7999 - val_loss: 4.3657\n",
      "[0.5019261  0.2954342  0.24125558]\n",
      "[0.51762754 0.49799052 0.49833483]\n",
      "[1.        0.7335582 0.6268134]\n",
      "Epoch 1142/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5324 - val_loss: 4.4314\n",
      "Epoch 1143/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.6937 - val_loss: 4.5246\n",
      "Epoch 1144/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8433 - val_loss: 4.0629\n",
      "[0.47305754 0.3439576  0.22401705]\n",
      "[0.5135414  0.49986637 0.4989934 ]\n",
      "[1.         0.75289196 0.6176164 ]\n",
      "Epoch 1145/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8561 - val_loss: 6.0963\n",
      "Epoch 1146/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8997 - val_loss: 5.9354\n",
      "Epoch 1147/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8342 - val_loss: 3.8396\n",
      "[0.40542203 0.36247498 0.21879336]\n",
      "[0.5117829  0.49968824 0.49949017]\n",
      "[1.         0.7651309  0.66491324]\n",
      "Epoch 1148/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7528 - val_loss: 4.1118\n",
      "Epoch 1149/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6633 - val_loss: 4.0549\n",
      "Epoch 1150/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6993 - val_loss: 4.1914\n",
      "[0.4641223  0.3380264  0.21103573]\n",
      "[0.513824   0.49989152 0.49923992]\n",
      "[1.         0.7810582  0.66489756]\n",
      "Epoch 1151/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7327 - val_loss: 4.3555\n",
      "Epoch 1152/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8918 - val_loss: 4.4680\n",
      "Epoch 1153/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6509 - val_loss: 4.0471\n",
      "[0.46399868 0.29389358 0.20796192]\n",
      "[0.5139806  0.49902183 0.49918184]\n",
      "[1.         0.76593363 0.6578568 ]\n",
      "Epoch 1154/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7846 - val_loss: 6.1371\n",
      "Epoch 1155/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7650 - val_loss: 4.0629\n",
      "Epoch 1156/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6699 - val_loss: 4.1821\n",
      "[0.5022621  0.2843368  0.28491753]\n",
      "[0.51751274 0.4979348  0.4995497 ]\n",
      "[1.         0.74532837 0.66093117]\n",
      "Epoch 1157/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8500 - val_loss: 5.9083\n",
      "Epoch 1158/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6754 - val_loss: 4.3225\n",
      "Epoch 1159/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6313 - val_loss: 4.2865\n",
      "[0.49567023 0.25280413 0.29205737]\n",
      "[0.5204954  0.49661365 0.49859056]\n",
      "[1.         0.73423606 0.6600981 ]\n",
      "Epoch 1160/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7214 - val_loss: 5.4889\n",
      "Epoch 1161/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8410 - val_loss: 4.3603\n",
      "Epoch 1162/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7773 - val_loss: 3.9526\n",
      "[0.4976426  0.21777597 0.31459847]\n",
      "[0.5212371  0.49336794 0.49989703]\n",
      "[1.         0.67681736 0.7043759 ]\n",
      "Epoch 1163/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7311 - val_loss: 4.4827\n",
      "Epoch 1164/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9456 - val_loss: 6.2450\n",
      "Epoch 1165/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8749 - val_loss: 5.9773\n",
      "[0.32368183 0.14084348 0.36139047]\n",
      "[0.52323514 0.4919501  0.5012462 ]\n",
      "[1.         0.55643433 0.7662709 ]\n",
      "Epoch 1166/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.6284 - val_loss: 4.3672\n",
      "Epoch 1167/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7497 - val_loss: 6.2118\n",
      "Epoch 1168/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7716 - val_loss: 4.1129\n",
      "[0.4992967  0.20590231 0.33431762]\n",
      "[0.520904   0.49340615 0.50094545]\n",
      "[1.         0.6028371  0.71067774]\n",
      "Epoch 1169/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7088 - val_loss: 6.2586\n",
      "Epoch 1170/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0251 - val_loss: 6.2252\n",
      "Epoch 1171/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8047 - val_loss: 5.6648\n",
      "[0.49930188 0.21066996 0.3037759 ]\n",
      "[0.5192892  0.49385253 0.5003816 ]\n",
      "[1.         0.68169403 0.66518605]\n",
      "Epoch 1172/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0142 - val_loss: 6.1964\n",
      "Epoch 1173/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7590 - val_loss: 5.9746\n",
      "Epoch 1174/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9307 - val_loss: 4.2398\n",
      "[0.50015444 0.1679278  0.3437388 ]\n",
      "[0.52816117 0.4901099  0.50321996]\n",
      "[1.         0.5544572  0.76746106]\n",
      "Epoch 1175/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7629 - val_loss: 4.3224\n",
      "Epoch 1176/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6248 - val_loss: 4.2939\n",
      "Epoch 1177/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0168 - val_loss: 4.2428\n",
      "[0.5027255  0.16507494 0.36365837]\n",
      "[0.5339961 0.4870632 0.5017549]\n",
      "[1.         0.51796204 0.7389434 ]\n",
      "Epoch 1178/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6817 - val_loss: 4.8655\n",
      "Epoch 1179/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8117 - val_loss: 4.5090\n",
      "Epoch 1180/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6596 - val_loss: 6.1943\n",
      "[0.49574772 0.16200033 0.36610597]\n",
      "[0.5236244  0.48866373 0.50389695]\n",
      "[1.         0.5140486  0.72871006]\n",
      "Epoch 1181/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8993 - val_loss: 6.1180\n",
      "Epoch 1182/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9368 - val_loss: 4.5801\n",
      "Epoch 1183/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7595 - val_loss: 4.2583\n",
      "[0.00169849 0.15823305 0.36283576]\n",
      "[0.5252217  0.48986647 0.5026872 ]\n",
      "[1.         0.50756323 0.6777725 ]\n",
      "Epoch 1184/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6464 - val_loss: 5.5724\n",
      "Epoch 1185/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7305 - val_loss: 4.3003\n",
      "Epoch 1186/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8103 - val_loss: 4.3962\n",
      "[0.14129731 0.14455414 0.37578678]\n",
      "[0.53158885 0.48469618 0.5051454 ]\n",
      "[1.         0.51006174 0.6726836 ]\n",
      "Epoch 1187/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7971 - val_loss: 4.3423\n",
      "Epoch 1188/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8258 - val_loss: 5.1305\n",
      "Epoch 1189/10000\n",
      "2268/2268 [==============================] - 22s 9ms/step - loss: 0.5931 - val_loss: 4.3135\n",
      "[0.10836437 0.16900966 0.33915335]\n",
      "[0.5265113  0.48631456 0.5058288 ]\n",
      "[1.         0.50851786 0.7061369 ]\n",
      "Epoch 1190/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.6813 - val_loss: 4.3595\n",
      "Epoch 1191/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8201 - val_loss: 3.7027\n",
      "Epoch 1192/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8233 - val_loss: 4.2830\n",
      "[3.5539379e-05 1.2664810e-01 3.4905374e-01]\n",
      "[0.52516454 0.48779282 0.5043155 ]\n",
      "[1.        0.5076058 0.7218596]\n",
      "Epoch 1193/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7802 - val_loss: 6.1000\n",
      "Epoch 1194/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6250 - val_loss: 3.9460\n",
      "Epoch 1195/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8610 - val_loss: 6.1137\n",
      "[0.29285032 0.13161427 0.36789867]\n",
      "[0.5167661  0.49036047 0.5048492 ]\n",
      "[1.         0.50657207 0.6730106 ]\n",
      "Epoch 1196/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8005 - val_loss: 4.2809\n",
      "Epoch 1197/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8148 - val_loss: 4.2931\n",
      "Epoch 1198/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5324 - val_loss: 4.4232\n",
      "[0.48569766 0.11514178 0.3460838 ]\n",
      "[0.5281562  0.48811236 0.504999  ]\n",
      "[1.         0.50682664 0.6949455 ]\n",
      "Epoch 1199/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7122 - val_loss: 5.6289\n",
      "Epoch 1200/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6103 - val_loss: 4.3806\n",
      "Epoch 1201/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8435 - val_loss: 4.4935\n",
      "[0.00848708 0.12727082 0.3123424 ]\n",
      "[0.5298549  0.48627466 0.50314295]\n",
      "[1.         0.50828046 0.7365519 ]\n",
      "Epoch 1202/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7501 - val_loss: 4.1447\n",
      "Epoch 1203/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8438 - val_loss: 4.2767\n",
      "Epoch 1204/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7953 - val_loss: 4.3948\n",
      "[1.1383105e-04 1.1636138e-01 3.4306192e-01]\n",
      "[0.5255804  0.48788196 0.5032635 ]\n",
      "[1.         0.50769556 0.6677184 ]\n",
      "Epoch 1205/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9134 - val_loss: 4.5498\n",
      "Epoch 1206/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8247 - val_loss: 6.0908\n",
      "Epoch 1207/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8473 - val_loss: 4.4834\n",
      "[0.15822136 0.14583501 0.34197628]\n",
      "[0.5265423  0.49023736 0.5040659 ]\n",
      "[1.        0.5057264 0.7181984]\n",
      "Epoch 1208/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8649 - val_loss: 4.3027\n",
      "Epoch 1209/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9708 - val_loss: 5.3898\n",
      "Epoch 1210/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7355 - val_loss: 6.0708\n",
      "[0.36726505 0.15346897 0.35269088]\n",
      "[0.52103156 0.48970586 0.5037776 ]\n",
      "[1.         0.5059642  0.65850973]\n",
      "Epoch 1211/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8461 - val_loss: 5.2055\n",
      "Epoch 1212/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8045 - val_loss: 4.7205\n",
      "Epoch 1213/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.8292 - val_loss: 4.2897\n",
      "[0.29523087 0.14938012 0.3427781 ]\n",
      "[0.5212099 0.4898881 0.5026253]\n",
      "[1.         0.50770235 0.64634424]\n",
      "Epoch 1214/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7543 - val_loss: 4.5174\n",
      "Epoch 1215/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8262 - val_loss: 4.6130\n",
      "Epoch 1216/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7591 - val_loss: 4.1089\n",
      "[0.4265245  0.09777838 0.34598827]\n",
      "[0.5205483  0.48872465 0.5027842 ]\n",
      "[1.        0.5059466 0.6711954]\n",
      "Epoch 1217/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8678 - val_loss: 4.3597\n",
      "Epoch 1218/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7278 - val_loss: 4.6768\n",
      "Epoch 1219/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5960 - val_loss: 4.5878\n",
      "[0.50294155 0.13164937 0.34847158]\n",
      "[0.5231962  0.48973832 0.50217736]\n",
      "[1.        0.5048778 0.6870904]\n",
      "Epoch 1220/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7569 - val_loss: 4.4741\n",
      "Epoch 1221/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8170 - val_loss: 4.3909\n",
      "Epoch 1222/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7747 - val_loss: 4.0325\n",
      "[0.00302497 0.15252897 0.32676917]\n",
      "[0.5090879  0.49718022 0.500596  ]\n",
      "[1.         0.50355667 0.6949879 ]\n",
      "Epoch 1223/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9014 - val_loss: 4.4991\n",
      "Epoch 1224/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7871 - val_loss: 4.3201\n",
      "Epoch 1225/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8417 - val_loss: 5.7701\n",
      "[0.03552556 0.1845893  0.33834928]\n",
      "[0.51020247 0.4972044  0.50125694]\n",
      "[1.         0.54096645 0.6721381 ]\n",
      "Epoch 1226/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7460 - val_loss: 6.0467\n",
      "Epoch 1227/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9153 - val_loss: 4.6676\n",
      "Epoch 1228/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8581 - val_loss: 5.4030\n",
      "[0.15678966 0.20113462 0.34703374]\n",
      "[0.50896996 0.49771026 0.50040436]\n",
      "[1.        0.5136266 0.6620049]\n",
      "Epoch 1229/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8313 - val_loss: 6.1206\n",
      "Epoch 1230/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.1162 - val_loss: 4.0004\n",
      "Epoch 1231/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6579 - val_loss: 6.0395\n",
      "[0.34884918 0.20166093 0.34419167]\n",
      "[0.50951326 0.4972661  0.5001072 ]\n",
      "[1.         0.5526391  0.65051734]\n",
      "Epoch 1232/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7307 - val_loss: 4.3526\n",
      "Epoch 1233/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7100 - val_loss: 4.3914\n",
      "Epoch 1234/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9354 - val_loss: 4.1510\n",
      "[0.45485184 0.19767383 0.30337456]\n",
      "[0.50939995 0.4984509  0.49954027]\n",
      "[1.         0.54042065 0.62875   ]\n",
      "Epoch 1235/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7769 - val_loss: 4.5791\n",
      "Epoch 1236/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6996 - val_loss: 4.4462\n",
      "Epoch 1237/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8342 - val_loss: 4.3749\n",
      "[0.47409505 0.18420342 0.30189466]\n",
      "[0.5103269  0.4983077  0.49952507]\n",
      "[1.         0.5343841  0.63526094]\n",
      "Epoch 1238/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8564 - val_loss: 4.5937\n",
      "Epoch 1239/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8470 - val_loss: 3.8810\n",
      "Epoch 1240/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6374 - val_loss: 4.2634\n",
      "[0.4745021  0.20391428 0.281994  ]\n",
      "[0.5088495  0.49873373 0.49938482]\n",
      "[1.         0.5382908  0.62462544]\n",
      "Epoch 1241/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7732 - val_loss: 4.1076\n",
      "Epoch 1242/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8048 - val_loss: 3.9520\n",
      "Epoch 1243/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6102 - val_loss: 6.1530\n",
      "[0.45282847 0.20131862 0.29663068]\n",
      "[0.5064967  0.49855056 0.49925745]\n",
      "[1.        0.542533  0.6159799]\n",
      "Epoch 1244/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7086 - val_loss: 6.0924\n",
      "Epoch 1245/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5908 - val_loss: 3.9491\n",
      "Epoch 1246/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8622 - val_loss: 6.0806\n",
      "[0.47964537 0.22232023 0.30026072]\n",
      "[0.5042054  0.4991165  0.49961677]\n",
      "[1.         0.56282055 0.60421294]\n",
      "Epoch 1247/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7668 - val_loss: 4.7856\n",
      "Epoch 1248/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7546 - val_loss: 4.6148\n",
      "Epoch 1249/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8552 - val_loss: 6.1180\n",
      "[0.4205717  0.25619355 0.2637059 ]\n",
      "[0.5045513  0.49911398 0.49953488]\n",
      "[1.         0.5341176  0.57819223]\n",
      "Epoch 1250/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8137 - val_loss: 4.2752\n",
      "Epoch 1251/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6358 - val_loss: 4.4258\n",
      "Epoch 1252/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9471 - val_loss: 6.1138\n",
      "[0.453583   0.28834355 0.26577204]\n",
      "[0.50461274 0.49930567 0.49960262]\n",
      "[1.        0.5507932 0.5969559]\n",
      "Epoch 1253/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7446 - val_loss: 6.1029\n",
      "Epoch 1254/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7636 - val_loss: 5.9497\n",
      "Epoch 1255/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6362 - val_loss: 4.4444\n",
      "[0.46452546 0.28172317 0.25993603]\n",
      "[0.50984675 0.49934745 0.49962738]\n",
      "[1.        0.5314927 0.6039771]\n",
      "Epoch 1256/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8871 - val_loss: 4.3066\n",
      "Epoch 1257/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8440 - val_loss: 6.1239\n",
      "Epoch 1258/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8096 - val_loss: 4.6601\n",
      "[0.5010152  0.25880274 0.24860287]\n",
      "[0.51335984 0.49951085 0.4997615 ]\n",
      "[1.         0.5645924  0.59367394]\n",
      "Epoch 1259/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7150 - val_loss: 6.0750\n",
      "Epoch 1260/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7490 - val_loss: 4.4123\n",
      "Epoch 1261/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6675 - val_loss: 4.3951\n",
      "[0.35294878 0.31083438 0.24399254]\n",
      "[0.5100781  0.4995387  0.49952835]\n",
      "[1.         0.54781705 0.5228591 ]\n",
      "Epoch 1262/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7697 - val_loss: 5.9436\n",
      "Epoch 1263/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9176 - val_loss: 4.2209\n",
      "Epoch 1264/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8467 - val_loss: 6.1280\n",
      "[0.38213575 0.2529784  0.26097894]\n",
      "[0.5045096 0.499462  0.4996703]\n",
      "[1.        0.6248441 0.6439934]\n",
      "Epoch 1265/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8018 - val_loss: 4.5700\n",
      "Epoch 1266/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9043 - val_loss: 6.1641\n",
      "Epoch 1267/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8671 - val_loss: 4.3636\n",
      "[0.4724865  0.3146757  0.24381167]\n",
      "[0.5106623  0.49957958 0.4996571 ]\n",
      "[1.         0.5721811  0.54581374]\n",
      "Epoch 1268/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9468 - val_loss: 5.9674\n",
      "Epoch 1269/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6267 - val_loss: 4.5663\n",
      "Epoch 1270/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7926 - val_loss: 6.0433\n",
      "[0.44205898 0.31986493 0.24548087]\n",
      "[0.5070058  0.4995208  0.49954477]\n",
      "[1.         0.59801245 0.5301995 ]\n",
      "Epoch 1271/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8235 - val_loss: 4.4863\n",
      "Epoch 1272/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7161 - val_loss: 4.5002\n",
      "Epoch 1273/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6587 - val_loss: 4.3681\n",
      "[0.41195947 0.30686155 0.24023154]\n",
      "[0.5101491  0.49943998 0.4993333 ]\n",
      "[1.         0.5816456  0.51112413]\n",
      "Epoch 1274/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5840 - val_loss: 4.5392\n",
      "Epoch 1275/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9428 - val_loss: 6.0958\n",
      "Epoch 1276/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7492 - val_loss: 4.5069\n",
      "[0.5042099  0.33195752 0.23804408]\n",
      "[0.51104164 0.49954975 0.4995636 ]\n",
      "[1.         0.56795704 0.5186371 ]\n",
      "Epoch 1277/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7069 - val_loss: 5.9923\n",
      "Epoch 1278/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7364 - val_loss: 4.6462\n",
      "Epoch 1279/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8294 - val_loss: 4.5045\n",
      "[0.5041654 0.3270149 0.2622405]\n",
      "[0.5110551  0.4995066  0.49934146]\n",
      "[1.         0.554318   0.56981295]\n",
      "Epoch 1280/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6421 - val_loss: 5.9485\n",
      "Epoch 1281/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7080 - val_loss: 4.2217\n",
      "Epoch 1282/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7127 - val_loss: 4.3257\n",
      "[0.50269413 0.31984022 0.24446017]\n",
      "[0.5101811  0.49952778 0.4993438 ]\n",
      "[1.        0.5600889 0.5144139]\n",
      "Epoch 1283/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7382 - val_loss: 4.1747\n",
      "Epoch 1284/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5839 - val_loss: 4.6837\n",
      "Epoch 1285/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8036 - val_loss: 5.9502\n",
      "[0.42138585 0.3244737  0.2378287 ]\n",
      "[0.50176805 0.49916166 0.49906778]\n",
      "[1.         0.5812383  0.52448535]\n",
      "Epoch 1286/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8519 - val_loss: 4.5295\n",
      "Epoch 1287/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7730 - val_loss: 3.8787\n",
      "Epoch 1288/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0355 - val_loss: 6.0460\n",
      "[0.48544028 0.3366278  0.2395375 ]\n",
      "[0.50441253 0.49941623 0.4992875 ]\n",
      "[1.        0.5630302 0.5383576]\n",
      "Epoch 1289/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6079 - val_loss: 5.8249\n",
      "Epoch 1290/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6711 - val_loss: 4.4545\n",
      "Epoch 1291/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9389 - val_loss: 4.4537\n",
      "[0.50058776 0.34608048 0.24493128]\n",
      "[0.5123032  0.49940315 0.49943176]\n",
      "[1.         0.582142   0.52776825]\n",
      "Epoch 1292/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7028 - val_loss: 6.2106\n",
      "Epoch 1293/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5977 - val_loss: 4.2131\n",
      "Epoch 1294/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9329 - val_loss: 4.5669\n",
      "[0.50541186 0.35706043 0.2549529 ]\n",
      "[0.5123566  0.49940288 0.49970907]\n",
      "[1.         0.5937445  0.54312044]\n",
      "Epoch 1295/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7055 - val_loss: 4.5786\n",
      "Epoch 1296/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8194 - val_loss: 5.9746\n",
      "Epoch 1297/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7731 - val_loss: 5.9870\n",
      "[0.47255072 0.3321821  0.2972567 ]\n",
      "[0.50246865 0.4993794  0.49983063]\n",
      "[1.         0.57820857 0.5288592 ]\n",
      "Epoch 1298/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7170 - val_loss: 4.3221\n",
      "Epoch 1299/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7993 - val_loss: 4.3142\n",
      "Epoch 1300/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8438 - val_loss: 4.5265\n",
      "[0.49749935 0.3327492  0.3202275 ]\n",
      "[0.5112319  0.49948198 0.49989665]\n",
      "[1.        0.5888635 0.5479968]\n",
      "Epoch 1301/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0231 - val_loss: 6.1227\n",
      "Epoch 1302/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8543 - val_loss: 4.4258\n",
      "Epoch 1303/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8869 - val_loss: 5.9996\n",
      "[0.49953333 0.3764125  0.3167638 ]\n",
      "[0.5069683 0.499368  0.4998985]\n",
      "[1.         0.58957505 0.520408  ]\n",
      "Epoch 1304/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7638 - val_loss: 3.7741\n",
      "Epoch 1305/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6060 - val_loss: 4.3606\n",
      "Epoch 1306/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.6413 - val_loss: 4.5014\n",
      "[0.463836   0.38069776 0.29464865]\n",
      "[0.5115646  0.4995957  0.49980706]\n",
      "[1.         0.57241184 0.5126622 ]\n",
      "Epoch 1307/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8226 - val_loss: 3.9374\n",
      "Epoch 1308/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7824 - val_loss: 6.0195\n",
      "Epoch 1309/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7984 - val_loss: 5.7451\n",
      "[0.49972063 0.39019334 0.29880762]\n",
      "[0.5075476  0.4997105  0.49988356]\n",
      "[1.         0.5941123  0.51413184]\n",
      "Epoch 1310/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5892 - val_loss: 4.4330\n",
      "Epoch 1311/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6149 - val_loss: 4.4127\n",
      "Epoch 1312/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6898 - val_loss: 4.4459\n",
      "[0.5040266  0.3395759  0.27918968]\n",
      "[0.5115158  0.49964198 0.49990243]\n",
      "[1.        0.5973867 0.5327811]\n",
      "Epoch 1313/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7199 - val_loss: 6.1540\n",
      "Epoch 1314/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8872 - val_loss: 6.0061\n",
      "Epoch 1315/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7734 - val_loss: 3.9741\n",
      "[0.36576623 0.33870393 0.26452625]\n",
      "[0.5092942  0.49941024 0.4996784 ]\n",
      "[1.         0.58652383 0.53505796]\n",
      "Epoch 1316/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7125 - val_loss: 6.1828\n",
      "Epoch 1317/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7679 - val_loss: 4.1460\n",
      "Epoch 1318/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7247 - val_loss: 4.1556\n",
      "[0.01243049 0.2860309  0.27432692]\n",
      "[0.5113298  0.49882537 0.4995864 ]\n",
      "[1.        0.6205519 0.5492263]\n",
      "Epoch 1319/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7979 - val_loss: 4.0196\n",
      "Epoch 1320/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9480 - val_loss: 3.3712\n",
      "Epoch 1321/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8497 - val_loss: 5.9971\n",
      "[0.1851106  0.3350668  0.27426225]\n",
      "[0.50356865 0.49904382 0.49951535]\n",
      "[1.         0.6311167  0.54336584]\n",
      "Epoch 1322/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9179 - val_loss: 6.0937\n",
      "Epoch 1323/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7762 - val_loss: 4.2400\n",
      "Epoch 1324/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9893 - val_loss: 4.2368\n",
      "[0.5024297  0.34173867 0.26743162]\n",
      "[0.5110037  0.49936852 0.49961123]\n",
      "[1.        0.600025  0.5432586]\n",
      "Epoch 1325/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8711 - val_loss: 6.1874\n",
      "Epoch 1326/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7145 - val_loss: 4.2095\n",
      "Epoch 1327/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9724 - val_loss: 4.3105\n",
      "[0.35191184 0.33432966 0.32674295]\n",
      "[0.5091157  0.49962297 0.4999537 ]\n",
      "[1.         0.590343   0.56454295]\n",
      "Epoch 1328/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6434 - val_loss: 4.5010\n",
      "Epoch 1329/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.6601 - val_loss: 4.3893\n",
      "Epoch 1330/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.8113 - val_loss: 3.6009\n",
      "[0.32580668 0.33005738 0.28007227]\n",
      "[0.5065304  0.49966535 0.49991184]\n",
      "[1.         0.6064704  0.55593383]\n",
      "Epoch 1331/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8414 - val_loss: 4.6174\n",
      "Epoch 1332/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7085 - val_loss: 4.4271\n",
      "Epoch 1333/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6236 - val_loss: 3.9955\n",
      "[0.3803681  0.32389075 0.27499712]\n",
      "[0.5076857  0.49948996 0.49990416]\n",
      "[1.         0.5576825  0.57911974]\n",
      "Epoch 1334/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0567 - val_loss: 4.5700\n",
      "Epoch 1335/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6754 - val_loss: 4.0745\n",
      "Epoch 1336/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7706 - val_loss: 3.9618\n",
      "[0.38656953 0.30124986 0.2661665 ]\n",
      "[0.5074226  0.49948516 0.49984604]\n",
      "[1.         0.55838984 0.5578209 ]\n",
      "Epoch 1337/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7392 - val_loss: 5.7241\n",
      "Epoch 1338/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9162 - val_loss: 6.1634\n",
      "Epoch 1339/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0726 - val_loss: 6.1109\n",
      "[0.41766354 0.31568563 0.25511807]\n",
      "[0.50470257 0.49947384 0.49985453]\n",
      "[1.         0.57702917 0.56826705]\n",
      "Epoch 1340/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7806 - val_loss: 4.3657\n",
      "Epoch 1341/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7097 - val_loss: 4.3485\n",
      "Epoch 1342/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8561 - val_loss: 4.1072\n",
      "[0.29522702 0.34545738 0.29922116]\n",
      "[0.5088068  0.49915683 0.49967346]\n",
      "[1.         0.54280674 0.51945466]\n",
      "Epoch 1343/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.4823 - val_loss: 4.3128\n",
      "Epoch 1344/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8008 - val_loss: 4.1526\n",
      "Epoch 1345/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9465 - val_loss: 4.4451\n",
      "[0.36250114 0.319713   0.26282012]\n",
      "[0.511064   0.499131   0.49986392]\n",
      "[1.         0.55598265 0.53973633]\n",
      "Epoch 1346/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8556 - val_loss: 6.1828\n",
      "Epoch 1347/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7080 - val_loss: 5.9903\n",
      "Epoch 1348/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7969 - val_loss: 4.4271\n",
      "[0.48935184 0.35219464 0.3609864 ]\n",
      "[0.51050687 0.49934217 0.49991626]\n",
      "[1.        0.5584862 0.5258485]\n",
      "Epoch 1349/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6928 - val_loss: 4.6334\n",
      "Epoch 1350/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9202 - val_loss: 4.0219\n",
      "Epoch 1351/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8250 - val_loss: 4.2033\n",
      "[0.49639484 0.34950337 0.38699985]\n",
      "[0.5085779  0.49924982 0.49984726]\n",
      "[1.         0.58471733 0.52811766]\n",
      "Epoch 1352/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.8386 - val_loss: 4.1886\n",
      "Epoch 1353/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.8711 - val_loss: 6.0228\n",
      "Epoch 1354/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6880 - val_loss: 4.3020\n",
      "[0.41462263 0.34670198 0.39110714]\n",
      "[0.5086067  0.49932724 0.4999288 ]\n",
      "[1.         0.56200963 0.52203995]\n",
      "Epoch 1355/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6672 - val_loss: 4.4850\n",
      "Epoch 1356/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8998 - val_loss: 4.0777\n",
      "Epoch 1357/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.4804 - val_loss: 6.0294\n",
      "[0.4997147  0.3346271  0.38668445]\n",
      "[0.5071559  0.49900156 0.49967694]\n",
      "[1.         0.563084   0.53430974]\n",
      "Epoch 1358/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6766 - val_loss: 4.0454\n",
      "Epoch 1359/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6166 - val_loss: 4.4355\n",
      "Epoch 1360/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0273 - val_loss: 5.9781\n",
      "[0.49569204 0.33690622 0.3922676 ]\n",
      "[0.5033499 0.4990408 0.4997619]\n",
      "[1.         0.5623934  0.53144145]\n",
      "Epoch 1361/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7916 - val_loss: 6.1901\n",
      "Epoch 1362/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8185 - val_loss: 3.8857\n",
      "Epoch 1363/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7288 - val_loss: 4.2395\n",
      "[0.5021152  0.33678478 0.3731389 ]\n",
      "[0.51012164 0.4988321  0.49949822]\n",
      "[1.        0.5356918 0.5392609]\n",
      "Epoch 1364/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7655 - val_loss: 6.1556\n",
      "Epoch 1365/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8136 - val_loss: 4.1215\n",
      "Epoch 1366/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8808 - val_loss: 6.1551\n",
      "[0.4978838  0.32225758 0.36855975]\n",
      "[0.50643295 0.4986405  0.49937958]\n",
      "[1.         0.5727951  0.53847444]\n",
      "Epoch 1367/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6940 - val_loss: 4.2418\n",
      "Epoch 1368/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7084 - val_loss: 3.6582\n",
      "Epoch 1369/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7394 - val_loss: 4.4675\n",
      "[0.4606446  0.31959477 0.35637367]\n",
      "[0.51422256 0.4987546  0.4995087 ]\n",
      "[1.        0.5682441 0.5606279]\n",
      "Epoch 1370/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7439 - val_loss: 4.2804\n",
      "Epoch 1371/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8709 - val_loss: 3.8389\n",
      "Epoch 1372/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6372 - val_loss: 4.3912\n",
      "[0.5044105  0.3243475  0.34608573]\n",
      "[0.5140781 0.4987842 0.4994516]\n",
      "[1.         0.573733   0.55502355]\n",
      "Epoch 1373/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8076 - val_loss: 6.1784\n",
      "Epoch 1374/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7461 - val_loss: 4.1391\n",
      "Epoch 1375/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7113 - val_loss: 4.1658\n",
      "[0.5015581  0.33146948 0.33920088]\n",
      "[0.511409   0.49892047 0.49942926]\n",
      "[1.         0.5746844  0.54386836]\n",
      "Epoch 1376/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7479 - val_loss: 3.7446\n",
      "Epoch 1377/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7283 - val_loss: 4.2159\n",
      "Epoch 1378/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9016 - val_loss: 6.1979\n",
      "[0.4366241  0.3042177  0.32682616]\n",
      "[0.5093973  0.49833587 0.4992478 ]\n",
      "[1.        0.5646342 0.5721326]\n",
      "Epoch 1379/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7105 - val_loss: 6.0976\n",
      "Epoch 1380/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8038 - val_loss: 4.3380\n",
      "Epoch 1381/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7809 - val_loss: 4.4825\n",
      "[0.4683625  0.32458198 0.33646205]\n",
      "[0.51480067 0.49889445 0.49956384]\n",
      "[1.         0.56254363 0.6100295 ]\n",
      "Epoch 1382/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7584 - val_loss: 4.4448\n",
      "Epoch 1383/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7317 - val_loss: 6.1565\n",
      "Epoch 1384/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7766 - val_loss: 4.1279\n",
      "[0.4649302  0.3045625  0.33140188]\n",
      "[0.5119873 0.4979908 0.4992384]\n",
      "[1.         0.53446084 0.5868449 ]\n",
      "Epoch 1385/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7761 - val_loss: 6.2116\n",
      "Epoch 1386/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7025 - val_loss: 4.3231\n",
      "Epoch 1387/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6473 - val_loss: 3.7737\n",
      "[0.48562142 0.32064518 0.3458795 ]\n",
      "[0.50965554 0.49843842 0.49948224]\n",
      "[1.         0.54530984 0.6025478 ]\n",
      "Epoch 1388/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8933 - val_loss: 5.9733\n",
      "Epoch 1389/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7796 - val_loss: 4.2999\n",
      "Epoch 1390/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7377 - val_loss: 4.3510\n",
      "[0.48807642 0.3129421  0.34752634]\n",
      "[0.5116297  0.49857932 0.49979636]\n",
      "[1.         0.5692452  0.62665427]\n",
      "Epoch 1391/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7626 - val_loss: 4.3223\n",
      "Epoch 1392/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7589 - val_loss: 4.4266\n",
      "Epoch 1393/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7533 - val_loss: 4.0457\n",
      "[0.50040793 0.32126352 0.3605414 ]\n",
      "[0.50949466 0.49876466 0.49957618]\n",
      "[1.        0.5567216 0.6036931]\n",
      "Epoch 1394/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7641 - val_loss: 5.9567\n",
      "Epoch 1395/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7607 - val_loss: 4.0048\n",
      "Epoch 1396/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9604 - val_loss: 6.1036\n",
      "[0.43526578 0.3125506  0.35996264]\n",
      "[0.50603724 0.49872613 0.4994692 ]\n",
      "[1.        0.5487334 0.5875144]\n",
      "Epoch 1397/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7207 - val_loss: 4.4445\n",
      "Epoch 1398/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7082 - val_loss: 4.5188\n",
      "Epoch 1399/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.6242 - val_loss: 4.3736\n",
      "[0.49892172 0.33666772 0.36306792]\n",
      "[0.51203644 0.49922308 0.49959058]\n",
      "[1.        0.5738313 0.6014952]\n",
      "Epoch 1400/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.8525 - val_loss: 3.3258\n",
      "Epoch 1401/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7834 - val_loss: 4.2662\n",
      "Epoch 1402/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6799 - val_loss: 4.1758\n",
      "[0.50118685 0.33560604 0.36110312]\n",
      "[0.5099338  0.4992551  0.49961925]\n",
      "[1.         0.5675355  0.59265906]\n",
      "Epoch 1403/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7206 - val_loss: 4.0883\n",
      "Epoch 1404/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8944 - val_loss: 6.1365\n",
      "Epoch 1405/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8337 - val_loss: 4.0953\n",
      "[0.39122182 0.32841164 0.35968965]\n",
      "[0.509565   0.49911004 0.49951732]\n",
      "[1.        0.5508036 0.5824255]\n",
      "Epoch 1406/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6815 - val_loss: 4.0319\n",
      "Epoch 1407/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5321 - val_loss: 4.4044\n",
      "Epoch 1408/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8425 - val_loss: 4.0124\n",
      "[0.4254799  0.32935196 0.35606205]\n",
      "[0.5096873  0.49898487 0.49931258]\n",
      "[1.         0.56230587 0.56612706]\n",
      "Epoch 1409/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6868 - val_loss: 4.0785\n",
      "Epoch 1410/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6519 - val_loss: 4.1474\n",
      "Epoch 1411/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6743 - val_loss: 4.0570\n",
      "[0.48681608 0.33377063 0.36537802]\n",
      "[0.5096041  0.4990951  0.49945945]\n",
      "[1.        0.5525319 0.5812307]\n",
      "Epoch 1412/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8842 - val_loss: 4.3555\n",
      "Epoch 1413/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8636 - val_loss: 6.1043\n",
      "Epoch 1414/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6120 - val_loss: 4.2804\n",
      "[0.50320035 0.32474768 0.3503115 ]\n",
      "[0.5136559  0.49852562 0.49892214]\n",
      "[1.        0.5713872 0.5947463]\n",
      "Epoch 1415/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7878 - val_loss: 4.3302\n",
      "Epoch 1416/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7655 - val_loss: 4.3501\n",
      "Epoch 1417/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7750 - val_loss: 3.9617\n",
      "[0.5008624  0.31966823 0.3503727 ]\n",
      "[0.5115862  0.49869645 0.49876016]\n",
      "[1.         0.58120465 0.5386412 ]\n",
      "Epoch 1418/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7444 - val_loss: 4.0479\n",
      "Epoch 1419/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8269 - val_loss: 3.6217\n",
      "Epoch 1420/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7716 - val_loss: 4.3304\n",
      "[0.5033868  0.31857297 0.35580432]\n",
      "[0.5142213  0.49864244 0.49883625]\n",
      "[1.         0.5774654  0.53998345]\n",
      "Epoch 1421/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9553 - val_loss: 6.1407\n",
      "Epoch 1422/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.8865 - val_loss: 6.1977\n",
      "Epoch 1423/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.9470 - val_loss: 4.4389\n",
      "[0.5054311  0.32882628 0.3499335 ]\n",
      "[0.5165596  0.49877194 0.49881434]\n",
      "[1.         0.58231133 0.52801657]\n",
      "Epoch 1424/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7821 - val_loss: 6.1558\n",
      "Epoch 1425/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8102 - val_loss: 6.2267\n",
      "Epoch 1426/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7287 - val_loss: 4.0009\n",
      "[0.5010359  0.3278455  0.34108925]\n",
      "[0.5122711  0.49873707 0.49901658]\n",
      "[1.         0.58183634 0.5314606 ]\n",
      "Epoch 1427/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8739 - val_loss: 4.1705\n",
      "Epoch 1428/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6634 - val_loss: 6.2154\n",
      "Epoch 1429/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6394 - val_loss: 4.0194\n",
      "[0.50102955 0.32273    0.34751958]\n",
      "[0.51217026 0.4986725  0.49894777]\n",
      "[1.         0.58517313 0.52725905]\n",
      "Epoch 1430/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8454 - val_loss: 3.8987\n",
      "Epoch 1431/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7476 - val_loss: 4.4895\n",
      "Epoch 1432/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8289 - val_loss: 4.0076\n",
      "[0.50086486 0.32999712 0.34922916]\n",
      "[0.5118637  0.49880603 0.49893203]\n",
      "[1.         0.58885276 0.53822243]\n",
      "Epoch 1433/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5562 - val_loss: 4.0683\n",
      "Epoch 1434/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7928 - val_loss: 6.1265\n",
      "Epoch 1435/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9024 - val_loss: 4.2157\n",
      "[0.5024175  0.32850823 0.34287205]\n",
      "[0.51309973 0.49890384 0.4990077 ]\n",
      "[1.         0.59447753 0.5344726 ]\n",
      "Epoch 1436/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9136 - val_loss: 4.5194\n",
      "Epoch 1437/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9294 - val_loss: 6.1791\n",
      "Epoch 1438/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8505 - val_loss: 6.1266\n",
      "[0.49748284 0.33950114 0.35173064]\n",
      "[0.50704426 0.49911258 0.49928218]\n",
      "[1.        0.5904701 0.5373499]\n",
      "Epoch 1439/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8382 - val_loss: 6.1445\n",
      "Epoch 1440/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8710 - val_loss: 4.2045\n",
      "Epoch 1441/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8126 - val_loss: 4.1105\n",
      "[0.50091004 0.34511417 0.3711151 ]\n",
      "[0.50982255 0.49885693 0.4995016 ]\n",
      "[1.        0.5857874 0.5564239]\n",
      "Epoch 1442/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6313 - val_loss: 6.1658\n",
      "Epoch 1443/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9314 - val_loss: 4.1172\n",
      "Epoch 1444/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6886 - val_loss: 6.1580\n",
      "[0.4982452  0.35396922 0.34606606]\n",
      "[0.50778896 0.4991598  0.499269  ]\n",
      "[1.        0.59432   0.5407136]\n",
      "Epoch 1445/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6573 - val_loss: 4.0616\n",
      "Epoch 1446/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.6366 - val_loss: 4.2100\n",
      "Epoch 1447/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6697 - val_loss: 4.2104\n",
      "[0.5019429  0.35503685 0.34763038]\n",
      "[0.5115694  0.49926442 0.49932343]\n",
      "[1.         0.5916206  0.53499204]\n",
      "Epoch 1448/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6788 - val_loss: 3.8769\n",
      "Epoch 1449/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8429 - val_loss: 3.8463\n",
      "Epoch 1450/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6004 - val_loss: 4.3047\n",
      "[0.50259894 0.33968082 0.36140335]\n",
      "[0.5124934  0.49905798 0.49936777]\n",
      "[1.         0.5853565  0.54844725]\n",
      "Epoch 1451/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8650 - val_loss: 6.2093\n",
      "Epoch 1452/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0357 - val_loss: 5.9188\n",
      "Epoch 1453/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6420 - val_loss: 4.3166\n",
      "[0.42300987 0.32351333 0.3482527 ]\n",
      "[0.5161379  0.49860257 0.4989212 ]\n",
      "[1.         0.59263784 0.5599295 ]\n",
      "Epoch 1454/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6052 - val_loss: 4.4811\n",
      "Epoch 1455/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7327 - val_loss: 5.7157\n",
      "Epoch 1456/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6666 - val_loss: 4.2377\n",
      "[0.48781875 0.2604558  0.3585831 ]\n",
      "[0.5114921  0.49881834 0.49949244]\n",
      "[1.         0.57950914 0.5963739 ]\n",
      "Epoch 1457/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7684 - val_loss: 6.1761\n",
      "Epoch 1458/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9074 - val_loss: 4.1010\n",
      "Epoch 1459/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7484 - val_loss: 4.2623\n",
      "[0.01189995 0.23865706 0.3428245 ]\n",
      "[0.50987715 0.4985639  0.49958298]\n",
      "[1.         0.57283306 0.7270123 ]\n",
      "Epoch 1460/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6260 - val_loss: 4.5344\n",
      "Epoch 1461/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7981 - val_loss: 6.1379\n",
      "Epoch 1462/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7909 - val_loss: 3.9123\n",
      "[0.48205638 0.2499831  0.3033619 ]\n",
      "[0.50895923 0.49868065 0.49957088]\n",
      "[1.        0.5706256 0.6849633]\n",
      "Epoch 1463/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8168 - val_loss: 5.5162\n",
      "Epoch 1464/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9611 - val_loss: 6.1453\n",
      "Epoch 1465/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7899 - val_loss: 4.0027\n",
      "[0.23956802 0.23786023 0.3579338 ]\n",
      "[0.5096045  0.49858716 0.49959   ]\n",
      "[1.         0.56815827 0.6156658 ]\n",
      "Epoch 1466/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7811 - val_loss: 5.9855\n",
      "Epoch 1467/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7814 - val_loss: 4.2470\n",
      "Epoch 1468/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7029 - val_loss: 4.2855\n",
      "[0.11297408 0.22341669 0.35354006]\n",
      "[0.5114734  0.4982129  0.49955273]\n",
      "[1.         0.56304365 0.6185308 ]\n",
      "Epoch 1469/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.9269 - val_loss: 4.1032\n",
      "Epoch 1470/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6752 - val_loss: 4.0907\n",
      "Epoch 1471/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6916 - val_loss: 3.9091\n",
      "[0.01320723 0.22726387 0.37044665]\n",
      "[0.50989616 0.49833417 0.49951464]\n",
      "[1.        0.5642431 0.6122448]\n",
      "Epoch 1472/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9202 - val_loss: 3.8945\n",
      "Epoch 1473/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6857 - val_loss: 6.1406\n",
      "Epoch 1474/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8212 - val_loss: 6.0614\n",
      "[0.01059619 0.22353473 0.35952067]\n",
      "[0.5057974  0.4981246  0.49955994]\n",
      "[1.        0.5720944 0.6104332]\n",
      "Epoch 1475/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8481 - val_loss: 4.3102\n",
      "Epoch 1476/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7793 - val_loss: 4.0529\n",
      "Epoch 1477/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6658 - val_loss: 4.2759\n",
      "[0.49181134 0.26904172 0.3644301 ]\n",
      "[0.5115982  0.49870154 0.4994849 ]\n",
      "[1.        0.5775495 0.5671332]\n",
      "Epoch 1478/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9145 - val_loss: 4.2922\n",
      "Epoch 1479/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6041 - val_loss: 4.4633\n",
      "Epoch 1480/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7331 - val_loss: 6.1608\n",
      "[0.49705133 0.23375079 0.36122167]\n",
      "[0.5079515  0.49895978 0.49944535]\n",
      "[1.         0.58909774 0.58221525]\n",
      "Epoch 1481/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8202 - val_loss: 4.5269\n",
      "Epoch 1482/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6676 - val_loss: 4.4454\n",
      "Epoch 1483/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7249 - val_loss: 4.3952\n",
      "[0.5024135  0.30947548 0.38279465]\n",
      "[0.5113439  0.49938276 0.49955088]\n",
      "[1.         0.5917924  0.56566703]\n",
      "Epoch 1484/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8584 - val_loss: 6.1134\n",
      "Epoch 1485/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6229 - val_loss: 4.3000\n",
      "Epoch 1486/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7435 - val_loss: 4.4117\n",
      "[0.5033531  0.32639724 0.373079  ]\n",
      "[0.5124041  0.49950764 0.49943423]\n",
      "[1.        0.5968541 0.5411362]\n",
      "Epoch 1487/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8323 - val_loss: 4.4037\n",
      "Epoch 1488/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7167 - val_loss: 4.2499\n",
      "Epoch 1489/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7215 - val_loss: 4.3842\n",
      "[0.50278145 0.3755924  0.3834148 ]\n",
      "[0.5112486  0.49968767 0.4995009 ]\n",
      "[1.        0.5989103 0.541088 ]\n",
      "Epoch 1490/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7074 - val_loss: 6.1811\n",
      "Epoch 1491/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5175 - val_loss: 5.7623\n",
      "Epoch 1492/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.6431 - val_loss: 4.3196\n",
      "[0.50270045 0.42191836 0.36648846]\n",
      "[0.5113679  0.49988982 0.49942136]\n",
      "[1.         0.60544246 0.523989  ]\n",
      "Epoch 1493/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.6780 - val_loss: 4.4186\n",
      "Epoch 1494/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7087 - val_loss: 3.8652\n",
      "Epoch 1495/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7096 - val_loss: 4.1539\n",
      "[0.50141484 0.37767935 0.3647222 ]\n",
      "[0.5111375  0.49980548 0.49901417]\n",
      "[1.         0.60333884 0.54138887]\n",
      "Epoch 1496/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9002 - val_loss: 6.1572\n",
      "Epoch 1497/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6548 - val_loss: 6.0427\n",
      "Epoch 1498/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8579 - val_loss: 4.4992\n",
      "[0.5051762  0.34496468 0.3607074 ]\n",
      "[0.5151902  0.49981844 0.49894246]\n",
      "[1.        0.6005879 0.5710354]\n",
      "Epoch 1499/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6097 - val_loss: 4.4387\n",
      "Epoch 1500/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9490 - val_loss: 6.0389\n",
      "Epoch 1501/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7703 - val_loss: 6.1112\n",
      "[0.4995463  0.32887352 0.34499222]\n",
      "[0.51121557 0.49941048 0.49882692]\n",
      "[1.         0.59397596 0.59395576]\n",
      "Epoch 1502/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5146 - val_loss: 4.4750\n",
      "Epoch 1503/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8652 - val_loss: 3.8862\n",
      "Epoch 1504/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7334 - val_loss: 4.1170\n",
      "[0.50112534 0.3279593  0.27374452]\n",
      "[0.5121831  0.49947178 0.49888584]\n",
      "[1.         0.59526306 0.5892517 ]\n",
      "Epoch 1505/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7186 - val_loss: 4.5077\n",
      "Epoch 1506/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7800 - val_loss: 6.1408\n",
      "Epoch 1507/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7603 - val_loss: 4.2922\n",
      "[0.5019542  0.33974957 0.32602823]\n",
      "[0.5122901  0.49956134 0.49914935]\n",
      "[1.         0.6090786  0.61190826]\n",
      "Epoch 1508/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7696 - val_loss: 6.0173\n",
      "Epoch 1509/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8663 - val_loss: 6.1886\n",
      "Epoch 1510/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6388 - val_loss: 6.1604\n",
      "[0.49733075 0.358663   0.28626364]\n",
      "[0.50753075 0.49969995 0.49908134]\n",
      "[1.         0.59915423 0.5885624 ]\n",
      "Epoch 1511/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7385 - val_loss: 3.9488\n",
      "Epoch 1512/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7251 - val_loss: 4.1917\n",
      "Epoch 1513/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7413 - val_loss: 4.0714\n",
      "[0.5009424  0.33436936 0.31153747]\n",
      "[0.51104736 0.49970308 0.4991641 ]\n",
      "[1.        0.6046431 0.5978499]\n",
      "Epoch 1514/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8995 - val_loss: 4.0934\n",
      "Epoch 1515/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7707 - val_loss: 5.9720\n",
      "Epoch 1516/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.6594 - val_loss: 6.1064\n",
      "[0.49709406 0.34966403 0.32129186]\n",
      "[0.5071177  0.499894   0.49910355]\n",
      "[1.        0.6014529 0.5921457]\n",
      "Epoch 1517/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6893 - val_loss: 4.3382\n",
      "Epoch 1518/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6912 - val_loss: 4.0909\n",
      "Epoch 1519/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6495 - val_loss: 3.8175\n",
      "[0.495879   0.3489365  0.33419448]\n",
      "[0.50998974 0.49994436 0.4990978 ]\n",
      "[1.         0.6110459  0.59252584]\n",
      "Epoch 1520/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8699 - val_loss: 3.6120\n",
      "Epoch 1521/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9963 - val_loss: 3.7628\n",
      "Epoch 1522/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6593 - val_loss: 6.0984\n",
      "[0.4849122  0.3339805  0.30984962]\n",
      "[0.5068326  0.49995795 0.4992603 ]\n",
      "[1.         0.60338306 0.5898053 ]\n",
      "Epoch 1523/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7947 - val_loss: 4.1754\n",
      "Epoch 1524/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7541 - val_loss: 6.0859\n",
      "Epoch 1525/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8520 - val_loss: 4.1440\n",
      "[0.50081384 0.34168428 0.3129299 ]\n",
      "[0.5091176  0.49986753 0.4993325 ]\n",
      "[1.         0.60233945 0.5831777 ]\n",
      "Epoch 1526/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6761 - val_loss: 4.3442\n",
      "Epoch 1527/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8521 - val_loss: 3.3878\n",
      "Epoch 1528/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7563 - val_loss: 6.0944\n",
      "[0.49721348 0.360442   0.34750748]\n",
      "[0.50550234 0.49989265 0.49936   ]\n",
      "[1.        0.6026979 0.5756428]\n",
      "Epoch 1529/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9704 - val_loss: 4.0694\n",
      "Epoch 1530/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7127 - val_loss: 4.0060\n",
      "Epoch 1531/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8137 - val_loss: 4.2938\n",
      "[0.5019526  0.36993152 0.32692772]\n",
      "[0.50958556 0.49992794 0.49948114]\n",
      "[1.        0.5991328 0.5767943]\n",
      "Epoch 1532/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8245 - val_loss: 4.5922\n",
      "Epoch 1533/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8499 - val_loss: 5.8165\n",
      "Epoch 1534/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7655 - val_loss: 4.3659\n",
      "[0.50321674 0.395375   0.3570779 ]\n",
      "[0.5115027  0.499957   0.49940354]\n",
      "[1.         0.60405755 0.530293  ]\n",
      "Epoch 1535/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8144 - val_loss: 3.5355\n",
      "Epoch 1536/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6952 - val_loss: 4.4449\n",
      "Epoch 1537/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7414 - val_loss: 5.7463\n",
      "[0.49963102 0.3672995  0.3319421 ]\n",
      "[0.50829744 0.49981037 0.49927193]\n",
      "[1.         0.6018373  0.54837865]\n",
      "Epoch 1538/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7845 - val_loss: 3.9123\n",
      "Epoch 1539/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.8690 - val_loss: 4.1235\n",
      "Epoch 1540/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7823 - val_loss: 4.4313\n",
      "[0.5050102  0.35679823 0.3058149 ]\n",
      "[0.5143298  0.4996965  0.49910006]\n",
      "[1.         0.60170203 0.55748534]\n",
      "Epoch 1541/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9112 - val_loss: 4.2177\n",
      "Epoch 1542/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7327 - val_loss: 4.1544\n",
      "Epoch 1543/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5768 - val_loss: 4.0885\n",
      "[0.5006982  0.3783297  0.31573987]\n",
      "[0.5097941  0.49967644 0.49915907]\n",
      "[1.         0.6017751  0.57398874]\n",
      "Epoch 1544/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6816 - val_loss: 6.1385\n",
      "Epoch 1545/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7490 - val_loss: 4.2286\n",
      "Epoch 1546/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6685 - val_loss: 4.4504\n",
      "[0.5046074  0.39992273 0.34783995]\n",
      "[0.5134383  0.4997586  0.49930307]\n",
      "[1.         0.60390544 0.5387345 ]\n",
      "Epoch 1547/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7386 - val_loss: 5.9120\n",
      "Epoch 1548/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6421 - val_loss: 3.9568\n",
      "Epoch 1549/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6919 - val_loss: 4.1812\n",
      "[0.5016123  0.37641522 0.36057493]\n",
      "[0.5110826  0.49972743 0.4991631 ]\n",
      "[1.         0.6039264  0.54488224]\n",
      "Epoch 1550/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8265 - val_loss: 4.1551\n",
      "Epoch 1551/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7177 - val_loss: 4.0002\n",
      "Epoch 1552/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6130 - val_loss: 4.4844\n",
      "[0.50483173 0.38230607 0.3708703 ]\n",
      "[0.5134419  0.4997692  0.49936143]\n",
      "[1.         0.6045995  0.55044204]\n",
      "Epoch 1553/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9091 - val_loss: 4.2648\n",
      "Epoch 1554/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6767 - val_loss: 5.9154\n",
      "Epoch 1555/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7201 - val_loss: 6.0708\n",
      "[0.4990013 0.3677234 0.3553025]\n",
      "[0.5081626  0.49971324 0.49926147]\n",
      "[1.         0.60576195 0.54729587]\n",
      "Epoch 1556/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7653 - val_loss: 3.2672\n",
      "Epoch 1557/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8355 - val_loss: 6.1016\n",
      "Epoch 1558/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7140 - val_loss: 4.2443\n",
      "[0.50176907 0.35691583 0.3469439 ]\n",
      "[0.5134614  0.49953642 0.49873677]\n",
      "[1.        0.6052798 0.56257  ]\n",
      "Epoch 1559/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8058 - val_loss: 3.9767\n",
      "Epoch 1560/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7400 - val_loss: 3.6027\n",
      "Epoch 1561/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6227 - val_loss: 4.4683\n",
      "[0.5047438  0.3594923  0.34425056]\n",
      "[0.5159361  0.49933633 0.49892864]\n",
      "[1.         0.60389256 0.56150705]\n",
      "Epoch 1562/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7770 - val_loss: 4.4077\n",
      "Epoch 1563/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7899 - val_loss: 5.1616\n",
      "Epoch 1564/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7842 - val_loss: 4.2749\n",
      "[0.50214666 0.372972   0.34090936]\n",
      "[0.5139097  0.4992853  0.49882433]\n",
      "[1.         0.60450333 0.5521042 ]\n",
      "Epoch 1565/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8498 - val_loss: 4.6007\n",
      "Epoch 1566/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6577 - val_loss: 4.2810\n",
      "Epoch 1567/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7241 - val_loss: 4.3446\n",
      "[0.5022036  0.36304545 0.342274  ]\n",
      "[0.51450926 0.49939153 0.49874067]\n",
      "[1.         0.60925627 0.55574703]\n",
      "Epoch 1568/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8135 - val_loss: 4.2804\n",
      "Epoch 1569/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7011 - val_loss: 4.3828\n",
      "Epoch 1570/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9299 - val_loss: 6.1975\n",
      "[0.49794763 0.36507612 0.32383853]\n",
      "[0.5110113  0.49965975 0.49833712]\n",
      "[1.         0.61514074 0.5523115 ]\n",
      "Epoch 1571/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8273 - val_loss: 2.8248\n",
      "Epoch 1572/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6474 - val_loss: 6.2648\n",
      "Epoch 1573/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8468 - val_loss: 5.7745\n",
      "[0.49952367 0.36127672 0.3062516 ]\n",
      "[0.5144604  0.49879178 0.49692282]\n",
      "[1.         0.6222515  0.54778135]\n",
      "Epoch 1574/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8440 - val_loss: 6.2233\n",
      "Epoch 1575/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7851 - val_loss: 4.2096\n",
      "Epoch 1576/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8625 - val_loss: 6.0862\n",
      "[0.49908507 0.36002702 0.29823554]\n",
      "[0.5117285  0.49982935 0.49823537]\n",
      "[1.         0.63631916 0.54997563]\n",
      "Epoch 1577/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7569 - val_loss: 4.0362\n",
      "Epoch 1578/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9603 - val_loss: 4.3553\n",
      "Epoch 1579/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6536 - val_loss: 6.1602\n",
      "[0.49877214 0.36437514 0.30740988]\n",
      "[0.51102465 0.49975672 0.4984525 ]\n",
      "[1.         0.61895144 0.5468101 ]\n",
      "Epoch 1580/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7479 - val_loss: 4.2847\n",
      "Epoch 1581/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7023 - val_loss: 6.1191\n",
      "Epoch 1582/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0791 - val_loss: 4.2828\n",
      "[0.5019084 0.3641225 0.3222838]\n",
      "[0.5143159  0.49959743 0.49846947]\n",
      "[1.         0.64350736 0.5504557 ]\n",
      "Epoch 1583/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5860 - val_loss: 4.2409\n",
      "Epoch 1584/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6834 - val_loss: 4.1712\n",
      "Epoch 1585/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9092 - val_loss: 4.4110\n",
      "[0.50382996 0.3565554  0.32409582]\n",
      "[0.5163763  0.499716   0.49846107]\n",
      "[1.         0.65425014 0.5455854 ]\n",
      "Epoch 1586/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7598 - val_loss: 4.3674\n",
      "Epoch 1587/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8832 - val_loss: 5.7143\n",
      "Epoch 1588/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8395 - val_loss: 4.5461\n",
      "[0.50695205 0.38802448 0.32915896]\n",
      "[0.5185934  0.49994582 0.49862626]\n",
      "[1.         0.64063567 0.5259578 ]\n",
      "Epoch 1589/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7345 - val_loss: 4.1161\n",
      "Epoch 1590/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0407 - val_loss: 6.2442\n",
      "Epoch 1591/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9571 - val_loss: 3.9925\n",
      "[0.5002443  0.37372836 0.33179557]\n",
      "[0.5110152  0.4998473  0.49893507]\n",
      "[1.         0.63527673 0.5304149 ]\n",
      "Epoch 1592/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7007 - val_loss: 5.9852\n",
      "Epoch 1593/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8027 - val_loss: 6.2348\n",
      "Epoch 1594/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6450 - val_loss: 3.2391\n",
      "[0.49952134 0.3645749  0.3293543 ]\n",
      "[0.510491   0.49985516 0.49888796]\n",
      "[1.         0.6362088  0.53330684]\n",
      "Epoch 1595/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8345 - val_loss: 4.2843\n",
      "Epoch 1596/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7941 - val_loss: 5.8716\n",
      "Epoch 1597/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.5705 - val_loss: 4.5366\n",
      "[0.50672483 0.37751308 0.3547879 ]\n",
      "[0.51703614 0.4997833  0.49899805]\n",
      "[1.         0.60524243 0.5420858 ]\n",
      "Epoch 1598/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6305 - val_loss: 4.5129\n",
      "Epoch 1599/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7860 - val_loss: 4.1808\n",
      "Epoch 1600/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7718 - val_loss: 3.9974\n",
      "[0.49998108 0.36423045 0.36156455]\n",
      "[0.5119078  0.49985135 0.49864987]\n",
      "[1.         0.6065747  0.55551535]\n",
      "Epoch 1601/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.4476 - val_loss: 4.4743\n",
      "Epoch 1602/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7826 - val_loss: 3.7288\n",
      "Epoch 1603/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5213 - val_loss: 4.5226\n",
      "[0.48106557 0.3448599  0.3615775 ]\n",
      "[0.51752037 0.4998419  0.49860722]\n",
      "[1.         0.60686636 0.55566895]\n",
      "Epoch 1604/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6657 - val_loss: 6.1924\n",
      "Epoch 1605/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8445 - val_loss: 6.0390\n",
      "Epoch 1606/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7796 - val_loss: 4.0175\n",
      "[0.49081424 0.36441708 0.37037724]\n",
      "[0.51168054 0.4998742  0.49875796]\n",
      "[1.        0.6064121 0.541912 ]\n",
      "Epoch 1607/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9282 - val_loss: 6.1140\n",
      "Epoch 1608/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9239 - val_loss: 5.7522\n",
      "Epoch 1609/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.9012 - val_loss: 3.9365\n",
      "[0.50025177 0.36238098 0.36607403]\n",
      "[0.5114236  0.49996287 0.49870104]\n",
      "[1.         0.6065578  0.53772384]\n",
      "Epoch 1610/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 1.0377 - val_loss: 4.5213\n",
      "Epoch 1611/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6758 - val_loss: 3.7421\n",
      "Epoch 1612/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7649 - val_loss: 6.1659\n",
      "[0.49450132 0.3834413  0.36926988]\n",
      "[0.5076155  0.5000766  0.49870378]\n",
      "[1.         0.6061204  0.54426074]\n",
      "Epoch 1613/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8123 - val_loss: 4.0013\n",
      "Epoch 1614/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8584 - val_loss: 4.1357\n",
      "Epoch 1615/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7336 - val_loss: 6.2304\n",
      "[0.4742714 0.392659  0.3718345]\n",
      "[0.5089662  0.5002259  0.49857664]\n",
      "[1.        0.6069187 0.5383074]\n",
      "Epoch 1616/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7539 - val_loss: 6.1801\n",
      "Epoch 1617/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8583 - val_loss: 6.1992\n",
      "Epoch 1618/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7629 - val_loss: 4.1020\n",
      "[0.5008887  0.41118872 0.37180102]\n",
      "[0.51145697 0.5002858  0.4987473 ]\n",
      "[1.         0.60730165 0.52459705]\n",
      "Epoch 1619/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7258 - val_loss: 4.3342\n",
      "Epoch 1620/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7912 - val_loss: 4.0231\n",
      "Epoch 1621/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8059 - val_loss: 4.1023\n",
      "[0.49865597 0.41611278 0.3663023 ]\n",
      "[0.51174515 0.50026685 0.49879757]\n",
      "[1.        0.6073556 0.5264175]\n",
      "Epoch 1622/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8176 - val_loss: 4.1235\n",
      "Epoch 1623/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7897 - val_loss: 3.4582\n",
      "Epoch 1624/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6791 - val_loss: 5.6336\n",
      "[0.49959666 0.38984305 0.37533635]\n",
      "[0.50909835 0.5002026  0.4989203 ]\n",
      "[1.        0.6077411 0.5351409]\n",
      "Epoch 1625/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9291 - val_loss: 4.1862\n",
      "Epoch 1626/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8300 - val_loss: 3.9807\n",
      "Epoch 1627/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8186 - val_loss: 4.2272\n",
      "[0.46712366 0.37801665 0.37312388]\n",
      "[0.5134795  0.5001563  0.49866858]\n",
      "[1.         0.60734737 0.54651856]\n",
      "Epoch 1628/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8010 - val_loss: 6.1352\n",
      "Epoch 1629/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8137 - val_loss: 4.3422\n",
      "Epoch 1630/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7374 - val_loss: 3.6003\n",
      "[0.50007504 0.33656424 0.3714041 ]\n",
      "[0.5121297  0.50004643 0.49848622]\n",
      "[1.         0.61013806 0.556219  ]\n",
      "Epoch 1631/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8041 - val_loss: 3.5151\n",
      "Epoch 1632/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 1.0154 - val_loss: 3.4520\n",
      "Epoch 1633/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 1.0296 - val_loss: 4.4569\n",
      "[0.4958226 0.3792112 0.3596859]\n",
      "[0.5157072  0.50010127 0.4987694 ]\n",
      "[1.         0.6104003  0.53785175]\n",
      "Epoch 1634/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7498 - val_loss: 4.3595\n",
      "Epoch 1635/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7732 - val_loss: 4.4659\n",
      "Epoch 1636/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6632 - val_loss: 4.0650\n",
      "[0.5012777  0.40398163 0.36273158]\n",
      "[0.51158   0.5002324 0.4987487]\n",
      "[1.         0.60960746 0.5168507 ]\n",
      "Epoch 1637/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5763 - val_loss: 4.4167\n",
      "Epoch 1638/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8322 - val_loss: 4.5463\n",
      "Epoch 1639/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9214 - val_loss: 3.7421\n",
      "[0.50014    0.37520918 0.35126728]\n",
      "[0.51154673 0.5001776  0.49852893]\n",
      "[1.         0.60741043 0.5191196 ]\n",
      "Epoch 1640/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6767 - val_loss: 4.0573\n",
      "Epoch 1641/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7374 - val_loss: 4.2782\n",
      "Epoch 1642/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8611 - val_loss: 6.0193\n",
      "[0.49944758 0.3972172  0.3484196 ]\n",
      "[0.50974673 0.50020206 0.49887428]\n",
      "[1.         0.6119663  0.51107955]\n",
      "Epoch 1643/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6194 - val_loss: 6.1387\n",
      "Epoch 1644/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0220 - val_loss: 6.1535\n",
      "Epoch 1645/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8090 - val_loss: 4.4590\n",
      "[0.50546235 0.39673573 0.3474481 ]\n",
      "[0.5159051  0.5001593  0.49883103]\n",
      "[1.        0.6098563 0.5105212]\n",
      "Epoch 1646/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7653 - val_loss: 6.1743\n",
      "Epoch 1647/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7955 - val_loss: 6.0046\n",
      "Epoch 1648/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8570 - val_loss: 4.2337\n",
      "[0.502264   0.39905256 0.35280448]\n",
      "[0.5122898  0.50008893 0.49889952]\n",
      "[1.        0.6109311 0.5158135]\n",
      "Epoch 1649/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7206 - val_loss: 6.1440\n",
      "Epoch 1650/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9849 - val_loss: 4.4322\n",
      "Epoch 1651/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7677 - val_loss: 4.3966\n",
      "[0.5029986 0.4144193 0.3505765]\n",
      "[0.51348454 0.50025487 0.49908033]\n",
      "[1.         0.60702956 0.50139564]\n",
      "Epoch 1652/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9190 - val_loss: 4.2321\n",
      "Epoch 1653/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7067 - val_loss: 3.7780\n",
      "Epoch 1654/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7797 - val_loss: 6.0776\n",
      "[0.4990765  0.43310496 0.36666387]\n",
      "[0.50852954 0.5002688  0.49905688]\n",
      "[1.        0.6050121 0.5017564]\n",
      "Epoch 1655/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7884 - val_loss: 4.3997\n",
      "Epoch 1656/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.8414 - val_loss: 6.1645\n",
      "Epoch 1657/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6849 - val_loss: 4.2490\n",
      "[0.5026289  0.44317603 0.35866976]\n",
      "[0.51176804 0.5003377  0.49912298]\n",
      "[1.        0.5987842 0.5009976]\n",
      "Epoch 1658/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7878 - val_loss: 3.9634\n",
      "Epoch 1659/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8071 - val_loss: 4.1088\n",
      "Epoch 1660/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8131 - val_loss: 6.1807\n",
      "[0.4649723 0.4304828 0.3532042]\n",
      "[0.50855273 0.50036645 0.49878567]\n",
      "[1.         0.60241675 0.51645136]\n",
      "Epoch 1661/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6978 - val_loss: 4.3397\n",
      "Epoch 1662/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7794 - val_loss: 6.1564\n",
      "Epoch 1663/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8117 - val_loss: 4.2849\n",
      "[0.49052733 0.43676132 0.3577823 ]\n",
      "[0.51275337 0.50034046 0.49878544]\n",
      "[1.         0.5954754  0.51888114]\n",
      "Epoch 1664/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7051 - val_loss: 6.1156\n",
      "Epoch 1665/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7649 - val_loss: 5.7664\n",
      "Epoch 1666/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7652 - val_loss: 4.1615\n",
      "[0.50216717 0.4393566  0.34797224]\n",
      "[0.51202345 0.5004335  0.4987546 ]\n",
      "[1.         0.59999335 0.5268771 ]\n",
      "Epoch 1667/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5956 - val_loss: 4.2113\n",
      "Epoch 1668/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6759 - val_loss: 6.1176\n",
      "Epoch 1669/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7045 - val_loss: 4.0139\n",
      "[0.49694273 0.46296915 0.3584093 ]\n",
      "[0.50950104 0.500376   0.4990793 ]\n",
      "[1.         0.600986   0.53311765]\n",
      "Epoch 1670/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9480 - val_loss: 6.0678\n",
      "Epoch 1671/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7851 - val_loss: 4.3688\n",
      "Epoch 1672/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7556 - val_loss: 3.9276\n",
      "[0.5009998  0.45814985 0.34953925]\n",
      "[0.51094586 0.50044477 0.49873164]\n",
      "[1.         0.6060899  0.52877295]\n",
      "Epoch 1673/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7919 - val_loss: 3.8281\n",
      "Epoch 1674/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6541 - val_loss: 4.5360\n",
      "Epoch 1675/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9286 - val_loss: 4.2966\n",
      "[0.49925533 0.45279878 0.3451059 ]\n",
      "[0.5124779  0.50037897 0.49900255]\n",
      "[1.         0.62058103 0.53616613]\n",
      "Epoch 1676/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5708 - val_loss: 4.2600\n",
      "Epoch 1677/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8096 - val_loss: 4.4718\n",
      "Epoch 1678/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9100 - val_loss: 6.1591\n",
      "[0.4985726 0.4428547 0.3531916]\n",
      "[0.50716615 0.500226   0.49934074]\n",
      "[1.         0.62187785 0.5208625 ]\n",
      "Epoch 1679/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.8929 - val_loss: 4.0964\n",
      "Epoch 1680/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.8012 - val_loss: 4.1397\n",
      "Epoch 1681/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8133 - val_loss: 4.2548\n",
      "[0.5026874  0.45546073 0.36548105]\n",
      "[0.51180685 0.5002833  0.49922493]\n",
      "[1.         0.61756814 0.5224686 ]\n",
      "Epoch 1682/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7984 - val_loss: 4.2750\n",
      "Epoch 1683/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5420 - val_loss: 4.3219\n",
      "Epoch 1684/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6682 - val_loss: 4.1594\n",
      "[0.5016792  0.46001753 0.37226635]\n",
      "[0.5103254  0.5002964  0.49934125]\n",
      "[1.         0.62705255 0.5250542 ]\n",
      "Epoch 1685/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7489 - val_loss: 6.0905\n",
      "Epoch 1686/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7769 - val_loss: 3.7494\n",
      "Epoch 1687/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8066 - val_loss: 3.8513\n",
      "[0.5005346  0.44768694 0.3743676 ]\n",
      "[0.50962603 0.5003441  0.49923837]\n",
      "[1.         0.61756325 0.5079258 ]\n",
      "Epoch 1688/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6901 - val_loss: 4.0907\n",
      "Epoch 1689/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7516 - val_loss: 4.3806\n",
      "Epoch 1690/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7802 - val_loss: 3.9037\n",
      "[0.50091994 0.45624065 0.35748667]\n",
      "[0.50949776 0.5003062  0.49929366]\n",
      "[1.        0.6218141 0.5178835]\n",
      "Epoch 1691/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6236 - val_loss: 4.3019\n",
      "Epoch 1692/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7133 - val_loss: 3.8286\n",
      "Epoch 1693/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8603 - val_loss: 6.0695\n",
      "[0.49675274 0.4550519  0.3622472 ]\n",
      "[0.5053664  0.5002585  0.49933365]\n",
      "[1.         0.6360837  0.51235914]\n",
      "Epoch 1694/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6913 - val_loss: 3.7698\n",
      "Epoch 1695/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7035 - val_loss: 4.1992\n",
      "Epoch 1696/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8989 - val_loss: 6.1262\n",
      "[0.49744454 0.46381173 0.37592095]\n",
      "[0.5055878  0.50029296 0.49942136]\n",
      "[1.        0.6392908 0.5120995]\n",
      "Epoch 1697/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8992 - val_loss: 4.1887\n",
      "Epoch 1698/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7701 - val_loss: 5.9954\n",
      "Epoch 1699/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7748 - val_loss: 4.1395\n",
      "[0.5020481  0.4573549  0.37284964]\n",
      "[0.5104251  0.5003539  0.49936017]\n",
      "[1.         0.6563506  0.53364784]\n",
      "Epoch 1700/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7073 - val_loss: 6.1470\n",
      "Epoch 1701/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7954 - val_loss: 4.3548\n",
      "Epoch 1702/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6030 - val_loss: 3.6215\n",
      "[0.5001047  0.46608433 0.36808217]\n",
      "[0.50844336 0.5004489  0.49930996]\n",
      "[1.        0.6663277 0.5570779]\n",
      "Epoch 1703/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7496 - val_loss: 3.8453\n",
      "Epoch 1704/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8247 - val_loss: 4.2390\n",
      "Epoch 1705/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7767 - val_loss: 6.1216\n",
      "[0.49712443 0.45935643 0.36675394]\n",
      "[0.5055076  0.50049263 0.49926707]\n",
      "[1.         0.65876627 0.56118196]\n",
      "Epoch 1706/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7506 - val_loss: 4.5065\n",
      "Epoch 1707/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7324 - val_loss: 6.1600\n",
      "Epoch 1708/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7290 - val_loss: 4.2546\n",
      "[0.5024379  0.46969804 0.3727585 ]\n",
      "[0.5105041  0.5004175  0.49939805]\n",
      "[1.        0.6701067 0.5555381]\n",
      "Epoch 1709/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8716 - val_loss: 3.8809\n",
      "Epoch 1710/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6714 - val_loss: 6.0218\n",
      "Epoch 1711/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6916 - val_loss: 5.9828\n",
      "[0.49342483 0.46459645 0.37360045]\n",
      "[0.50141084 0.5004016  0.49945918]\n",
      "[1.         0.6686893  0.53776383]\n",
      "Epoch 1712/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0916 - val_loss: 6.1093\n",
      "Epoch 1713/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7601 - val_loss: 3.8685\n",
      "Epoch 1714/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9672 - val_loss: 6.1276\n",
      "[0.49743238 0.4810724  0.37945634]\n",
      "[0.5056281  0.5003555  0.49948955]\n",
      "[1.        0.6711873 0.5549791]\n",
      "Epoch 1715/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9856 - val_loss: 6.1383\n",
      "Epoch 1716/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7259 - val_loss: 3.4274\n",
      "Epoch 1717/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6900 - val_loss: 6.1067\n",
      "[0.49750707 0.4810864  0.38068578]\n",
      "[0.50604117 0.5003198  0.49947667]\n",
      "[1.         0.663545   0.54079944]\n",
      "Epoch 1718/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7337 - val_loss: 6.0135\n",
      "Epoch 1719/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6160 - val_loss: 3.9354\n",
      "Epoch 1720/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6771 - val_loss: 3.8026\n",
      "[0.50013787 0.4784159  0.3762003 ]\n",
      "[0.50806266 0.5002939  0.49952504]\n",
      "[1.         0.6639929  0.51013565]\n",
      "Epoch 1721/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9320 - val_loss: 4.5482\n",
      "Epoch 1722/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7046 - val_loss: 3.7828\n",
      "Epoch 1723/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7982 - val_loss: 5.9753\n",
      "[0.49736702 0.46022445 0.38932687]\n",
      "[0.5066377  0.5002907  0.49951515]\n",
      "[1.        0.6745137 0.5441101]\n",
      "Epoch 1724/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7483 - val_loss: 3.8368\n",
      "Epoch 1725/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8571 - val_loss: 3.7352\n",
      "Epoch 1726/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.5008 - val_loss: 4.0944\n",
      "[0.49770012 0.47549492 0.38877028]\n",
      "[0.5077693  0.5002496  0.49957356]\n",
      "[1.         0.66868687 0.5441393 ]\n",
      "Epoch 1727/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7416 - val_loss: 4.3854\n",
      "Epoch 1728/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7848 - val_loss: 6.0973\n",
      "Epoch 1729/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8209 - val_loss: 4.2720\n",
      "[0.50255424 0.4766254  0.39186412]\n",
      "[0.5096569  0.50029665 0.49956483]\n",
      "[1.        0.677611  0.5457923]\n",
      "Epoch 1730/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8139 - val_loss: 4.4362\n",
      "Epoch 1731/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8057 - val_loss: 5.9633\n",
      "Epoch 1732/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8217 - val_loss: 6.1186\n",
      "[0.49490654 0.45509824 0.36349863]\n",
      "[0.5056605 0.5005184 0.4994396]\n",
      "[1.        0.6941571 0.5767102]\n",
      "Epoch 1733/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6349 - val_loss: 3.6349\n",
      "Epoch 1734/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7349 - val_loss: 4.3449\n",
      "Epoch 1735/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9629 - val_loss: 4.3438\n",
      "[0.4978287 0.4303785 0.2963823]\n",
      "[0.51230866 0.5007534  0.49922442]\n",
      "[1.        0.6949438 0.5816226]\n",
      "Epoch 1736/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7754 - val_loss: 6.1049\n",
      "Epoch 1737/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8347 - val_loss: 6.1670\n",
      "Epoch 1738/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8821 - val_loss: 6.1273\n",
      "[0.49305233 0.4435996  0.31693497]\n",
      "[0.50520897 0.50062835 0.4993752 ]\n",
      "[1.         0.69809985 0.5839313 ]\n",
      "Epoch 1739/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8500 - val_loss: 4.5701\n",
      "Epoch 1740/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9948 - val_loss: 4.2155\n",
      "Epoch 1741/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6154 - val_loss: 4.5774\n",
      "[0.507186   0.43962815 0.32321805]\n",
      "[0.515583   0.5007152  0.49933589]\n",
      "[1.         0.693261   0.58940846]\n",
      "Epoch 1742/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7476 - val_loss: 4.0275\n",
      "Epoch 1743/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7501 - val_loss: 3.5583\n",
      "Epoch 1744/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.5602 - val_loss: 3.5302\n",
      "[0.49997532 0.44531265 0.29714203]\n",
      "[0.50863993 0.5007924  0.49928242]\n",
      "[1.         0.69542414 0.59590757]\n",
      "Epoch 1745/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7997 - val_loss: 4.3016\n",
      "Epoch 1746/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8834 - val_loss: 5.7129\n",
      "Epoch 1747/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9234 - val_loss: 5.3390\n",
      "[0.49989685 0.44466314 0.3001029 ]\n",
      "[0.5092255  0.5007193  0.49925774]\n",
      "[1.         0.698387   0.58959687]\n",
      "Epoch 1748/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7325 - val_loss: 6.2052\n",
      "Epoch 1749/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8438 - val_loss: 4.2426\n",
      "Epoch 1750/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8176 - val_loss: 3.6824\n",
      "[0.5001476  0.45316648 0.33792144]\n",
      "[0.50888324 0.5006963  0.4993588 ]\n",
      "[1.         0.70384383 0.5819967 ]\n",
      "Epoch 1751/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5658 - val_loss: 3.8016\n",
      "Epoch 1752/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7965 - val_loss: 4.1594\n",
      "Epoch 1753/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7213 - val_loss: 4.4058\n",
      "[0.5046341  0.45943326 0.37148845]\n",
      "[0.5124371  0.50047463 0.499548  ]\n",
      "[1.         0.69609594 0.5847664 ]\n",
      "Epoch 1754/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8202 - val_loss: 4.3202\n",
      "Epoch 1755/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7779 - val_loss: 4.4380\n",
      "Epoch 1756/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6478 - val_loss: 4.2391\n",
      "[0.5023795  0.47872612 0.37506735]\n",
      "[0.5097248  0.50039613 0.49958318]\n",
      "[1.        0.6787037 0.5636075]\n",
      "Epoch 1757/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7011 - val_loss: 4.4382\n",
      "Epoch 1758/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6822 - val_loss: 6.0859\n",
      "Epoch 1759/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8092 - val_loss: 4.3107\n",
      "[0.5032307  0.46401542 0.38716763]\n",
      "[0.5107957  0.50041354 0.49956548]\n",
      "[1.         0.68417424 0.58316314]\n",
      "Epoch 1760/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9018 - val_loss: 5.9834\n",
      "Epoch 1761/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0470 - val_loss: 5.9917\n",
      "Epoch 1762/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0012 - val_loss: 4.0427\n",
      "[0.50152904 0.471028   0.3871667 ]\n",
      "[0.5097216  0.50041723 0.49952883]\n",
      "[1.         0.68174046 0.57410455]\n",
      "Epoch 1763/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8786 - val_loss: 4.5614\n",
      "Epoch 1764/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6863 - val_loss: 4.3712\n",
      "Epoch 1765/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8029 - val_loss: 3.7387\n",
      "[0.50008875 0.45858765 0.39776742]\n",
      "[0.50721145 0.50042635 0.49960586]\n",
      "[1.         0.68162555 0.57389075]\n",
      "Epoch 1766/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0039 - val_loss: 4.3415\n",
      "Epoch 1767/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9037 - val_loss: 6.0170\n",
      "Epoch 1768/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8315 - val_loss: 4.5262\n",
      "[0.50698256 0.4755916  0.39612794]\n",
      "[0.5142557 0.5004215 0.4996423]\n",
      "[1.        0.6859532 0.5688672]\n",
      "Epoch 1769/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5943 - val_loss: 4.3194\n",
      "Epoch 1770/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6467 - val_loss: 4.1506\n",
      "Epoch 1771/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6796 - val_loss: 4.3460\n",
      "[0.50135434 0.47429642 0.40588564]\n",
      "[0.5105026  0.50035435 0.499697  ]\n",
      "[1.         0.6666111  0.56481045]\n",
      "Epoch 1772/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9584 - val_loss: 3.7829\n",
      "Epoch 1773/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.8581 - val_loss: 4.4266\n",
      "Epoch 1774/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9041 - val_loss: 4.1547\n",
      "[0.50147635 0.48961487 0.4171797 ]\n",
      "[0.5079587  0.5002913  0.49977845]\n",
      "[1.        0.6647389 0.5374044]\n",
      "Epoch 1775/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7054 - val_loss: 3.9666\n",
      "Epoch 1776/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8401 - val_loss: 4.4630\n",
      "Epoch 1777/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7953 - val_loss: 4.3222\n",
      "[0.50244975 0.48766327 0.42016554]\n",
      "[0.50844294 0.50021166 0.49981916]\n",
      "[1.        0.6610396 0.5584455]\n",
      "Epoch 1778/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7765 - val_loss: 4.0910\n",
      "Epoch 1779/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8239 - val_loss: 4.5776\n",
      "Epoch 1780/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8463 - val_loss: 4.2999\n",
      "[0.5027369  0.48394138 0.4235977 ]\n",
      "[0.5089117  0.5002469  0.49976447]\n",
      "[1.         0.66442835 0.5232681 ]\n",
      "Epoch 1781/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8028 - val_loss: 3.9238\n",
      "Epoch 1782/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8538 - val_loss: 4.2512\n",
      "Epoch 1783/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7764 - val_loss: 4.3025\n",
      "[0.5023348 0.4769427 0.4252668]\n",
      "[0.5083405 0.5002771 0.4997353]\n",
      "[1.        0.6644167 0.5008553]\n",
      "Epoch 1784/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6663 - val_loss: 6.1856\n",
      "Epoch 1785/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8851 - val_loss: 4.4223\n",
      "Epoch 1786/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9744 - val_loss: 4.2686\n",
      "[0.5024089  0.47626418 0.4276901 ]\n",
      "[0.5088244  0.50027704 0.49973187]\n",
      "[1.        0.6631407 0.5006263]\n",
      "Epoch 1787/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6663 - val_loss: 6.0686\n",
      "Epoch 1788/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6769 - val_loss: 3.8552\n",
      "Epoch 1789/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6267 - val_loss: 3.8625\n",
      "[0.4512187  0.48001885 0.4111017 ]\n",
      "[0.5070526  0.5003175  0.49966618]\n",
      "[1.         0.66313505 0.5280166 ]\n",
      "Epoch 1790/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7973 - val_loss: 4.3119\n",
      "Epoch 1791/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9159 - val_loss: 6.0271\n",
      "Epoch 1792/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9042 - val_loss: 6.1263\n",
      "[0.42085916 0.4595591  0.40582985]\n",
      "[0.506077   0.5003295  0.49958098]\n",
      "[1.         0.65964365 0.539661  ]\n",
      "Epoch 1793/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7563 - val_loss: 6.1713\n",
      "Epoch 1794/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8398 - val_loss: 4.4331\n",
      "Epoch 1795/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8170 - val_loss: 4.2119\n",
      "[0.42321834 0.46305585 0.40336087]\n",
      "[0.50993186 0.5002809  0.49964198]\n",
      "[1.         0.6609535  0.54794574]\n",
      "Epoch 1796/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7680 - val_loss: 4.1984\n",
      "Epoch 1797/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7596 - val_loss: 6.0118\n",
      "Epoch 1798/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9328 - val_loss: 3.6970\n",
      "[0.4493589  0.4499217  0.40384576]\n",
      "[0.50689894 0.50031215 0.49962726]\n",
      "[1.         0.65202355 0.52115864]\n",
      "Epoch 1799/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7821 - val_loss: 5.8194\n",
      "Epoch 1800/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8396 - val_loss: 6.1725\n",
      "Epoch 1801/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8030 - val_loss: 3.9596\n",
      "[0.33691904 0.44461346 0.4131303 ]\n",
      "[0.5082848  0.5003141  0.49954614]\n",
      "[1.         0.6311204  0.51074404]\n",
      "Epoch 1802/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8243 - val_loss: 6.1795\n",
      "Epoch 1803/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6382 - val_loss: 4.0226\n",
      "Epoch 1804/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8218 - val_loss: 6.1755\n",
      "[0.40187636 0.4391204  0.41385895]\n",
      "[0.50678074 0.5002596  0.499597  ]\n",
      "[1.       0.61207  0.501169]\n",
      "Epoch 1805/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6374 - val_loss: 6.1826\n",
      "Epoch 1806/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8532 - val_loss: 4.3522\n",
      "Epoch 1807/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7496 - val_loss: 5.9841\n",
      "[0.36681575 0.42070678 0.4152571 ]\n",
      "[0.5011309 0.5001993 0.4996505]\n",
      "[1.        0.6250004 0.5307379]\n",
      "Epoch 1808/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7660 - val_loss: 4.3437\n",
      "Epoch 1809/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7284 - val_loss: 4.3372\n",
      "Epoch 1810/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7963 - val_loss: 4.2817\n",
      "[0.3606647  0.42993236 0.4249763 ]\n",
      "[0.50897557 0.5001393  0.49970236]\n",
      "[1.        0.6169121 0.5301063]\n",
      "Epoch 1811/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9297 - val_loss: 4.0913\n",
      "Epoch 1812/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7919 - val_loss: 4.1699\n",
      "Epoch 1813/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7924 - val_loss: 6.1374\n",
      "[0.3909642 0.4346537 0.4090781]\n",
      "[0.504977   0.50021017 0.49963662]\n",
      "[1.        0.6274615 0.5189921]\n",
      "Epoch 1814/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8970 - val_loss: 4.5075\n",
      "Epoch 1815/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6746 - val_loss: 4.6019\n",
      "Epoch 1816/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8447 - val_loss: 4.5916\n",
      "[0.1095235  0.405144   0.40718132]\n",
      "[0.5141115  0.5002039  0.49961442]\n",
      "[1.        0.6106988 0.5262829]\n",
      "Epoch 1817/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8575 - val_loss: 6.0261\n",
      "Epoch 1818/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6552 - val_loss: 4.3276\n",
      "Epoch 1819/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7209 - val_loss: 6.0087\n",
      "[0.39393324 0.42597762 0.39513075]\n",
      "[0.50808096 0.50030553 0.49945682]\n",
      "[1.         0.60756034 0.506601  ]\n",
      "Epoch 1820/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.8166 - val_loss: 6.1781\n",
      "Epoch 1821/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8926 - val_loss: 6.0985\n",
      "Epoch 1822/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7210 - val_loss: 4.4156\n",
      "[0.4131616  0.44165143 0.4090163 ]\n",
      "[0.51292247 0.5002366  0.4995375 ]\n",
      "[1.        0.6046901 0.5007852]\n",
      "Epoch 1823/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7959 - val_loss: 4.0517\n",
      "Epoch 1824/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8378 - val_loss: 4.0036\n",
      "Epoch 1825/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8474 - val_loss: 5.9891\n",
      "[0.48246554 0.45553574 0.41433847]\n",
      "[0.50295895 0.5002222  0.49954492]\n",
      "[1.         0.6098996  0.50089556]\n",
      "Epoch 1826/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8296 - val_loss: 4.0958\n",
      "Epoch 1827/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6238 - val_loss: 6.1692\n",
      "Epoch 1828/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6781 - val_loss: 4.2390\n",
      "[0.44441572 0.47141868 0.41237164]\n",
      "[0.5104464  0.5001071  0.49964637]\n",
      "[1.         0.5823871  0.50361896]\n",
      "Epoch 1829/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7861 - val_loss: 4.4046\n",
      "Epoch 1830/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8539 - val_loss: 6.1139\n",
      "Epoch 1831/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9043 - val_loss: 5.9192\n",
      "[0.4964765 0.4844122 0.4163891]\n",
      "[0.50737387 0.5001254  0.49967015]\n",
      "[1.        0.5848627 0.504364 ]\n",
      "Epoch 1832/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7954 - val_loss: 4.0820\n",
      "Epoch 1833/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9117 - val_loss: 4.1197\n",
      "Epoch 1834/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9096 - val_loss: 3.8785\n",
      "[0.49610573 0.4860036  0.41220504]\n",
      "[0.50795984 0.5000796  0.49968222]\n",
      "[1.        0.5816435 0.5039518]\n",
      "Epoch 1835/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5656 - val_loss: 6.0881\n",
      "Epoch 1836/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9454 - val_loss: 4.5741\n",
      "Epoch 1837/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6444 - val_loss: 4.3118\n",
      "[0.4967399  0.4782151  0.41450328]\n",
      "[0.5096044  0.50004065 0.49972808]\n",
      "[1.         0.57808685 0.5077404 ]\n",
      "Epoch 1838/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7936 - val_loss: 4.0143\n",
      "Epoch 1839/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8373 - val_loss: 4.4399\n",
      "Epoch 1840/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9402 - val_loss: 4.5046\n",
      "[0.49768367 0.44512826 0.40380305]\n",
      "[0.51286995 0.49997777 0.49973723]\n",
      "[1.         0.5806291  0.51882017]\n",
      "Epoch 1841/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8009 - val_loss: 6.1209\n",
      "Epoch 1842/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6722 - val_loss: 4.1921\n",
      "Epoch 1843/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8636 - val_loss: 3.8133\n",
      "[0.4890496 0.4489    0.3952534]\n",
      "[0.50629807 0.49998748 0.49975663]\n",
      "[1.         0.59294695 0.51248837]\n",
      "Epoch 1844/10000\n",
      "2268/2268 [==============================] - 22s 9ms/step - loss: 0.8804 - val_loss: 4.4681\n",
      "Epoch 1845/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6266 - val_loss: 6.1392\n",
      "Epoch 1846/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6425 - val_loss: 4.4082\n",
      "[0.48490772 0.45499328 0.42729953]\n",
      "[0.51182187 0.5000232  0.49976775]\n",
      "[1.        0.5746929 0.517113 ]\n",
      "Epoch 1847/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8487 - val_loss: 3.8081\n",
      "Epoch 1848/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8710 - val_loss: 6.1434\n",
      "Epoch 1849/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8024 - val_loss: 6.1836\n",
      "[0.47244477 0.4503538  0.40120745]\n",
      "[0.5053507 0.5000761 0.499718 ]\n",
      "[1.        0.5892508 0.5259162]\n",
      "Epoch 1850/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6744 - val_loss: 3.9920\n",
      "Epoch 1851/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7628 - val_loss: 4.2343\n",
      "Epoch 1852/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5123 - val_loss: 4.4714\n",
      "[0.48926663 0.45348135 0.40084743]\n",
      "[0.5115746  0.50007945 0.49972275]\n",
      "[1.        0.5834923 0.5249191]\n",
      "Epoch 1853/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7728 - val_loss: 4.1044\n",
      "Epoch 1854/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8012 - val_loss: 6.1884\n",
      "Epoch 1855/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9621 - val_loss: 4.3222\n",
      "[0.5024916 0.4524126 0.3974912]\n",
      "[0.50987935 0.5000742  0.4997048 ]\n",
      "[1.         0.59480524 0.5240637 ]\n",
      "Epoch 1856/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8411 - val_loss: 4.3622\n",
      "Epoch 1857/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9072 - val_loss: 4.3691\n",
      "Epoch 1858/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9181 - val_loss: 4.1486\n",
      "[0.49678993 0.44522536 0.3912632 ]\n",
      "[0.5087443 0.5001061 0.4996443]\n",
      "[1.         0.59915227 0.5299245 ]\n",
      "Epoch 1859/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6415 - val_loss: 4.5449\n",
      "Epoch 1860/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8950 - val_loss: 4.3296\n",
      "Epoch 1861/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8182 - val_loss: 4.4507\n",
      "[0.5061407  0.44582164 0.3937222 ]\n",
      "[0.5142095  0.50011104 0.49962705]\n",
      "[1.        0.5947212 0.5234855]\n",
      "Epoch 1862/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8843 - val_loss: 4.1339\n",
      "Epoch 1863/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8901 - val_loss: 4.0395\n",
      "Epoch 1864/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7954 - val_loss: 4.2643\n",
      "[0.48152977 0.44139007 0.39413986]\n",
      "[0.5102918  0.5000959  0.49963418]\n",
      "[1.         0.5947628  0.52627057]\n",
      "Epoch 1865/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8909 - val_loss: 3.9097\n",
      "Epoch 1866/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6572 - val_loss: 4.4114\n",
      "Epoch 1867/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7973 - val_loss: 4.3956\n",
      "[0.49716952 0.43605036 0.3957531 ]\n",
      "[0.5111271  0.50008845 0.49964097]\n",
      "[1.         0.5966728  0.52537686]\n",
      "Epoch 1868/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6175 - val_loss: 4.3162\n",
      "Epoch 1869/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8967 - val_loss: 4.1727\n",
      "Epoch 1870/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8076 - val_loss: 6.1467\n",
      "[0.49741188 0.43800288 0.3928572 ]\n",
      "[0.5049882  0.50009704 0.49963468]\n",
      "[1.         0.59704286 0.5076507 ]\n",
      "Epoch 1871/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6780 - val_loss: 4.4757\n",
      "Epoch 1872/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6073 - val_loss: 4.3343\n",
      "Epoch 1873/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9371 - val_loss: 4.4803\n",
      "[0.50555    0.44435585 0.3957891 ]\n",
      "[0.5124067  0.50009733 0.49967426]\n",
      "[1.         0.59491026 0.523503  ]\n",
      "Epoch 1874/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6888 - val_loss: 4.2456\n",
      "Epoch 1875/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6811 - val_loss: 6.1805\n",
      "Epoch 1876/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8886 - val_loss: 4.3113\n",
      "[0.50291675 0.44419497 0.41006452]\n",
      "[0.5097046 0.5000894 0.4997107]\n",
      "[1.         0.5886392  0.53089565]\n",
      "Epoch 1877/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7716 - val_loss: 4.3025\n",
      "Epoch 1878/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8664 - val_loss: 4.1431\n",
      "Epoch 1879/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8569 - val_loss: 4.0648\n",
      "[0.5000644  0.4454912  0.41776872]\n",
      "[0.50727993 0.50006187 0.4997466 ]\n",
      "[1.         0.5824698  0.51814455]\n",
      "Epoch 1880/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7578 - val_loss: 6.2093\n",
      "Epoch 1881/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9887 - val_loss: 6.0130\n",
      "Epoch 1882/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8389 - val_loss: 4.4348\n",
      "[0.50274426 0.48760432 0.43670782]\n",
      "[0.5123721 0.5000491 0.4997624]\n",
      "[1.         0.54140204 0.500103  ]\n",
      "Epoch 1883/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6353 - val_loss: 3.9274\n",
      "Epoch 1884/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8498 - val_loss: 4.3548\n",
      "Epoch 1885/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9220 - val_loss: 6.0135\n",
      "[0.4895144  0.43771985 0.41121894]\n",
      "[0.50221926 0.5000819  0.49969235]\n",
      "[1.         0.57956696 0.523777  ]\n",
      "Epoch 1886/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8259 - val_loss: 4.4113\n",
      "Epoch 1887/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8073 - val_loss: 4.1157\n",
      "Epoch 1888/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7561 - val_loss: 4.2338\n",
      "[0.4946098  0.44934478 0.41917077]\n",
      "[0.5103547  0.500087   0.49970987]\n",
      "[1.        0.5801382 0.5203449]\n",
      "Epoch 1889/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6277 - val_loss: 4.2539\n",
      "Epoch 1890/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7877 - val_loss: 4.3275\n",
      "Epoch 1891/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.8625 - val_loss: 4.4979\n",
      "[0.5040435  0.49858245 0.42913643]\n",
      "[0.5142085  0.5001175  0.49970984]\n",
      "[1.         0.55136317 0.5001108 ]\n",
      "Epoch 1892/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7275 - val_loss: 3.7605\n",
      "Epoch 1893/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7888 - val_loss: 6.1687\n",
      "Epoch 1894/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6602 - val_loss: 4.4355\n",
      "[0.5013251  0.4990634  0.43223238]\n",
      "[0.5126496  0.5001573  0.49969175]\n",
      "[1.         0.5463272  0.50008005]\n",
      "Epoch 1895/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8111 - val_loss: 6.0532\n",
      "Epoch 1896/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8457 - val_loss: 4.0141\n",
      "Epoch 1897/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9926 - val_loss: 4.1143\n",
      "[0.5014716  0.49905232 0.44170505]\n",
      "[0.50965184 0.500125   0.4996999 ]\n",
      "[1.         0.54273754 0.5000707 ]\n",
      "Epoch 1898/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5396 - val_loss: 4.4157\n",
      "Epoch 1899/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6776 - val_loss: 4.3361\n",
      "Epoch 1900/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7941 - val_loss: 4.3776\n",
      "[0.5044806  0.49924433 0.43074584]\n",
      "[0.51233834 0.50015825 0.49970996]\n",
      "[1.         0.54577684 0.500118  ]\n",
      "Epoch 1901/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9266 - val_loss: 4.2692\n",
      "Epoch 1902/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7905 - val_loss: 4.3000\n",
      "Epoch 1903/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9006 - val_loss: 6.1523\n",
      "[0.49726185 0.49941713 0.43026525]\n",
      "[0.5052261  0.50016034 0.49973947]\n",
      "[1.        0.5438843 0.5001371]\n",
      "Epoch 1904/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8429 - val_loss: 4.2309\n",
      "Epoch 1905/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8066 - val_loss: 6.2056\n",
      "Epoch 1906/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8032 - val_loss: 4.2565\n",
      "[0.50242525 0.49950737 0.43006513]\n",
      "[0.5099358 0.500142  0.4997451]\n",
      "[1.         0.53810644 0.50013655]\n",
      "Epoch 1907/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7042 - val_loss: 4.1139\n",
      "Epoch 1908/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8022 - val_loss: 4.4093\n",
      "Epoch 1909/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8050 - val_loss: 6.0959\n",
      "[0.49899334 0.49961528 0.43337867]\n",
      "[0.50649214 0.50010794 0.49976602]\n",
      "[1.        0.5333621 0.5003211]\n",
      "Epoch 1910/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7971 - val_loss: 4.2509\n",
      "Epoch 1911/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9079 - val_loss: 6.1623\n",
      "Epoch 1912/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7442 - val_loss: 4.2153\n",
      "[0.501369   0.4982105  0.43601725]\n",
      "[0.50838965 0.5000958  0.49976593]\n",
      "[1.        0.534461  0.5015792]\n",
      "Epoch 1913/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7629 - val_loss: 4.3005\n",
      "Epoch 1914/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7351 - val_loss: 3.9677\n",
      "Epoch 1915/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9777 - val_loss: 4.1887\n",
      "[0.5002177  0.49900198 0.44424602]\n",
      "[0.5078729  0.5000798  0.49979007]\n",
      "[1.         0.53405607 0.50061136]\n",
      "Epoch 1916/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0148 - val_loss: 4.1932\n",
      "Epoch 1917/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6865 - val_loss: 4.3125\n",
      "Epoch 1918/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7585 - val_loss: 6.0113\n",
      "[0.49352854 0.4994623  0.42945695]\n",
      "[0.50098675 0.50009626 0.49975833]\n",
      "[1.         0.54365724 0.500211  ]\n",
      "Epoch 1919/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0192 - val_loss: 5.9408\n",
      "Epoch 1920/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7909 - val_loss: 6.1439\n",
      "Epoch 1921/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8560 - val_loss: 4.1745\n",
      "[0.5007921  0.4986583  0.43869567]\n",
      "[0.5085969  0.50010127 0.49974886]\n",
      "[1.         0.5402024  0.50114274]\n",
      "Epoch 1922/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0160 - val_loss: 4.0680\n",
      "Epoch 1923/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6253 - val_loss: 6.0028\n",
      "Epoch 1924/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8190 - val_loss: 6.1501\n",
      "[0.4972627  0.4983653  0.42366958]\n",
      "[0.50497794 0.50010574 0.4997077 ]\n",
      "[1.        0.5424142 0.5013028]\n",
      "Epoch 1925/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6666 - val_loss: 4.4953\n",
      "Epoch 1926/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7803 - val_loss: 4.2401\n",
      "Epoch 1927/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7981 - val_loss: 3.9037\n",
      "[0.49995893 0.49929786 0.42612645]\n",
      "[0.5077536  0.50010437 0.49972633]\n",
      "[1.         0.55277795 0.50016063]\n",
      "Epoch 1928/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7707 - val_loss: 4.2870\n",
      "Epoch 1929/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6834 - val_loss: 4.2962\n",
      "Epoch 1930/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8363 - val_loss: 6.0875\n",
      "[0.49655244 0.49618754 0.43802217]\n",
      "[0.5043034  0.50004655 0.49972507]\n",
      "[1.       0.549402 0.50009 ]\n",
      "Epoch 1931/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6933 - val_loss: 4.1643\n",
      "Epoch 1932/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8427 - val_loss: 4.1549\n",
      "Epoch 1933/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7985 - val_loss: 4.1626\n",
      "[0.49955043 0.49234214 0.43843174]\n",
      "[0.5089936  0.5000327  0.49973127]\n",
      "[1.         0.55042326 0.500095  ]\n",
      "Epoch 1934/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8362 - val_loss: 5.8422\n",
      "Epoch 1935/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8679 - val_loss: 4.3344\n",
      "Epoch 1936/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8260 - val_loss: 4.3486\n",
      "[0.5004465  0.4921794  0.43899775]\n",
      "[0.511212   0.50003946 0.49971488]\n",
      "[1.         0.54924476 0.50009656]\n",
      "Epoch 1937/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7020 - val_loss: 4.0663\n",
      "Epoch 1938/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7274 - val_loss: 4.2975\n",
      "Epoch 1939/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5764 - val_loss: 4.2262\n",
      "[0.49011058 0.48295316 0.4328518 ]\n",
      "[0.50949705 0.49999684 0.49972206]\n",
      "[1.         0.54871905 0.50008327]\n",
      "Epoch 1940/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7768 - val_loss: 6.1960\n",
      "Epoch 1941/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6823 - val_loss: 4.3908\n",
      "Epoch 1942/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7920 - val_loss: 6.2073\n",
      "[0.49390122 0.48183346 0.4382462 ]\n",
      "[0.5074125 0.5000096 0.4996956]\n",
      "[1.        0.5481037 0.5000592]\n",
      "Epoch 1943/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7852 - val_loss: 6.0845\n",
      "Epoch 1944/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8048 - val_loss: 6.0239\n",
      "Epoch 1945/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7621 - val_loss: 3.7790\n",
      "[0.500134   0.47350478 0.43567064]\n",
      "[0.50811964 0.50000596 0.4996969 ]\n",
      "[1.         0.5380106  0.50003344]\n",
      "Epoch 1946/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8671 - val_loss: 4.3508\n",
      "Epoch 1947/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7993 - val_loss: 4.5214\n",
      "Epoch 1948/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0226 - val_loss: 3.9195\n",
      "[0.5005466  0.48408502 0.44190407]\n",
      "[0.509028   0.50002646 0.4996794 ]\n",
      "[1.        0.5485463 0.5000317]\n",
      "Epoch 1949/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9895 - val_loss: 6.1692\n",
      "Epoch 1950/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9268 - val_loss: 6.1396\n",
      "Epoch 1951/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7496 - val_loss: 3.7305\n",
      "[0.50008357 0.48594198 0.4266824 ]\n",
      "[0.50817865 0.50003964 0.4996743 ]\n",
      "[1.         0.56273556 0.5000285 ]\n",
      "Epoch 1952/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8767 - val_loss: 4.0810\n",
      "Epoch 1953/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6777 - val_loss: 4.1275\n",
      "Epoch 1954/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7683 - val_loss: 4.2283\n",
      "[0.5026596  0.49336657 0.40492934]\n",
      "[0.5107842  0.5000807  0.49962962]\n",
      "[1.         0.58848923 0.5000184 ]\n",
      "Epoch 1955/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8885 - val_loss: 4.3718\n",
      "Epoch 1956/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8143 - val_loss: 4.0402\n",
      "Epoch 1957/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8067 - val_loss: 4.1064\n",
      "[0.50164616 0.4996135  0.40070254]\n",
      "[0.51003206 0.5001132  0.4996109 ]\n",
      "[1.         0.5979657  0.50001734]\n",
      "Epoch 1958/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8168 - val_loss: 4.0346\n",
      "Epoch 1959/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7827 - val_loss: 4.3115\n",
      "Epoch 1960/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7657 - val_loss: 4.0981\n",
      "[0.5019001  0.4962238  0.40705493]\n",
      "[0.51060915 0.50013    0.49954677]\n",
      "[1.        0.584644  0.5000156]\n",
      "Epoch 1961/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7659 - val_loss: 6.1930\n",
      "Epoch 1962/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9555 - val_loss: 4.2522\n",
      "Epoch 1963/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9125 - val_loss: 4.2629\n",
      "[0.5035636  0.49567765 0.4092568 ]\n",
      "[0.51235235 0.5001548  0.49952248]\n",
      "[1.        0.5889106 0.5000138]\n",
      "Epoch 1964/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6822 - val_loss: 6.1711\n",
      "Epoch 1965/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6720 - val_loss: 4.3306\n",
      "Epoch 1966/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6566 - val_loss: 3.7588\n",
      "[0.5003887  0.49330238 0.41947043]\n",
      "[0.50874853 0.5001357  0.49953637]\n",
      "[1.         0.5882879  0.50001496]\n",
      "Epoch 1967/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6680 - val_loss: 4.3487\n",
      "Epoch 1968/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9022 - val_loss: 3.9104\n",
      "Epoch 1969/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8274 - val_loss: 3.7723\n",
      "[0.50051075 0.49113312 0.41158554]\n",
      "[0.50918114 0.50012606 0.49950993]\n",
      "[1.         0.5802766  0.50001335]\n",
      "Epoch 1970/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8098 - val_loss: 6.0599\n",
      "Epoch 1971/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7149 - val_loss: 6.1563\n",
      "Epoch 1972/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8233 - val_loss: 4.2144\n",
      "[0.5035167  0.49196556 0.41295144]\n",
      "[0.51267636 0.5001601  0.4994804 ]\n",
      "[1.        0.5764481 0.5000137]\n",
      "Epoch 1973/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5695 - val_loss: 3.9295\n",
      "Epoch 1974/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7818 - val_loss: 4.0056\n",
      "Epoch 1975/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8489 - val_loss: 4.3431\n",
      "[0.5049354  0.49286267 0.40956557]\n",
      "[0.5137074  0.50019956 0.49946323]\n",
      "[1.        0.5849974 0.5000114]\n",
      "Epoch 1976/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7846 - val_loss: 4.0600\n",
      "Epoch 1977/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7877 - val_loss: 3.7894\n",
      "Epoch 1978/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6923 - val_loss: 4.0221\n",
      "[0.50157523 0.4912079  0.41386455]\n",
      "[0.5104842  0.5001676  0.49947318]\n",
      "[1.        0.5819265 0.5000083]\n",
      "Epoch 1979/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8780 - val_loss: 6.1551\n",
      "Epoch 1980/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7339 - val_loss: 4.4427\n",
      "Epoch 1981/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7101 - val_loss: 4.0625\n",
      "[0.5020437  0.49184301 0.41696775]\n",
      "[0.51094526 0.5001776  0.4994509 ]\n",
      "[1.        0.5798678 0.500007 ]\n",
      "Epoch 1982/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7920 - val_loss: 3.2181\n",
      "Epoch 1983/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8386 - val_loss: 3.5320\n",
      "Epoch 1984/10000\n",
      "2268/2268 [==============================] - 22s 9ms/step - loss: 0.6539 - val_loss: 6.2566\n",
      "[0.49871954 0.4939729  0.4134396 ]\n",
      "[0.50758886 0.50020266 0.49946097]\n",
      "[1.         0.5858168  0.50001097]\n",
      "Epoch 1985/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7136 - val_loss: 3.6555\n",
      "Epoch 1986/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7135 - val_loss: 6.0272\n",
      "Epoch 1987/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8896 - val_loss: 4.4426\n",
      "[0.50706065 0.49484545 0.4004923 ]\n",
      "[0.5164371 0.5002295 0.4994331]\n",
      "[1.         0.59420234 0.5000082 ]\n",
      "Epoch 1988/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9328 - val_loss: 3.2781\n",
      "Epoch 1989/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9117 - val_loss: 3.6863\n",
      "Epoch 1990/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8798 - val_loss: 5.7345\n",
      "[0.49995103 0.49494034 0.40494147]\n",
      "[0.5090059  0.5002365  0.49943873]\n",
      "[1.        0.5982734 0.5000096]\n",
      "Epoch 1991/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8885 - val_loss: 6.2038\n",
      "Epoch 1992/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7657 - val_loss: 3.7665\n",
      "Epoch 1993/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7057 - val_loss: 3.6263\n",
      "[0.500207   0.49455458 0.40686285]\n",
      "[0.50937724 0.50025403 0.49940962]\n",
      "[1.         0.59994656 0.50001055]\n",
      "Epoch 1994/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6818 - val_loss: 3.8702\n",
      "Epoch 1995/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7628 - val_loss: 3.4336\n",
      "Epoch 1996/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9459 - val_loss: 6.1620\n",
      "[0.49918294 0.49189463 0.38873228]\n",
      "[0.5083272  0.5002907  0.49934372]\n",
      "[1.         0.59684604 0.50002337]\n",
      "Epoch 1997/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7225 - val_loss: 4.1672\n",
      "Epoch 1998/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7537 - val_loss: 3.7711\n",
      "Epoch 1999/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8652 - val_loss: 4.3612\n",
      "[0.50578123 0.48705757 0.3951527 ]\n",
      "[0.5150261  0.5002682  0.49940214]\n",
      "[1.        0.5907222 0.5091878]\n",
      "Epoch 2000/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8185 - val_loss: 3.9267\n",
      "Epoch 2001/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7882 - val_loss: 4.2818\n",
      "Epoch 2002/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6092 - val_loss: 4.2309\n",
      "[0.5038361  0.48708385 0.39400876]\n",
      "[0.5127445  0.50027084 0.4993939 ]\n",
      "[1.         0.5951658  0.50587535]\n",
      "Epoch 2003/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8270 - val_loss: 6.2265\n",
      "Epoch 2004/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6882 - val_loss: 4.2869\n",
      "Epoch 2005/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8846 - val_loss: 4.0589\n",
      "[0.50260454 0.48912454 0.3968144 ]\n",
      "[0.51222456 0.50036    0.49931234]\n",
      "[1.         0.60188925 0.5000422 ]\n",
      "Epoch 2006/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8545 - val_loss: 6.0515\n",
      "Epoch 2007/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8756 - val_loss: 4.3099\n",
      "Epoch 2008/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7203 - val_loss: 4.2882\n",
      "[0.5024461  0.48916802 0.40378296]\n",
      "[0.5140621 0.5003582 0.4993529]\n",
      "[1.         0.6135608  0.50004315]\n",
      "Epoch 2009/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7013 - val_loss: 3.7081\n",
      "Epoch 2010/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9119 - val_loss: 4.0847\n",
      "Epoch 2011/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6439 - val_loss: 3.4976\n",
      "[0.45972237 0.4885983  0.40117356]\n",
      "[0.5093589  0.50046307 0.49929166]\n",
      "[1.        0.6379584 0.5000463]\n",
      "Epoch 2012/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6390 - val_loss: 6.1990\n",
      "Epoch 2013/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7935 - val_loss: 3.8013\n",
      "Epoch 2014/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8714 - val_loss: 4.4438\n",
      "[0.48508197 0.4896862  0.39745617]\n",
      "[0.5145803  0.5003806  0.49944293]\n",
      "[1.        0.6187089 0.5000804]\n",
      "Epoch 2015/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7987 - val_loss: 4.0191\n",
      "Epoch 2016/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8737 - val_loss: 4.3113\n",
      "Epoch 2017/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7261 - val_loss: 4.3426\n",
      "[0.4991271  0.48894244 0.41941607]\n",
      "[0.5140598  0.5003658  0.49949884]\n",
      "[1.         0.62455714 0.50004244]\n",
      "Epoch 2018/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9215 - val_loss: 6.2493\n",
      "Epoch 2019/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.1256 - val_loss: 3.9701\n",
      "Epoch 2020/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7871 - val_loss: 4.1805\n",
      "[0.49567613 0.4832761  0.4140766 ]\n",
      "[0.5121828  0.50029814 0.49949622]\n",
      "[1.         0.60956377 0.5088909 ]\n",
      "Epoch 2021/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8766 - val_loss: 6.0451\n",
      "Epoch 2022/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8643 - val_loss: 4.2949\n",
      "Epoch 2023/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7538 - val_loss: 4.4801\n",
      "[0.5068895 0.4838091 0.4090531]\n",
      "[0.5157707 0.5002881 0.4995208]\n",
      "[1.        0.5791872 0.5227775]\n",
      "Epoch 2024/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8187 - val_loss: 4.4568\n",
      "Epoch 2025/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9585 - val_loss: 3.8066\n",
      "Epoch 2026/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8314 - val_loss: 6.0872\n",
      "[0.49713066 0.48114222 0.4057007 ]\n",
      "[0.50624263 0.5002504  0.49952948]\n",
      "[1.         0.56681085 0.53292304]\n",
      "Epoch 2027/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8167 - val_loss: 6.2150\n",
      "Epoch 2028/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8223 - val_loss: 4.3238\n",
      "Epoch 2029/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6786 - val_loss: 3.9835\n",
      "[0.50124586 0.4840547  0.4027872 ]\n",
      "[0.51081073 0.50033957 0.4994588 ]\n",
      "[1.         0.57727796 0.5201859 ]\n",
      "Epoch 2030/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9227 - val_loss: 3.9466\n",
      "Epoch 2031/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7978 - val_loss: 6.1420\n",
      "Epoch 2032/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.1128 - val_loss: 6.0311\n",
      "[0.49273482 0.48433807 0.3994054 ]\n",
      "[0.50315744 0.50041056 0.49938005]\n",
      "[1.         0.58653784 0.5104238 ]\n",
      "Epoch 2033/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0239 - val_loss: 6.0212\n",
      "Epoch 2034/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7979 - val_loss: 4.4085\n",
      "Epoch 2035/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7522 - val_loss: 6.0941\n",
      "[0.49305683 0.48223868 0.40381503]\n",
      "[0.50392604 0.5003885  0.49939185]\n",
      "[1.        0.5697244 0.5204524]\n",
      "Epoch 2036/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8477 - val_loss: 6.1671\n",
      "Epoch 2037/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9188 - val_loss: 3.9471\n",
      "Epoch 2038/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0455 - val_loss: 6.1223\n",
      "[0.4940138  0.48844343 0.39122432]\n",
      "[0.50603825 0.5005929  0.49926102]\n",
      "[1.        0.5809329 0.5120048]\n",
      "Epoch 2039/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0242 - val_loss: 3.9133\n",
      "Epoch 2040/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9153 - val_loss: 4.2262\n",
      "Epoch 2041/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5566 - val_loss: 4.2307\n",
      "[0.50449073 0.47834516 0.3854035 ]\n",
      "[0.515704   0.5005259  0.49927953]\n",
      "[1.         0.57715    0.51247823]\n",
      "Epoch 2042/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7469 - val_loss: 4.3022\n",
      "Epoch 2043/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7702 - val_loss: 3.9787\n",
      "Epoch 2044/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8098 - val_loss: 4.0605\n",
      "[0.5017495  0.4756141  0.39895806]\n",
      "[0.5120364  0.50037336 0.49940214]\n",
      "[1.         0.56414145 0.51868194]\n",
      "Epoch 2045/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6978 - val_loss: 4.2518\n",
      "Epoch 2046/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9527 - val_loss: 6.1077\n",
      "Epoch 2047/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7983 - val_loss: 6.1872\n",
      "[0.49732128 0.47826633 0.4066812 ]\n",
      "[0.5095957  0.5004645  0.49933937]\n",
      "[1.         0.5703785  0.52308375]\n",
      "Epoch 2048/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7928 - val_loss: 4.0288\n",
      "Epoch 2049/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8105 - val_loss: 4.0418\n",
      "Epoch 2050/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8906 - val_loss: 3.4675\n",
      "[0.4996168  0.48034242 0.4163574 ]\n",
      "[0.5107763  0.5004869  0.49939805]\n",
      "[1.         0.58954674 0.51864433]\n",
      "Epoch 2051/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7311 - val_loss: 6.2394\n",
      "Epoch 2052/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7542 - val_loss: 4.2546\n",
      "Epoch 2053/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8081 - val_loss: 4.1604\n",
      "[0.50335723 0.4783046  0.41523415]\n",
      "[0.5140521  0.5004626  0.49940175]\n",
      "[1.        0.5773912 0.5257076]\n",
      "Epoch 2054/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7231 - val_loss: 3.8311\n",
      "Epoch 2055/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8207 - val_loss: 6.1689\n",
      "Epoch 2056/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9180 - val_loss: 6.1458\n",
      "[0.49464843 0.47982663 0.40001   ]\n",
      "[0.506396   0.5005512  0.49929664]\n",
      "[1.         0.58901215 0.5166344 ]\n",
      "Epoch 2057/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7709 - val_loss: 4.3267\n",
      "Epoch 2058/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8561 - val_loss: 6.1567\n",
      "Epoch 2059/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8068 - val_loss: 4.1476\n",
      "[0.50357574 0.4814199  0.40554488]\n",
      "[0.5150528  0.5006041  0.49929333]\n",
      "[1.         0.59382766 0.50877285]\n",
      "Epoch 2060/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6444 - val_loss: 3.8381\n",
      "Epoch 2061/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.9852 - val_loss: 4.2069\n",
      "Epoch 2062/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7214 - val_loss: 3.6354\n",
      "[0.50015414 0.48114753 0.4048597 ]\n",
      "[0.51079154 0.5004629  0.49937686]\n",
      "[1.        0.5840782 0.5185697]\n",
      "Epoch 2063/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6185 - val_loss: 4.2416\n",
      "Epoch 2064/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7219 - val_loss: 3.4665\n",
      "Epoch 2065/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.9602 - val_loss: 3.8825\n",
      "[0.5008728  0.47814414 0.40805107]\n",
      "[0.5112819  0.5003177  0.49945417]\n",
      "[1.        0.5708477 0.5301227]\n",
      "Epoch 2066/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7536 - val_loss: 4.0952\n",
      "Epoch 2067/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7898 - val_loss: 4.3654\n",
      "Epoch 2068/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9806 - val_loss: 6.2418\n",
      "[0.49828973 0.4758982  0.41373038]\n",
      "[0.5082686  0.50026023 0.49945265]\n",
      "[1.        0.5776952 0.5208744]\n",
      "Epoch 2069/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8492 - val_loss: 4.0594\n",
      "Epoch 2070/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8313 - val_loss: 6.1537\n",
      "Epoch 2071/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7865 - val_loss: 3.8585\n",
      "[0.5005778  0.46956676 0.4168708 ]\n",
      "[0.5102362  0.5001276  0.49948904]\n",
      "[1.         0.5577979  0.52670693]\n",
      "Epoch 2072/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.9490 - val_loss: 4.0420\n",
      "Epoch 2073/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7757 - val_loss: 3.7175\n",
      "Epoch 2074/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7476 - val_loss: 4.2417\n",
      "[0.50452626 0.45702773 0.41501638]\n",
      "[0.5136786  0.49994865 0.49953008]\n",
      "[1.         0.53830355 0.53812593]\n",
      "Epoch 2075/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6168 - val_loss: 4.1765\n",
      "Epoch 2076/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7518 - val_loss: 6.0878\n",
      "Epoch 2077/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9807 - val_loss: 6.2032\n",
      "[0.498565   0.45164087 0.41419655]\n",
      "[0.5088583  0.49982488 0.49952793]\n",
      "[1.         0.53607893 0.53281283]\n",
      "Epoch 2078/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7964 - val_loss: 4.2485\n",
      "Epoch 2079/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7499 - val_loss: 3.8269\n",
      "Epoch 2080/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7300 - val_loss: 3.5339\n",
      "[0.50006133 0.45192263 0.4133888 ]\n",
      "[0.509945   0.49986443 0.49955302]\n",
      "[1.         0.53959155 0.53450257]\n",
      "Epoch 2081/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.9063 - val_loss: 3.9730\n",
      "Epoch 2082/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8026 - val_loss: 6.1943\n",
      "Epoch 2083/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6326 - val_loss: 4.2357\n",
      "[0.5048357  0.45709676 0.41449225]\n",
      "[0.5149315 0.49986   0.4995528]\n",
      "[1.         0.5408201  0.53374803]\n",
      "Epoch 2084/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7187 - val_loss: 3.7741\n",
      "Epoch 2085/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8169 - val_loss: 4.0443\n",
      "Epoch 2086/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7922 - val_loss: 6.1506\n",
      "[0.49522147 0.4627185  0.4212603 ]\n",
      "[0.5048391 0.4998337 0.4995764]\n",
      "[1.         0.5402657  0.52887815]\n",
      "Epoch 2087/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8244 - val_loss: 4.3786\n",
      "Epoch 2088/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.9900 - val_loss: 4.2952\n",
      "Epoch 2089/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7629 - val_loss: 4.2064\n",
      "[0.5043554  0.4560526  0.42119765]\n",
      "[0.51449585 0.4997137  0.49956512]\n",
      "[1.         0.53430873 0.5329705 ]\n",
      "Epoch 2090/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7280 - val_loss: 6.1441\n",
      "Epoch 2091/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.5584 - val_loss: 4.1275\n",
      "Epoch 2092/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8246 - val_loss: 5.8298\n",
      "[0.49969444 0.46232778 0.42447153]\n",
      "[0.5101969  0.4997911  0.49959058]\n",
      "[1.        0.5432325 0.5345928]\n",
      "Epoch 2093/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.5640 - val_loss: 4.1120\n",
      "Epoch 2094/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7508 - val_loss: 4.1496\n",
      "Epoch 2095/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.9754 - val_loss: 3.9345\n",
      "[0.5002503  0.46620083 0.42621046]\n",
      "[0.511257   0.49991336 0.49957347]\n",
      "[1.         0.5511322  0.52741987]\n",
      "Epoch 2096/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7816 - val_loss: 3.5892\n",
      "Epoch 2097/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.5011 - val_loss: 3.1436\n",
      "Epoch 2098/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8283 - val_loss: 4.2411\n",
      "[0.5039761  0.47145376 0.43101597]\n",
      "[0.5153872  0.49995977 0.4995853 ]\n",
      "[1.         0.55741286 0.52857906]\n",
      "Epoch 2099/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7693 - val_loss: 4.1327\n",
      "Epoch 2100/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8047 - val_loss: 4.3237\n",
      "Epoch 2101/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8297 - val_loss: 4.0588\n",
      "[0.5022663  0.47099835 0.42521334]\n",
      "[0.513067   0.4999828  0.49956125]\n",
      "[1.        0.5613476 0.5240109]\n",
      "Epoch 2102/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7591 - val_loss: 4.0185\n",
      "Epoch 2103/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7481 - val_loss: 4.2174\n",
      "Epoch 2104/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8430 - val_loss: 6.0724\n",
      "[0.49397334 0.473871   0.41053843]\n",
      "[0.5048796  0.49997297 0.49960434]\n",
      "[1.        0.5815623 0.5378182]\n",
      "Epoch 2105/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7325 - val_loss: 4.2970\n",
      "Epoch 2106/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7531 - val_loss: 4.2098\n",
      "Epoch 2107/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7819 - val_loss: 5.9739\n",
      "[0.49952614 0.4715645  0.42539036]\n",
      "[0.51055145 0.49996257 0.49957255]\n",
      "[1.         0.56667745 0.53705907]\n",
      "Epoch 2108/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8364 - val_loss: 3.9915\n",
      "Epoch 2109/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6979 - val_loss: 4.1004\n",
      "Epoch 2110/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6755 - val_loss: 6.1619\n",
      "[0.49411926 0.47103125 0.40023342]\n",
      "[0.5085279 0.4999527 0.4995511]\n",
      "[1.        0.5746118 0.5446952]\n",
      "Epoch 2111/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7743 - val_loss: 5.8498\n",
      "Epoch 2112/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.9569 - val_loss: 4.0547\n",
      "Epoch 2113/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7849 - val_loss: 4.0917\n",
      "[0.49905166 0.46994907 0.40017635]\n",
      "[0.51374125 0.49996176 0.49953339]\n",
      "[1.         0.5846919  0.53947425]\n",
      "Epoch 2114/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7168 - val_loss: 4.2403\n",
      "Epoch 2115/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7335 - val_loss: 5.1899\n",
      "Epoch 2116/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6599 - val_loss: 3.8292\n",
      "[0.49535394 0.4692603  0.40140918]\n",
      "[0.51266575 0.49995998 0.4995084 ]\n",
      "[1.         0.58572626 0.5380875 ]\n",
      "Epoch 2117/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6721 - val_loss: 3.9905\n",
      "Epoch 2118/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7809 - val_loss: 6.1030\n",
      "Epoch 2119/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7092 - val_loss: 4.1917\n",
      "[0.500656   0.46704033 0.41852143]\n",
      "[0.5158576  0.49991193 0.49952635]\n",
      "[1.        0.5617558 0.5352787]\n",
      "Epoch 2120/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7777 - val_loss: 4.0372\n",
      "Epoch 2121/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.9006 - val_loss: 5.6994\n",
      "Epoch 2122/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9214 - val_loss: 6.1459\n",
      "[0.49774927 0.47171605 0.41932416]\n",
      "[0.509583   0.4999824  0.49949726]\n",
      "[1.        0.570555  0.5358663]\n",
      "Epoch 2123/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9655 - val_loss: 4.0324\n",
      "Epoch 2124/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6929 - val_loss: 5.9198\n",
      "Epoch 2125/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6433 - val_loss: 3.8853\n",
      "[0.5008765  0.46918887 0.40506008]\n",
      "[0.5129441  0.49994054 0.49947178]\n",
      "[1.        0.5610479 0.5363078]\n",
      "Epoch 2126/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8747 - val_loss: 4.1456\n",
      "Epoch 2127/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8155 - val_loss: 4.0562\n",
      "Epoch 2128/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8042 - val_loss: 3.9434\n",
      "[0.5011112  0.47490695 0.42167524]\n",
      "[0.51344264 0.5000098  0.49946046]\n",
      "[1.         0.56521153 0.5302329 ]\n",
      "Epoch 2129/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8127 - val_loss: 6.1196\n",
      "Epoch 2130/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7622 - val_loss: 4.0015\n",
      "Epoch 2131/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6909 - val_loss: 3.8654\n",
      "[0.483411  0.476708  0.3935463]\n",
      "[0.5128219  0.5000375  0.49947947]\n",
      "[1.         0.57022715 0.5424925 ]\n",
      "Epoch 2132/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7022 - val_loss: 5.8920\n",
      "Epoch 2133/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8106 - val_loss: 4.0850\n",
      "Epoch 2134/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7982 - val_loss: 3.9583\n",
      "[0.49186555 0.47151113 0.41964406]\n",
      "[0.51392144 0.49996147 0.49948317]\n",
      "[1.         0.55962944 0.5406603 ]\n",
      "Epoch 2135/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8410 - val_loss: 5.1250\n",
      "Epoch 2136/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7917 - val_loss: 5.6695\n",
      "Epoch 2137/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6460 - val_loss: 6.0243\n",
      "[0.49194932 0.47058856 0.4090113 ]\n",
      "[0.51067626 0.4999106  0.49947914]\n",
      "[1.         0.5606209  0.53324217]\n",
      "Epoch 2138/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6639 - val_loss: 4.0031\n",
      "Epoch 2139/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7040 - val_loss: 4.2472\n",
      "Epoch 2140/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8851 - val_loss: 4.0232\n",
      "[0.48564938 0.4699886  0.41971   ]\n",
      "[0.51409423 0.49988407 0.4995094 ]\n",
      "[1.         0.56099045 0.54211545]\n",
      "Epoch 2141/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7817 - val_loss: 3.2148\n",
      "Epoch 2142/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8717 - val_loss: 5.9840\n",
      "Epoch 2143/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6462 - val_loss: 3.7589\n",
      "[0.4935729  0.47117493 0.41928098]\n",
      "[0.5138269  0.49990556 0.49947825]\n",
      "[1.         0.5616408  0.53150374]\n",
      "Epoch 2144/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7885 - val_loss: 4.1275\n",
      "Epoch 2145/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.5287 - val_loss: 3.8621\n",
      "Epoch 2146/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6769 - val_loss: 5.8717\n",
      "[0.480999   0.47165534 0.42192653]\n",
      "[0.51149565 0.49986023 0.4994953 ]\n",
      "[1.         0.57018006 0.5401159 ]\n",
      "Epoch 2147/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6457 - val_loss: 4.1161\n",
      "Epoch 2148/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9228 - val_loss: 5.7951\n",
      "Epoch 2149/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7078 - val_loss: 5.6546\n",
      "[0.48985076 0.4680356  0.40611467]\n",
      "[0.5122941  0.49983823 0.49949655]\n",
      "[1.        0.5706184 0.5502669]\n",
      "Epoch 2150/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8475 - val_loss: 5.8428\n",
      "Epoch 2151/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5820 - val_loss: 4.1924\n",
      "Epoch 2152/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8395 - val_loss: 3.6259\n",
      "[0.41711476 0.46879175 0.41219246]\n",
      "[0.51366615 0.49991238 0.49946126]\n",
      "[1.        0.5660227 0.5529897]\n",
      "Epoch 2153/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8712 - val_loss: 5.8598\n",
      "Epoch 2154/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8707 - val_loss: 3.7390\n",
      "Epoch 2155/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8054 - val_loss: 3.2977\n",
      "[0.48111913 0.46643618 0.41904712]\n",
      "[0.51290405 0.49988052 0.4994827 ]\n",
      "[1.        0.5635141 0.5622844]\n",
      "Epoch 2156/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8617 - val_loss: 3.9180\n",
      "Epoch 2157/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.5538 - val_loss: 4.0537\n",
      "Epoch 2158/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6947 - val_loss: 4.1362\n",
      "[0.43692145 0.46339136 0.41280377]\n",
      "[0.5158104  0.4998797  0.49947488]\n",
      "[1.         0.58824104 0.55902785]\n",
      "Epoch 2159/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6582 - val_loss: 4.1383\n",
      "Epoch 2160/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.9223 - val_loss: 4.0922\n",
      "Epoch 2161/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8459 - val_loss: 5.9766\n",
      "[0.37824893 0.46468154 0.3866951 ]\n",
      "[0.50835866 0.49994743 0.49943545]\n",
      "[1.         0.6055134  0.54782796]\n",
      "Epoch 2162/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7903 - val_loss: 5.6864\n",
      "Epoch 2163/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7346 - val_loss: 5.6461\n",
      "Epoch 2164/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7078 - val_loss: 3.8036\n",
      "[0.48721635 0.46717387 0.41507328]\n",
      "[0.51397216 0.4999419  0.49944463]\n",
      "[1.         0.5813797  0.54386795]\n",
      "Epoch 2165/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.5855 - val_loss: 4.1156\n",
      "Epoch 2166/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8058 - val_loss: 4.0148\n",
      "Epoch 2167/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8232 - val_loss: 4.0853\n",
      "[0.50235736 0.4690589  0.4241221 ]\n",
      "[0.5155907  0.5000503  0.49941018]\n",
      "[1.         0.57309437 0.5282437 ]\n",
      "Epoch 2168/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6281 - val_loss: 4.1817\n",
      "Epoch 2169/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6840 - val_loss: 3.2555\n",
      "Epoch 2170/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6999 - val_loss: 4.1831\n",
      "[0.50122714 0.4660794  0.4239063 ]\n",
      "[0.51621884 0.5000484  0.4994585 ]\n",
      "[1.         0.5755803  0.52515566]\n",
      "Epoch 2171/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9094 - val_loss: 6.1483\n",
      "Epoch 2172/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8324 - val_loss: 4.0494\n",
      "Epoch 2173/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8948 - val_loss: 3.8155\n",
      "[0.4983924 0.4669373 0.4257511]\n",
      "[0.5117117  0.50011414 0.4994848 ]\n",
      "[1.         0.57344544 0.5149213 ]\n",
      "Epoch 2174/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9804 - val_loss: 3.9756\n",
      "Epoch 2175/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5377 - val_loss: 4.1222\n",
      "Epoch 2176/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.5485 - val_loss: 5.8561\n",
      "[0.4977763  0.47361764 0.424891  ]\n",
      "[0.511892  0.5001357 0.4994548]\n",
      "[1.         0.5785099  0.51644766]\n",
      "Epoch 2177/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7927 - val_loss: 4.0310\n",
      "Epoch 2178/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7485 - val_loss: 3.7917\n",
      "Epoch 2179/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.9189 - val_loss: 3.9359\n",
      "[0.4863279  0.47025868 0.42460454]\n",
      "[0.512995   0.5000896  0.49948674]\n",
      "[1.         0.57104033 0.5224312 ]\n",
      "Epoch 2180/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8917 - val_loss: 4.0528\n",
      "Epoch 2181/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.5874 - val_loss: 4.0346\n",
      "Epoch 2182/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7462 - val_loss: 4.1066\n",
      "[0.49416643 0.4679016  0.42484927]\n",
      "[0.51587754 0.5000973  0.49950367]\n",
      "[1.         0.5753454  0.52665347]\n",
      "Epoch 2183/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7830 - val_loss: 4.1439\n",
      "Epoch 2184/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8259 - val_loss: 4.0600\n",
      "Epoch 2185/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8607 - val_loss: 4.0360\n",
      "[0.5018877  0.4690512  0.42697614]\n",
      "[0.51433074 0.50006354 0.49951273]\n",
      "[1.        0.5895131 0.5396373]\n",
      "Epoch 2186/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6189 - val_loss: 6.1679\n",
      "Epoch 2187/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.9859 - val_loss: 4.0776\n",
      "Epoch 2188/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7626 - val_loss: 3.7700\n",
      "[0.4995232  0.46379882 0.426883  ]\n",
      "[0.5131347  0.49999267 0.49950796]\n",
      "[1.        0.563228  0.5359834]\n",
      "Epoch 2189/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7472 - val_loss: 4.0943\n",
      "Epoch 2190/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6492 - val_loss: 6.0776\n",
      "Epoch 2191/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8424 - val_loss: 3.9950\n",
      "[0.50142664 0.46519655 0.4274446 ]\n",
      "[0.5145407  0.5000205  0.49952826]\n",
      "[1.         0.59090406 0.5428171 ]\n",
      "Epoch 2192/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7096 - val_loss: 4.1530\n",
      "Epoch 2193/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8551 - val_loss: 5.9965\n",
      "Epoch 2194/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8186 - val_loss: 4.1647\n",
      "[0.50466365 0.46742767 0.41352877]\n",
      "[0.5170038 0.5000572 0.4995381]\n",
      "[1.         0.59058094 0.5464675 ]\n",
      "Epoch 2195/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7656 - val_loss: 3.9736\n",
      "Epoch 2196/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8301 - val_loss: 3.8453\n",
      "Epoch 2197/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8097 - val_loss: 3.9209\n",
      "[0.50066286 0.4806885  0.40676636]\n",
      "[0.51245993 0.4999917  0.49960425]\n",
      "[1.        0.5965671 0.5563357]\n",
      "Epoch 2198/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8348 - val_loss: 5.8455\n",
      "Epoch 2199/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6788 - val_loss: 4.0977\n",
      "Epoch 2200/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8716 - val_loss: 3.6099\n",
      "[0.5000652  0.46413907 0.4049407 ]\n",
      "[0.51153105 0.49995494 0.4995766 ]\n",
      "[1.         0.5690037  0.56420696]\n",
      "Epoch 2201/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8860 - val_loss: 6.0751\n",
      "Epoch 2202/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8213 - val_loss: 4.0465\n",
      "Epoch 2203/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8117 - val_loss: 2.6280\n",
      "[0.4999536  0.4652096  0.40198392]\n",
      "[0.51128435 0.49998954 0.49959704]\n",
      "[1.         0.567719   0.56678194]\n",
      "Epoch 2204/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6772 - val_loss: 6.1740\n",
      "Epoch 2205/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6993 - val_loss: 6.2092\n",
      "Epoch 2206/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7844 - val_loss: 5.6920\n",
      "[0.49203128 0.46696222 0.39878324]\n",
      "[0.51088107 0.5000641  0.49960682]\n",
      "[1.         0.58471465 0.571064  ]\n",
      "Epoch 2207/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7275 - val_loss: 4.0701\n",
      "Epoch 2208/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8905 - val_loss: 3.7407\n",
      "Epoch 2209/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8299 - val_loss: 3.8376\n",
      "[0.44083932 0.46694934 0.38125786]\n",
      "[0.5119846  0.500046   0.49955958]\n",
      "[1.         0.5861803  0.57123667]\n",
      "Epoch 2210/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8070 - val_loss: 2.6577\n",
      "Epoch 2211/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8741 - val_loss: 6.0968\n",
      "Epoch 2212/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8279 - val_loss: 4.2898\n",
      "[0.5070902  0.4775279  0.38578743]\n",
      "[0.51912045 0.5000093  0.49958283]\n",
      "[1.         0.59539753 0.5668709 ]\n",
      "Epoch 2213/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8254 - val_loss: 3.7384\n",
      "Epoch 2214/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.5323 - val_loss: 4.0388\n",
      "Epoch 2215/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.9787 - val_loss: 3.9699\n",
      "[0.49390545 0.48659548 0.3959883 ]\n",
      "[0.5128981  0.5001157  0.49959433]\n",
      "[1.         0.60712945 0.5669068 ]\n",
      "Epoch 2216/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7396 - val_loss: 4.0563\n",
      "Epoch 2217/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8512 - val_loss: 6.2270\n",
      "Epoch 2218/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7727 - val_loss: 4.0261\n",
      "[0.5019893  0.48590472 0.39593774]\n",
      "[0.5129347  0.50017047 0.49957573]\n",
      "[1.         0.60354745 0.55509716]\n",
      "Epoch 2219/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7501 - val_loss: 6.1264\n",
      "Epoch 2220/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6591 - val_loss: 6.2122\n",
      "Epoch 2221/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8502 - val_loss: 4.0338\n",
      "[0.50204   0.4834496 0.397511 ]\n",
      "[0.5129733  0.5001122  0.49959227]\n",
      "[1.         0.5922674  0.55280644]\n",
      "Epoch 2222/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7278 - val_loss: 3.9449\n",
      "Epoch 2223/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7483 - val_loss: 3.9261\n",
      "Epoch 2224/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8525 - val_loss: 6.1269\n",
      "[0.49663168 0.48184797 0.3935276 ]\n",
      "[0.50825477 0.50013804 0.49956608]\n",
      "[1.        0.5951691 0.5586437]\n",
      "Epoch 2225/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8464 - val_loss: 6.0723\n",
      "Epoch 2226/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0145 - val_loss: 4.0631\n",
      "Epoch 2227/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7331 - val_loss: 6.1506\n",
      "[0.4975907  0.47286254 0.4155622 ]\n",
      "[0.50934184 0.5001309  0.4995718 ]\n",
      "[1.         0.59561473 0.55710447]\n",
      "Epoch 2228/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7201 - val_loss: 3.6686\n",
      "Epoch 2229/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6701 - val_loss: 4.2039\n",
      "Epoch 2230/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7573 - val_loss: 4.0703\n",
      "[0.50249434 0.47692648 0.40631986]\n",
      "[0.5142511  0.50028074 0.49952772]\n",
      "[1.        0.617353  0.5549468]\n",
      "Epoch 2231/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6792 - val_loss: 4.0053\n",
      "Epoch 2232/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8529 - val_loss: 3.8244\n",
      "Epoch 2233/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7955 - val_loss: 5.8408\n",
      "[0.49978375 0.46887836 0.3868818 ]\n",
      "[0.51112527 0.50025874 0.49957648]\n",
      "[1.        0.6162348 0.5544195]\n",
      "Epoch 2234/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8582 - val_loss: 4.2422\n",
      "Epoch 2235/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8173 - val_loss: 3.6935\n",
      "Epoch 2236/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7262 - val_loss: 4.0748\n",
      "[0.50280213 0.47205716 0.40921438]\n",
      "[0.5136105  0.50025326 0.4996057 ]\n",
      "[1.         0.61603904 0.5570784 ]\n",
      "Epoch 2237/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8977 - val_loss: 6.1544\n",
      "Epoch 2238/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7533 - val_loss: 5.7903\n",
      "Epoch 2239/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8679 - val_loss: 4.0048\n",
      "[0.5019437  0.46938568 0.40786254]\n",
      "[0.51293635 0.50021064 0.49963027]\n",
      "[1.         0.6046985  0.54794174]\n",
      "Epoch 2240/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7437 - val_loss: 6.0505\n",
      "Epoch 2241/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7307 - val_loss: 4.0518\n",
      "Epoch 2242/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7968 - val_loss: 3.5991\n",
      "[0.50047845 0.47155282 0.4039575 ]\n",
      "[0.5123698  0.50032437 0.49957645]\n",
      "[1.         0.59768057 0.5489485 ]\n",
      "Epoch 2243/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7722 - val_loss: 5.7850\n",
      "Epoch 2244/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7124 - val_loss: 6.0196\n",
      "Epoch 2245/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7940 - val_loss: 4.0581\n",
      "[0.5028264  0.46929914 0.41159937]\n",
      "[0.51427996 0.50018585 0.4996377 ]\n",
      "[1.        0.5984026 0.5502057]\n",
      "Epoch 2246/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7015 - val_loss: 5.8352\n",
      "Epoch 2247/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8491 - val_loss: 4.1505\n",
      "Epoch 2248/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7919 - val_loss: 6.1032\n",
      "[0.49820277 0.46623424 0.3741128 ]\n",
      "[0.50916255 0.5000515  0.49962625]\n",
      "[1.         0.59710306 0.56602365]\n",
      "Epoch 2249/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7679 - val_loss: 3.5459\n",
      "Epoch 2250/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6745 - val_loss: 4.0380\n",
      "Epoch 2251/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6829 - val_loss: 5.0605\n",
      "[0.4999869  0.46989256 0.3691577 ]\n",
      "[0.51214844 0.50007707 0.49959844]\n",
      "[1.         0.60587907 0.5615378 ]\n",
      "Epoch 2252/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8939 - val_loss: 3.7596\n",
      "Epoch 2253/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6847 - val_loss: 5.8773\n",
      "Epoch 2254/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7756 - val_loss: 3.7568\n",
      "[0.5014832  0.4699342  0.37685293]\n",
      "[0.51443034 0.50009465 0.499509  ]\n",
      "[1.        0.5979492 0.5587037]\n",
      "Epoch 2255/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7593 - val_loss: 5.8446\n",
      "Epoch 2256/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7214 - val_loss: 5.9724\n",
      "Epoch 2257/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7067 - val_loss: 4.2021\n",
      "[0.5057659  0.469012   0.38280967]\n",
      "[0.5183513  0.50015914 0.49946874]\n",
      "[1.        0.5875665 0.5634054]\n",
      "Epoch 2258/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7643 - val_loss: 3.6946\n",
      "Epoch 2259/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8455 - val_loss: 3.7637\n",
      "Epoch 2260/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7297 - val_loss: 3.7880\n",
      "[0.50201285 0.46773446 0.38807243]\n",
      "[0.51466155 0.500077   0.49947095]\n",
      "[1.         0.58729094 0.5616852 ]\n",
      "Epoch 2261/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8482 - val_loss: 3.8752\n",
      "Epoch 2262/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.5418 - val_loss: 3.8775\n",
      "Epoch 2263/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8521 - val_loss: 5.2784\n",
      "[0.49974406 0.46740666 0.4018022 ]\n",
      "[0.5130602 0.5000421 0.4994558]\n",
      "[1.         0.57977414 0.5618332 ]\n",
      "Epoch 2264/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7638 - val_loss: 5.5773\n",
      "Epoch 2265/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6378 - val_loss: 4.0574\n",
      "Epoch 2266/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9830 - val_loss: 2.9274\n",
      "[0.50038624 0.47037807 0.38877878]\n",
      "[0.5146533  0.50011617 0.49941033]\n",
      "[1.        0.5885001 0.5553359]\n",
      "Epoch 2267/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8285 - val_loss: 3.5021\n",
      "Epoch 2268/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7864 - val_loss: 3.6642\n",
      "Epoch 2269/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7526 - val_loss: 5.7394\n",
      "[0.48060286 0.4561257  0.37278244]\n",
      "[0.51000184 0.5000409  0.49935544]\n",
      "[1.         0.63530576 0.53703564]\n",
      "Epoch 2270/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6386 - val_loss: 5.7146\n",
      "Epoch 2271/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6543 - val_loss: 5.6471\n",
      "Epoch 2272/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8033 - val_loss: 4.0495\n",
      "[0.4995469  0.46210057 0.37973243]\n",
      "[0.519297   0.49994695 0.49936634]\n",
      "[1.         0.60461164 0.55503136]\n",
      "Epoch 2273/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8550 - val_loss: 5.3367\n",
      "Epoch 2274/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9119 - val_loss: 4.1717\n",
      "Epoch 2275/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8386 - val_loss: 2.6505\n",
      "[0.50004727 0.46335107 0.37198454]\n",
      "[0.5133488  0.49993962 0.49939966]\n",
      "[1.         0.60073215 0.55706215]\n",
      "Epoch 2276/10000\n",
      "2268/2268 [==============================] - 26s 11ms/step - loss: 0.5664 - val_loss: 4.1713\n",
      "Epoch 2277/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8055 - val_loss: 4.0412\n",
      "Epoch 2278/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7010 - val_loss: 3.9632\n",
      "[0.50305396 0.46478108 0.3674091 ]\n",
      "[0.5159873  0.49995443 0.4994086 ]\n",
      "[1.        0.5868073 0.560106 ]\n",
      "Epoch 2279/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6440 - val_loss: 5.8112\n",
      "Epoch 2280/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8398 - val_loss: 3.9667\n",
      "Epoch 2281/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8150 - val_loss: 3.0186\n",
      "[0.50031894 0.4656453  0.4078738 ]\n",
      "[0.5136779  0.4999999  0.49944207]\n",
      "[1.        0.5783666 0.5537278]\n",
      "Epoch 2282/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6409 - val_loss: 5.7640\n",
      "Epoch 2283/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6473 - val_loss: 5.4835\n",
      "Epoch 2284/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7138 - val_loss: 3.1569\n",
      "[0.50065887 0.46563938 0.4047061 ]\n",
      "[0.5145772  0.49999353 0.499448  ]\n",
      "[1.         0.5762001  0.56483257]\n",
      "Epoch 2285/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5835 - val_loss: 3.7929\n",
      "Epoch 2286/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6004 - val_loss: 3.7138\n",
      "Epoch 2287/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8247 - val_loss: 5.6194\n",
      "[0.49846122 0.46128917 0.4052189 ]\n",
      "[0.5128164  0.49987665 0.49948174]\n",
      "[1.         0.5800519  0.56880563]\n",
      "Epoch 2288/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7740 - val_loss: 3.7656\n",
      "Epoch 2289/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8548 - val_loss: 5.5598\n",
      "Epoch 2290/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8675 - val_loss: 3.4833\n",
      "[0.5005918  0.45637414 0.392445  ]\n",
      "[0.51485157 0.4998056  0.49946105]\n",
      "[1.         0.61621606 0.5700295 ]\n",
      "Epoch 2291/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7713 - val_loss: 5.6266\n",
      "Epoch 2292/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8839 - val_loss: 5.6197\n",
      "Epoch 2293/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7776 - val_loss: 3.0977\n",
      "[0.49508438 0.45850462 0.37487787]\n",
      "[0.51432675 0.49979728 0.49942246]\n",
      "[1.         0.60887706 0.56593037]\n",
      "Epoch 2294/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8221 - val_loss: 3.4875\n",
      "Epoch 2295/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7491 - val_loss: 5.6492\n",
      "Epoch 2296/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7704 - val_loss: 5.3906\n",
      "[0.4727111  0.45074958 0.39248905]\n",
      "[0.5132806  0.49971017 0.49942762]\n",
      "[1.         0.58166265 0.5913235 ]\n",
      "Epoch 2297/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7152 - val_loss: 3.3721\n",
      "Epoch 2298/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7866 - val_loss: 5.5076\n",
      "Epoch 2299/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6679 - val_loss: 3.6184\n",
      "[0.44808346 0.4508726  0.42088795]\n",
      "[0.51583636 0.49976903 0.4995135 ]\n",
      "[1.         0.56532675 0.5615424 ]\n",
      "Epoch 2300/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8573 - val_loss: 3.6404\n",
      "Epoch 2301/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7185 - val_loss: 4.1814\n",
      "Epoch 2302/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8421 - val_loss: 3.9290\n",
      "[0.47837037 0.44979623 0.4230089 ]\n",
      "[0.5167468  0.49969494 0.4995605 ]\n",
      "[1.        0.5666399 0.5558405]\n",
      "Epoch 2303/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6615 - val_loss: 5.2522\n",
      "Epoch 2304/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7446 - val_loss: 2.3177\n",
      "Epoch 2305/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8536 - val_loss: 3.2260\n",
      "[0.481895   0.44591188 0.4216172 ]\n",
      "[0.51488465 0.49953267 0.499627  ]\n",
      "[1.        0.5652939 0.5557333]\n",
      "Epoch 2306/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8156 - val_loss: 3.4697\n",
      "Epoch 2307/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7643 - val_loss: 2.4513\n",
      "Epoch 2308/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6666 - val_loss: 2.7621\n",
      "[0.48480237 0.4486321  0.42409313]\n",
      "[0.5131379  0.49950704 0.49964547]\n",
      "[1.         0.5537842  0.55127716]\n",
      "Epoch 2309/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7757 - val_loss: 2.8799\n",
      "Epoch 2310/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8086 - val_loss: 3.7645\n",
      "Epoch 2311/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7646 - val_loss: 2.7795\n",
      "[0.4975865  0.45087638 0.42626226]\n",
      "[0.51234573 0.49977362 0.49974948]\n",
      "[1.        0.5792531 0.5516964]\n",
      "Epoch 2312/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7070 - val_loss: 5.5837\n",
      "Epoch 2313/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9097 - val_loss: 3.8602\n",
      "Epoch 2314/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6985 - val_loss: 3.7483\n",
      "[0.5001705  0.45251402 0.43112886]\n",
      "[0.51534986 0.49987948 0.4997672 ]\n",
      "[1.         0.58546036 0.55539787]\n",
      "Epoch 2315/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7017 - val_loss: 3.1786\n",
      "Epoch 2316/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6546 - val_loss: 5.4702\n",
      "Epoch 2317/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8291 - val_loss: 4.9449\n",
      "[0.49894395 0.4549637  0.430777  ]\n",
      "[0.5128596  0.49987164 0.49970564]\n",
      "[1.        0.5924617 0.5522915]\n",
      "Epoch 2318/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7029 - val_loss: 3.7778\n",
      "Epoch 2319/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8809 - val_loss: 1.6950\n",
      "Epoch 2320/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.5700 - val_loss: 3.9463\n",
      "[0.50532734 0.45239425 0.42770126]\n",
      "[0.51931924 0.49985978 0.4996567 ]\n",
      "[1.         0.59868866 0.5491028 ]\n",
      "Epoch 2321/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6772 - val_loss: 5.5204\n",
      "Epoch 2322/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.5362 - val_loss: 3.6474\n",
      "Epoch 2323/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8858 - val_loss: 2.5521\n",
      "[0.49971125 0.4606477  0.43159238]\n",
      "[0.5135     0.49998817 0.4996452 ]\n",
      "[1.         0.59998524 0.5503007 ]\n",
      "Epoch 2324/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7912 - val_loss: 3.0642\n",
      "Epoch 2325/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6442 - val_loss: 3.1375\n",
      "Epoch 2326/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6319 - val_loss: 3.8712\n",
      "[0.5043574 0.4567234 0.4250671]\n",
      "[0.52033335 0.49978116 0.49959642]\n",
      "[1.        0.5937688 0.5575039]\n",
      "Epoch 2327/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8471 - val_loss: 5.0616\n",
      "Epoch 2328/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8189 - val_loss: 3.3339\n",
      "Epoch 2329/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5556 - val_loss: 3.3937\n",
      "[0.5025651  0.46012095 0.42722186]\n",
      "[0.5175394  0.49982184 0.49959284]\n",
      "[1.         0.59888995 0.5561128 ]\n",
      "Epoch 2330/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7256 - val_loss: 2.9530\n",
      "Epoch 2331/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6459 - val_loss: 4.9326\n",
      "Epoch 2332/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6254 - val_loss: 3.8360\n",
      "[0.50474477 0.46354845 0.42311305]\n",
      "[0.51906174 0.4999576  0.49961093]\n",
      "[1.         0.5905293  0.55055904]\n",
      "Epoch 2333/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6739 - val_loss: 3.4119\n",
      "Epoch 2334/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6481 - val_loss: 5.2372\n",
      "Epoch 2335/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7536 - val_loss: 5.5342\n",
      "[0.49749967 0.46285823 0.43007734]\n",
      "[0.5124592  0.49997005 0.49965003]\n",
      "[1.        0.5873271 0.5589011]\n",
      "Epoch 2336/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5869 - val_loss: 3.6936\n",
      "Epoch 2337/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7639 - val_loss: 2.8605\n",
      "Epoch 2338/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7862 - val_loss: 3.8200\n",
      "[0.5052521  0.46590644 0.42693326]\n",
      "[0.5199222 0.500156  0.4995638]\n",
      "[1.         0.5735158  0.55718136]\n",
      "Epoch 2339/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7469 - val_loss: 3.2478\n",
      "Epoch 2340/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8795 - val_loss: 3.3218\n",
      "Epoch 2341/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6532 - val_loss: 5.5036\n",
      "[0.49798906 0.4624537  0.43172672]\n",
      "[0.5128729  0.5001316  0.49959475]\n",
      "[1.         0.57148874 0.5494789 ]\n",
      "Epoch 2342/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6603 - val_loss: 3.6285\n",
      "Epoch 2343/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8912 - val_loss: 3.7965\n",
      "Epoch 2344/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7175 - val_loss: 2.0369\n",
      "[0.49904498 0.45229894 0.43327278]\n",
      "[0.514768  0.4999499 0.4996273]\n",
      "[1.         0.5765794  0.54600704]\n",
      "Epoch 2345/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8014 - val_loss: 3.3682\n",
      "Epoch 2346/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7222 - val_loss: 4.8609\n",
      "Epoch 2347/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8583 - val_loss: 2.5745\n",
      "[0.4990518  0.45981577 0.4310915 ]\n",
      "[0.5137269  0.49996912 0.4997027 ]\n",
      "[1.         0.5599702  0.55256116]\n",
      "Epoch 2348/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5134 - val_loss: 5.5842\n",
      "Epoch 2349/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6989 - val_loss: 5.1867\n",
      "Epoch 2350/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7564 - val_loss: 4.4953\n",
      "[0.49611333 0.45975697 0.42881095]\n",
      "[0.5143238  0.49996978 0.499675  ]\n",
      "[1.        0.5721501 0.5424492]\n",
      "Epoch 2351/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7265 - val_loss: 3.0157\n",
      "Epoch 2352/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7083 - val_loss: 5.3685\n",
      "Epoch 2353/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7689 - val_loss: 3.3829\n",
      "[0.5018043  0.46553    0.42825693]\n",
      "[0.5159256  0.50011533 0.49969074]\n",
      "[1.         0.5692629  0.54645735]\n",
      "Epoch 2354/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6978 - val_loss: 3.3823\n",
      "Epoch 2355/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8554 - val_loss: 3.4110\n",
      "Epoch 2356/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8297 - val_loss: 5.5646\n",
      "[0.49662247 0.46732035 0.42689613]\n",
      "[0.512136   0.5000627  0.49970594]\n",
      "[1.         0.56638646 0.54712236]\n",
      "Epoch 2357/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6818 - val_loss: 5.4879\n",
      "Epoch 2358/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7051 - val_loss: 3.0930\n",
      "Epoch 2359/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5737 - val_loss: 3.6522\n",
      "[0.50314075 0.45778632 0.4283947 ]\n",
      "[0.51664895 0.49997047 0.4997474 ]\n",
      "[1.        0.5741485 0.5408927]\n",
      "Epoch 2360/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5924 - val_loss: 5.4418\n",
      "Epoch 2361/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7207 - val_loss: 3.2107\n",
      "Epoch 2362/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6949 - val_loss: 5.4316\n",
      "[0.49942952 0.46227446 0.43080062]\n",
      "[0.51286954 0.50021094 0.49972704]\n",
      "[1.         0.5672839  0.54223835]\n",
      "Epoch 2363/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8802 - val_loss: 5.7505\n",
      "Epoch 2364/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9208 - val_loss: 3.1670\n",
      "Epoch 2365/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7182 - val_loss: 3.8836\n",
      "[0.5050608  0.4631334  0.43174264]\n",
      "[0.5190955  0.5001807  0.49969384]\n",
      "[1.         0.5797535  0.53579134]\n",
      "Epoch 2366/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6457 - val_loss: 3.0427\n",
      "Epoch 2367/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6065 - val_loss: 2.7044\n",
      "Epoch 2368/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.4734 - val_loss: 3.3706\n",
      "[0.50230795 0.4609983  0.4312461 ]\n",
      "[0.516901  0.500145  0.4996981]\n",
      "[1.        0.5903868 0.5408169]\n",
      "Epoch 2369/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7505 - val_loss: 5.1992\n",
      "Epoch 2370/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8485 - val_loss: 3.8917\n",
      "Epoch 2371/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8336 - val_loss: 4.9169\n",
      "[0.49506575 0.44010553 0.4309693 ]\n",
      "[0.5139305 0.500182  0.4996653]\n",
      "[1.        0.5935784 0.5303125]\n",
      "Epoch 2372/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7636 - val_loss: 3.7404\n",
      "Epoch 2373/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6673 - val_loss: 3.4845\n",
      "Epoch 2374/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6481 - val_loss: 3.7707\n",
      "[0.48368865 0.45127198 0.42582285]\n",
      "[0.51711804 0.50015473 0.49970964]\n",
      "[1.         0.58086336 0.5387488 ]\n",
      "Epoch 2375/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8864 - val_loss: 5.8283\n",
      "Epoch 2376/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7821 - val_loss: 3.9773\n",
      "Epoch 2377/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7827 - val_loss: 3.2072\n",
      "[0.49092382 0.45197678 0.4297211 ]\n",
      "[0.51636887 0.5002332  0.49967733]\n",
      "[1.         0.58515525 0.534526  ]\n",
      "Epoch 2378/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7039 - val_loss: 3.8971\n",
      "Epoch 2379/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8002 - val_loss: 5.8034\n",
      "Epoch 2380/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8560 - val_loss: 2.4090\n",
      "[0.49076155 0.46775872 0.429565  ]\n",
      "[0.51558155 0.50035775 0.4997254 ]\n",
      "[1.         0.5768651  0.53900504]\n",
      "Epoch 2381/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7359 - val_loss: 5.7641\n",
      "Epoch 2382/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8047 - val_loss: 5.6951\n",
      "Epoch 2383/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7535 - val_loss: 1.8253\n",
      "[0.49388513 0.46321005 0.42900735]\n",
      "[0.515609  0.5003475 0.4997324]\n",
      "[1.        0.5797936 0.5402731]\n",
      "Epoch 2384/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8605 - val_loss: 5.6743\n",
      "Epoch 2385/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7721 - val_loss: 2.7146\n",
      "Epoch 2386/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7714 - val_loss: 5.1773\n",
      "[0.47916424 0.4585267  0.4271887 ]\n",
      "[0.51517063 0.50037074 0.4996319 ]\n",
      "[1.         0.58837295 0.5362453 ]\n",
      "Epoch 2387/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8581 - val_loss: 2.2910\n",
      "Epoch 2388/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6506 - val_loss: 3.3961\n",
      "Epoch 2389/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7299 - val_loss: 2.9046\n",
      "[0.46433586 0.4586083  0.42612287]\n",
      "[0.5157203  0.50022435 0.49961284]\n",
      "[1.         0.59431815 0.5402032 ]\n",
      "Epoch 2390/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7578 - val_loss: 3.8283\n",
      "Epoch 2391/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8870 - val_loss: 3.3633\n",
      "Epoch 2392/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6233 - val_loss: 5.2746\n",
      "[0.483056   0.44025108 0.4274744 ]\n",
      "[0.5139994  0.50022954 0.49960858]\n",
      "[1.         0.60340095 0.52982163]\n",
      "Epoch 2393/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6876 - val_loss: 3.1419\n",
      "Epoch 2394/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7851 - val_loss: 4.0510\n",
      "Epoch 2395/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7969 - val_loss: 3.4034\n",
      "[0.48046884 0.4221009  0.42479292]\n",
      "[0.5171688  0.5000739  0.49965218]\n",
      "[1.         0.61803705 0.53828293]\n",
      "Epoch 2396/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7774 - val_loss: 2.8997\n",
      "Epoch 2397/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6117 - val_loss: 3.1573\n",
      "Epoch 2398/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8129 - val_loss: 5.3270\n",
      "[0.4789753  0.43577924 0.4297701 ]\n",
      "[0.51383775 0.5002324  0.49965152]\n",
      "[1.         0.60215807 0.5308181 ]\n",
      "Epoch 2399/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7364 - val_loss: 3.1994\n",
      "Epoch 2400/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7440 - val_loss: 5.6949\n",
      "Epoch 2401/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.5750 - val_loss: 3.4914\n",
      "[0.49048525 0.43007073 0.4290482 ]\n",
      "[0.5176341  0.500195   0.49962977]\n",
      "[1.         0.60263133 0.5377267 ]\n",
      "Epoch 2402/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8383 - val_loss: 3.3031\n",
      "Epoch 2403/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8158 - val_loss: 3.0062\n",
      "Epoch 2404/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8142 - val_loss: 5.5162\n",
      "[0.48888186 0.4353454  0.4306144 ]\n",
      "[0.513206   0.50000817 0.49977714]\n",
      "[1.         0.6048052  0.54692894]\n",
      "Epoch 2405/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9394 - val_loss: 5.8453\n",
      "Epoch 2406/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8473 - val_loss: 5.4367\n",
      "Epoch 2407/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8031 - val_loss: 4.8404\n",
      "[0.4984936  0.43779382 0.4311431 ]\n",
      "[0.5147757 0.5000101 0.4997813]\n",
      "[1.         0.61301327 0.54289216]\n",
      "Epoch 2408/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7622 - val_loss: 3.7952\n",
      "Epoch 2409/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8291 - val_loss: 2.9108\n",
      "Epoch 2410/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7820 - val_loss: 2.4817\n",
      "[0.5000139  0.44032255 0.43009248]\n",
      "[0.5156857 0.5000122 0.4998531]\n",
      "[1.        0.6034906 0.5517162]\n",
      "Epoch 2411/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8426 - val_loss: 3.5725\n",
      "Epoch 2412/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6502 - val_loss: 3.8263\n",
      "Epoch 2413/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8326 - val_loss: 2.9741\n",
      "[0.49931258 0.4464962  0.43021777]\n",
      "[0.5164426  0.5000212  0.49983218]\n",
      "[1.         0.6053646  0.54685926]\n",
      "Epoch 2414/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7758 - val_loss: 3.5397\n",
      "Epoch 2415/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7093 - val_loss: 3.5786\n",
      "Epoch 2416/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6333 - val_loss: 4.3876\n",
      "[0.4859376  0.4331507  0.42979953]\n",
      "[0.5157975  0.4999684  0.49984378]\n",
      "[1.         0.6188611  0.54498875]\n",
      "Epoch 2417/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6912 - val_loss: 3.6401\n",
      "Epoch 2418/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6292 - val_loss: 2.4957\n",
      "Epoch 2419/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7936 - val_loss: 3.4200\n",
      "[0.49712443 0.42260912 0.4375062 ]\n",
      "[0.51719284 0.49976516 0.49995413]\n",
      "[1.         0.6192933  0.54344064]\n",
      "Epoch 2420/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7646 - val_loss: 5.1096\n",
      "Epoch 2421/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8164 - val_loss: 3.0406\n",
      "Epoch 2422/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7408 - val_loss: 1.6352\n",
      "[0.49692428 0.42749003 0.43441546]\n",
      "[0.5153233  0.499875   0.49993923]\n",
      "[1.         0.61991954 0.54380125]\n",
      "Epoch 2423/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7679 - val_loss: 3.3254\n",
      "Epoch 2424/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7097 - val_loss: 3.3682\n",
      "Epoch 2425/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7401 - val_loss: 3.4222\n",
      "[0.4928316 0.4137794 0.4425847]\n",
      "[0.51703286 0.49948895 0.50001293]\n",
      "[1.         0.62335247 0.54115254]\n",
      "Epoch 2426/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7923 - val_loss: 3.4806\n",
      "Epoch 2427/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8420 - val_loss: 3.2521\n",
      "Epoch 2428/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7929 - val_loss: 3.7344\n",
      "[0.4978562 0.4041189 0.4296577]\n",
      "[0.51848686 0.4995491  0.50002086]\n",
      "[1.        0.6254957 0.5403767]\n",
      "Epoch 2429/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7672 - val_loss: 2.6547\n",
      "Epoch 2430/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6863 - val_loss: 3.2851\n",
      "Epoch 2431/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6319 - val_loss: 3.8483\n",
      "[0.49001136 0.42276567 0.42929304]\n",
      "[0.51969475 0.49954677 0.49997997]\n",
      "[1.         0.6281396  0.54243076]\n",
      "Epoch 2432/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9359 - val_loss: 2.3061\n",
      "Epoch 2433/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8502 - val_loss: 3.6522\n",
      "Epoch 2434/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7823 - val_loss: 3.5640\n",
      "[0.50248927 0.39192316 0.43486077]\n",
      "[0.5186284 0.4993423 0.5000194]\n",
      "[1.         0.6149904  0.54390776]\n",
      "Epoch 2435/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7526 - val_loss: 3.4954\n",
      "Epoch 2436/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6646 - val_loss: 3.3444\n",
      "Epoch 2437/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7740 - val_loss: 3.3175\n",
      "[0.4985172  0.38954568 0.4182485 ]\n",
      "[0.51683086 0.49943042 0.49994662]\n",
      "[1.        0.6236841 0.5461378]\n",
      "Epoch 2438/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6865 - val_loss: 3.2717\n",
      "Epoch 2439/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8457 - val_loss: 5.6750\n",
      "Epoch 2440/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6732 - val_loss: 3.7436\n",
      "[0.50339895 0.38939852 0.43286374]\n",
      "[0.5190614  0.49961567 0.49989882]\n",
      "[1.         0.6139821  0.55154735]\n",
      "Epoch 2441/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7496 - val_loss: 5.7718\n",
      "Epoch 2442/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7176 - val_loss: 5.4445\n",
      "Epoch 2443/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9404 - val_loss: 5.4886\n",
      "[0.49908894 0.3875878  0.43709958]\n",
      "[0.5148899  0.49959007 0.4998982 ]\n",
      "[1.         0.6164439  0.54698825]\n",
      "Epoch 2444/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8297 - val_loss: 3.0932\n",
      "Epoch 2445/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7097 - val_loss: 3.9353\n",
      "Epoch 2446/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8469 - val_loss: 5.7644\n",
      "[0.49621734 0.3996608  0.4367268 ]\n",
      "[0.51172674 0.49963653 0.49983296]\n",
      "[1.         0.61212045 0.54864204]\n",
      "Epoch 2447/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6189 - val_loss: 3.0761\n",
      "Epoch 2448/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0061 - val_loss: 3.8727\n",
      "Epoch 2449/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8071 - val_loss: 2.6533\n",
      "[0.49311826 0.38927135 0.43204653]\n",
      "[0.51542366 0.4996133  0.499823  ]\n",
      "[1.        0.6150579 0.5459746]\n",
      "Epoch 2450/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8105 - val_loss: 3.4467\n",
      "Epoch 2451/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6957 - val_loss: 5.5794\n",
      "Epoch 2452/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7902 - val_loss: 3.7293\n",
      "[0.49062097 0.38132942 0.43291527]\n",
      "[0.51865655 0.49965784 0.49983636]\n",
      "[1.        0.6182469 0.5449077]\n",
      "Epoch 2453/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7010 - val_loss: 3.4919\n",
      "Epoch 2454/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9441 - val_loss: 5.7805\n",
      "Epoch 2455/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7627 - val_loss: 5.7539\n",
      "[0.49681112 0.3974519  0.43286878]\n",
      "[0.5121473  0.49965742 0.49983555]\n",
      "[1.         0.6142918  0.55177015]\n",
      "Epoch 2456/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6840 - val_loss: 3.9973\n",
      "Epoch 2457/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9179 - val_loss: 3.2867\n",
      "Epoch 2458/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7439 - val_loss: 5.7032\n",
      "[0.49344867 0.3812497  0.43567878]\n",
      "[0.51361805 0.49956986 0.49986413]\n",
      "[1.        0.6171851 0.5497832]\n",
      "Epoch 2459/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9269 - val_loss: 5.7341\n",
      "Epoch 2460/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7427 - val_loss: 3.7129\n",
      "Epoch 2461/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9194 - val_loss: 2.8473\n",
      "[0.49898034 0.37667382 0.41665477]\n",
      "[0.51618814 0.49945128 0.49993113]\n",
      "[1.         0.64412355 0.55596864]\n",
      "Epoch 2462/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6612 - val_loss: 5.6426\n",
      "Epoch 2463/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8795 - val_loss: 5.7090\n",
      "Epoch 2464/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8249 - val_loss: 3.5052\n",
      "[0.47199953 0.37572724 0.4299762 ]\n",
      "[0.5172617  0.49961856 0.49993274]\n",
      "[1.         0.6259005  0.56083244]\n",
      "Epoch 2465/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7722 - val_loss: 2.0994\n",
      "Epoch 2466/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.9281 - val_loss: 5.2550\n",
      "Epoch 2467/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7518 - val_loss: 5.6345\n",
      "[0.4979207  0.3743506  0.42172197]\n",
      "[0.51338446 0.49950078 0.49998006]\n",
      "[1.        0.632951  0.5601231]\n",
      "Epoch 2468/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.9396 - val_loss: 3.5070\n",
      "Epoch 2469/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6945 - val_loss: 2.5791\n",
      "Epoch 2470/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8526 - val_loss: 3.6294\n",
      "[0.50135624 0.37424198 0.42622924]\n",
      "[0.5183411  0.49964812 0.499989  ]\n",
      "[1.         0.620561   0.56158894]\n",
      "Epoch 2471/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7817 - val_loss: 3.6234\n",
      "Epoch 2472/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6992 - val_loss: 3.6658\n",
      "Epoch 2473/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5449 - val_loss: 3.9009\n",
      "[0.5047147  0.40167916 0.42615002]\n",
      "[0.51980793 0.4998562  0.49990743]\n",
      "[1.         0.61738867 0.55963516]\n",
      "Epoch 2474/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8040 - val_loss: 3.9194\n",
      "Epoch 2475/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8391 - val_loss: 5.6625\n",
      "Epoch 2476/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7604 - val_loss: 3.4564\n",
      "[0.5011044  0.37579787 0.42673606]\n",
      "[0.51754683 0.499407   0.49994394]\n",
      "[1.         0.62726504 0.55934805]\n",
      "Epoch 2477/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8727 - val_loss: 5.1261\n",
      "Epoch 2478/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7407 - val_loss: 3.7589\n",
      "Epoch 2479/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8136 - val_loss: 2.7161\n",
      "[0.49019456 0.39261475 0.39503407]\n",
      "[0.51485306 0.49925196 0.49983212]\n",
      "[1.         0.6371636  0.55887806]\n",
      "Epoch 2480/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8649 - val_loss: 3.1600\n",
      "Epoch 2481/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6392 - val_loss: 3.6996\n",
      "Epoch 2482/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5940 - val_loss: 5.5416\n",
      "[0.465039   0.3819437  0.40048516]\n",
      "[0.5128693  0.49922654 0.49985316]\n",
      "[1.         0.6379895  0.55748016]\n",
      "Epoch 2483/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7630 - val_loss: 5.0900\n",
      "Epoch 2484/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6686 - val_loss: 5.6227\n",
      "Epoch 2485/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6809 - val_loss: 3.9123\n",
      "[0.4687606  0.38447633 0.41768405]\n",
      "[0.51902246 0.4992266  0.49986678]\n",
      "[1.        0.6437653 0.5602739]\n",
      "Epoch 2486/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7376 - val_loss: 3.3435\n",
      "Epoch 2487/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6363 - val_loss: 3.7509\n",
      "Epoch 2488/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5147 - val_loss: 3.9864\n",
      "[0.47590762 0.38479936 0.430941  ]\n",
      "[0.5189861  0.49929795 0.4999133 ]\n",
      "[1.        0.6355714 0.5538111]\n",
      "Epoch 2489/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7441 - val_loss: 2.9923\n",
      "Epoch 2490/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7826 - val_loss: 3.7244\n",
      "Epoch 2491/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9078 - val_loss: 5.7201\n",
      "[0.47159705 0.38557974 0.42974478]\n",
      "[0.50990725 0.49934995 0.49989372]\n",
      "[1.         0.63314366 0.5565434 ]\n",
      "Epoch 2492/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8543 - val_loss: 5.4900\n",
      "Epoch 2493/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7943 - val_loss: 5.6842\n",
      "Epoch 2494/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8408 - val_loss: 3.2390\n",
      "[0.48019144 0.38751602 0.42318553]\n",
      "[0.514045  0.4993311 0.499971 ]\n",
      "[1.         0.627895   0.55042094]\n",
      "Epoch 2495/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9227 - val_loss: 2.7698\n",
      "Epoch 2496/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7066 - val_loss: 2.7190\n",
      "Epoch 2497/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8659 - val_loss: 5.7113\n",
      "[0.46074092 0.39033416 0.41016906]\n",
      "[0.51095414 0.49940902 0.49994752]\n",
      "[1.        0.6598771 0.5440215]\n",
      "Epoch 2498/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7402 - val_loss: 3.1052\n",
      "Epoch 2499/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6952 - val_loss: 3.1671\n",
      "Epoch 2500/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8310 - val_loss: 5.7734\n",
      "[0.47152922 0.38736063 0.39713722]\n",
      "[0.5082883  0.49936706 0.49987462]\n",
      "[1.         0.65959346 0.5417936 ]\n",
      "Epoch 2501/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7712 - val_loss: 3.2367\n",
      "Epoch 2502/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7781 - val_loss: 2.7587\n",
      "Epoch 2503/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8901 - val_loss: 2.9262\n",
      "[0.49081948 0.38299328 0.4107887 ]\n",
      "[0.5143169  0.4991329  0.49994993]\n",
      "[1.         0.63752645 0.5479811 ]\n",
      "Epoch 2504/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9391 - val_loss: 3.8265\n",
      "Epoch 2505/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6975 - val_loss: 2.9060\n",
      "Epoch 2506/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6332 - val_loss: 4.6616\n",
      "[0.4769644  0.39060456 0.42223287]\n",
      "[0.51345295 0.4989925  0.5000214 ]\n",
      "[1.        0.6547615 0.5488947]\n",
      "Epoch 2507/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7331 - val_loss: 2.9474\n",
      "Epoch 2508/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8869 - val_loss: 2.3212\n",
      "Epoch 2509/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5753 - val_loss: 3.2688\n",
      "[0.49005586 0.3932952  0.42090243]\n",
      "[0.5157279  0.49907354 0.50000674]\n",
      "[1.        0.6608307 0.5438884]\n",
      "Epoch 2510/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8252 - val_loss: 1.9161\n",
      "Epoch 2511/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8036 - val_loss: 2.1020\n",
      "Epoch 2512/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7605 - val_loss: 3.3173\n",
      "[0.49563313 0.39530075 0.39929843]\n",
      "[0.51759076 0.49869514 0.49994454]\n",
      "[1.         0.6565204  0.54669625]\n",
      "Epoch 2513/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8283 - val_loss: 2.6128\n",
      "Epoch 2514/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8159 - val_loss: 2.9664\n",
      "Epoch 2515/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7894 - val_loss: 2.7140\n",
      "[0.5000297  0.38366076 0.40938425]\n",
      "[0.5149031  0.49872428 0.4999624 ]\n",
      "[1.         0.6653371  0.54788285]\n",
      "Epoch 2516/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7869 - val_loss: 3.0850\n",
      "Epoch 2517/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8023 - val_loss: 5.3993\n",
      "Epoch 2518/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.9520 - val_loss: 4.9565\n",
      "[0.49819183 0.3878069  0.4307566 ]\n",
      "[0.513744   0.49872047 0.5000757 ]\n",
      "[1.         0.65389115 0.5463972 ]\n",
      "Epoch 2519/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6803 - val_loss: 3.3735\n",
      "Epoch 2520/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7992 - val_loss: 2.5878\n",
      "Epoch 2521/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7566 - val_loss: 3.3547\n",
      "[0.48981315 0.38484702 0.43203136]\n",
      "[0.51741534 0.4985285  0.5001379 ]\n",
      "[1.         0.6424929  0.54805416]\n",
      "Epoch 2522/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7939 - val_loss: 3.2409\n",
      "Epoch 2523/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7573 - val_loss: 3.0419\n",
      "Epoch 2524/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8251 - val_loss: 2.5150\n",
      "[0.4899725  0.39103532 0.42411682]\n",
      "[0.5124749  0.4987042  0.50009614]\n",
      "[1.         0.66547203 0.54651433]\n",
      "Epoch 2525/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6235 - val_loss: 5.2242\n",
      "Epoch 2526/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8422 - val_loss: 4.9518\n",
      "Epoch 2527/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8464 - val_loss: 2.9404\n",
      "[0.49045286 0.38925087 0.42018127]\n",
      "[0.51452744 0.49853778 0.5001059 ]\n",
      "[1.        0.6619246 0.544562 ]\n",
      "Epoch 2528/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6173 - val_loss: 2.8961\n",
      "Epoch 2529/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.9023 - val_loss: 2.5989\n",
      "Epoch 2530/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.5042 - val_loss: 3.0772\n",
      "[0.49391037 0.3763496  0.41767594]\n",
      "[0.5147079  0.49834305 0.5001589 ]\n",
      "[1.        0.6645523 0.5522961]\n",
      "Epoch 2531/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7700 - val_loss: 2.7459\n",
      "Epoch 2532/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8129 - val_loss: 3.2775\n",
      "Epoch 2533/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.4828 - val_loss: 3.7339\n",
      "[0.4903315 0.396553  0.3949118]\n",
      "[0.5184687  0.49837613 0.50015074]\n",
      "[1.         0.67178327 0.55416274]\n",
      "Epoch 2534/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7863 - val_loss: 4.8980\n",
      "Epoch 2535/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7661 - val_loss: 5.2221\n",
      "Epoch 2536/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8371 - val_loss: 3.4496\n",
      "[0.47232562 0.40124258 0.36304125]\n",
      "[0.51461285 0.49835575 0.5001828 ]\n",
      "[1.         0.68462586 0.54985183]\n",
      "Epoch 2537/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6736 - val_loss: 2.0185\n",
      "Epoch 2538/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7644 - val_loss: 4.4340\n",
      "Epoch 2539/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6806 - val_loss: 4.5611\n",
      "[0.48193595 0.40113002 0.38526338]\n",
      "[0.5112571  0.4985633  0.50008774]\n",
      "[1.         0.6829223  0.54374284]\n",
      "Epoch 2540/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9609 - val_loss: 4.8447\n",
      "Epoch 2541/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7588 - val_loss: 2.4709\n",
      "Epoch 2542/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7370 - val_loss: 4.9125\n",
      "[0.48779824 0.37380803 0.4048227 ]\n",
      "[0.51214594 0.49852002 0.500169  ]\n",
      "[1.        0.6764013 0.5431487]\n",
      "Epoch 2543/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6806 - val_loss: 4.9246\n",
      "Epoch 2544/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7409 - val_loss: 3.2806\n",
      "Epoch 2545/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6867 - val_loss: 5.4482\n",
      "[0.49574542 0.38029444 0.43136936]\n",
      "[0.51072943 0.49855602 0.50029916]\n",
      "[1.        0.6601873 0.5451929]\n",
      "Epoch 2546/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8457 - val_loss: 3.2746\n",
      "Epoch 2547/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8535 - val_loss: 2.4589\n",
      "Epoch 2548/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7572 - val_loss: 3.3480\n",
      "[0.50086725 0.3753347  0.41851765]\n",
      "[0.5162176  0.49851713 0.5002054 ]\n",
      "[1.         0.68768805 0.54229945]\n",
      "Epoch 2549/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6839 - val_loss: 1.6945\n",
      "Epoch 2550/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6898 - val_loss: 3.3180\n",
      "Epoch 2551/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7237 - val_loss: 3.1630\n",
      "[0.4812247  0.3834718  0.41815868]\n",
      "[0.51366043 0.498839   0.50021434]\n",
      "[1.         0.67380106 0.54136574]\n",
      "Epoch 2552/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7896 - val_loss: 5.3668\n",
      "Epoch 2553/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5486 - val_loss: 3.4317\n",
      "Epoch 2554/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8531 - val_loss: 4.9055\n",
      "[0.49952927 0.39212814 0.38135836]\n",
      "[0.512602   0.4981914  0.50015986]\n",
      "[1.         0.69180906 0.54206437]\n",
      "Epoch 2555/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6858 - val_loss: 4.7007\n",
      "Epoch 2556/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7159 - val_loss: 2.2538\n",
      "Epoch 2557/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8874 - val_loss: 5.4219\n",
      "[0.485509   0.38176906 0.391369  ]\n",
      "[0.51162416 0.4982038  0.5001133 ]\n",
      "[1.         0.6976276  0.54053515]\n",
      "Epoch 2558/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7696 - val_loss: 3.5188\n",
      "Epoch 2559/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7818 - val_loss: 3.3290\n",
      "Epoch 2560/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8117 - val_loss: 5.1820\n",
      "[0.47376394 0.39308286 0.39745474]\n",
      "[0.51202786 0.49808618 0.5000443 ]\n",
      "[1.        0.6910574 0.541779 ]\n",
      "Epoch 2561/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9212 - val_loss: 3.0610\n",
      "Epoch 2562/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7908 - val_loss: 2.3866\n",
      "Epoch 2563/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7215 - val_loss: 2.5155\n",
      "[0.48084098 0.38701916 0.36276323]\n",
      "[0.5145416  0.49776044 0.50001174]\n",
      "[1.         0.65644217 0.54108423]\n",
      "Epoch 2564/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9232 - val_loss: 2.9156\n",
      "Epoch 2565/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7047 - val_loss: 2.5241\n",
      "Epoch 2566/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7227 - val_loss: 2.6672\n",
      "[0.49330583 0.38134798 0.3615057 ]\n",
      "[0.51623297 0.49744293 0.5000392 ]\n",
      "[1.         0.66380316 0.5404114 ]\n",
      "Epoch 2567/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7443 - val_loss: 3.5915\n",
      "Epoch 2568/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8780 - val_loss: 2.8954\n",
      "Epoch 2569/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6288 - val_loss: 2.7492\n",
      "[0.48550794 0.38066974 0.4225451 ]\n",
      "[0.5136989  0.49812615 0.50023425]\n",
      "[1.         0.6709162  0.54300874]\n",
      "Epoch 2570/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8023 - val_loss: 2.7656\n",
      "Epoch 2571/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6842 - val_loss: 3.1633\n",
      "Epoch 2572/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8851 - val_loss: 5.1287\n",
      "[0.4899336  0.3982185  0.43045756]\n",
      "[0.5125704 0.4983878 0.500186 ]\n",
      "[1.         0.67857426 0.5442871 ]\n",
      "Epoch 2573/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8921 - val_loss: 2.5892\n",
      "Epoch 2574/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7796 - val_loss: 2.5413\n",
      "Epoch 2575/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7209 - val_loss: 5.5647\n",
      "[0.4870254  0.39980963 0.4200167 ]\n",
      "[0.5102165  0.4982608  0.50013226]\n",
      "[1.         0.6874285  0.54291916]\n",
      "Epoch 2576/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6704 - val_loss: 3.3355\n",
      "Epoch 2577/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8207 - val_loss: 5.5498\n",
      "Epoch 2578/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7786 - val_loss: 2.8668\n",
      "[0.46906623 0.39976853 0.42038375]\n",
      "[0.5147457  0.49834555 0.500246  ]\n",
      "[1.         0.69143814 0.5431008 ]\n",
      "Epoch 2579/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8036 - val_loss: 3.1910\n",
      "Epoch 2580/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7546 - val_loss: 5.5812\n",
      "Epoch 2581/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7839 - val_loss: 2.9316\n",
      "[0.49125275 0.40026683 0.4310058 ]\n",
      "[0.514776   0.49890843 0.5002127 ]\n",
      "[1.         0.689216   0.54429567]\n",
      "Epoch 2582/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7170 - val_loss: 5.0996\n",
      "Epoch 2583/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8364 - val_loss: 2.9176\n",
      "Epoch 2584/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7833 - val_loss: 3.6400\n",
      "[0.49593803 0.4004023  0.43040264]\n",
      "[0.5168805  0.5000535  0.50020164]\n",
      "[1.        0.6774739 0.5431645]\n",
      "Epoch 2585/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8507 - val_loss: 2.9101\n",
      "Epoch 2586/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8458 - val_loss: 3.2348\n",
      "Epoch 2587/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7257 - val_loss: 3.9644\n",
      "[0.505343   0.40025032 0.4347974 ]\n",
      "[0.51821166 0.5002755  0.5002368 ]\n",
      "[1.         0.672825   0.54442054]\n",
      "Epoch 2588/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7607 - val_loss: 3.9046\n",
      "Epoch 2589/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7192 - val_loss: 3.5397\n",
      "Epoch 2590/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7514 - val_loss: 3.8778\n",
      "[0.50321484 0.39958826 0.4364341 ]\n",
      "[0.51791316 0.5003119  0.50015545]\n",
      "[1.         0.66435784 0.54355156]\n",
      "Epoch 2591/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7739 - val_loss: 4.5025\n",
      "Epoch 2592/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6777 - val_loss: 5.1729\n",
      "Epoch 2593/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7442 - val_loss: 3.3934\n",
      "[0.5017543  0.39929226 0.41208902]\n",
      "[0.51514065 0.49997705 0.5001529 ]\n",
      "[1.         0.66526    0.54254115]\n",
      "Epoch 2594/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7879 - val_loss: 5.4788\n",
      "Epoch 2595/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5868 - val_loss: 3.6980\n",
      "Epoch 2596/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9419 - val_loss: 2.5220\n",
      "[0.4996182  0.39967456 0.39534938]\n",
      "[0.5122247 0.5003628 0.5001893]\n",
      "[1.        0.6647007 0.5434479]\n",
      "Epoch 2597/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5991 - val_loss: 3.1475\n",
      "Epoch 2598/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7492 - val_loss: 3.7437\n",
      "Epoch 2599/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7470 - val_loss: 3.7622\n",
      "[0.4932225  0.39932698 0.40754032]\n",
      "[0.5134083  0.5011236  0.50021166]\n",
      "[1.        0.6329676 0.5451408]\n",
      "Epoch 2600/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7893 - val_loss: 2.8028\n",
      "Epoch 2601/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8314 - val_loss: 1.2896\n",
      "Epoch 2602/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8444 - val_loss: 5.7653\n",
      "[0.4950718  0.39286745 0.39845258]\n",
      "[0.50633717 0.5002379  0.5002665 ]\n",
      "[1.         0.6369122  0.54639715]\n",
      "Epoch 2603/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7114 - val_loss: 2.4690\n",
      "Epoch 2604/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8093 - val_loss: 3.3284\n",
      "Epoch 2605/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8134 - val_loss: 3.4274\n",
      "[0.49929798 0.3979844  0.36466795]\n",
      "[0.5117067  0.50094277 0.50033194]\n",
      "[1.         0.63284224 0.5469835 ]\n",
      "Epoch 2606/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8272 - val_loss: 5.1609\n",
      "Epoch 2607/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6466 - val_loss: 5.7903\n",
      "Epoch 2608/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6535 - val_loss: 3.4584\n",
      "[0.5008716  0.3940393  0.34933197]\n",
      "[0.51413673 0.5003764  0.5003023 ]\n",
      "[1.         0.65833056 0.54806346]\n",
      "Epoch 2609/10000\n",
      "2268/2268 [==============================] - 25s 11ms/step - loss: 0.7326 - val_loss: 5.5996\n",
      "Epoch 2610/10000\n",
      "2268/2268 [==============================] - 31s 14ms/step - loss: 0.7474 - val_loss: 5.7567\n",
      "Epoch 2611/10000\n",
      "2268/2268 [==============================] - 30s 13ms/step - loss: 0.7641 - val_loss: 3.5784\n",
      "[0.50072753 0.3857952  0.3236159 ]\n",
      "[0.514182  0.5001911 0.5003129]\n",
      "[1.         0.6506412  0.54514474]\n",
      "Epoch 2612/10000\n",
      "2268/2268 [==============================] - 26s 11ms/step - loss: 0.8094 - val_loss: 3.8517\n",
      "Epoch 2613/10000\n",
      "2268/2268 [==============================] - 24s 11ms/step - loss: 0.6743 - val_loss: 3.8889\n",
      "Epoch 2614/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.7340 - val_loss: 3.4051\n",
      "[0.49597484 0.37453577 0.3042076 ]\n",
      "[0.5148336  0.4991111  0.50027364]\n",
      "[1.        0.6530267 0.5462661]\n",
      "Epoch 2615/10000\n",
      "2268/2268 [==============================] - 24s 11ms/step - loss: 0.9086 - val_loss: 3.1262\n",
      "Epoch 2616/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.6374 - val_loss: 2.9012\n",
      "Epoch 2617/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8457 - val_loss: 5.2045\n",
      "[0.49868375 0.38293236 0.2581905 ]\n",
      "[0.5137399  0.49871457 0.5001952 ]\n",
      "[1.         0.6703254  0.54341936]\n",
      "Epoch 2618/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9272 - val_loss: 5.6283\n",
      "Epoch 2619/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.9523 - val_loss: 2.6267\n",
      "Epoch 2620/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7720 - val_loss: 5.6280\n",
      "[0.43728542 0.38480413 0.27344543]\n",
      "[0.51157296 0.49846774 0.5001024 ]\n",
      "[1.         0.6615902  0.54232013]\n",
      "Epoch 2621/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7675 - val_loss: 3.9072\n",
      "Epoch 2622/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7475 - val_loss: 2.7991\n",
      "Epoch 2623/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6538 - val_loss: 2.7342\n",
      "[0.48252013 0.38675222 0.29625517]\n",
      "[0.51315653 0.4986938  0.5000616 ]\n",
      "[1.         0.6541566  0.54319304]\n",
      "Epoch 2624/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8656 - val_loss: 3.4236\n",
      "Epoch 2625/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8515 - val_loss: 3.2306\n",
      "Epoch 2626/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7389 - val_loss: 3.1682\n",
      "[0.48854163 0.387596   0.30385232]\n",
      "[0.5143658  0.49921244 0.5000267 ]\n",
      "[1.         0.6426493  0.54235184]\n",
      "Epoch 2627/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7644 - val_loss: 3.2664\n",
      "Epoch 2628/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8419 - val_loss: 5.1469\n",
      "Epoch 2629/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7546 - val_loss: 3.8720\n",
      "[0.5026247  0.39405733 0.2955029 ]\n",
      "[0.51794994 0.49968293 0.5000528 ]\n",
      "[1.        0.6245314 0.5419003]\n",
      "Epoch 2630/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8020 - val_loss: 5.3115\n",
      "Epoch 2631/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8376 - val_loss: 3.1729\n",
      "Epoch 2632/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8429 - val_loss: 3.0395\n",
      "[0.49559885 0.39798093 0.27199674]\n",
      "[0.5138932  0.49967965 0.500063  ]\n",
      "[1.        0.6074156 0.5422095]\n",
      "Epoch 2633/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9017 - val_loss: 5.6384\n",
      "Epoch 2634/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7153 - val_loss: 3.3068\n",
      "Epoch 2635/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7276 - val_loss: 3.5179\n",
      "[0.4971854  0.38814148 0.24234879]\n",
      "[0.51603585 0.4988934  0.50004923]\n",
      "[1.         0.65443826 0.54231113]\n",
      "Epoch 2636/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6272 - val_loss: 3.7347\n",
      "Epoch 2637/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7716 - val_loss: 3.8277\n",
      "Epoch 2638/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7145 - val_loss: 3.6619\n",
      "[0.49276277 0.37598005 0.2573745 ]\n",
      "[0.51707214 0.4989103  0.50007266]\n",
      "[1.        0.636009  0.5427514]\n",
      "Epoch 2639/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7831 - val_loss: 3.1721\n",
      "Epoch 2640/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8935 - val_loss: 5.5911\n",
      "Epoch 2641/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9309 - val_loss: 5.4571\n",
      "[0.49637148 0.39876685 0.3331806 ]\n",
      "[0.51347125 0.49935362 0.5000862 ]\n",
      "[1.         0.60263175 0.54204524]\n",
      "Epoch 2642/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8927 - val_loss: 5.4795\n",
      "Epoch 2643/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9330 - val_loss: 5.5033\n",
      "Epoch 2644/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7299 - val_loss: 5.6996\n",
      "[0.49773592 0.39721254 0.33209315]\n",
      "[0.51145214 0.49961996 0.5000735 ]\n",
      "[1.        0.5997338 0.5410696]\n",
      "Epoch 2645/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8088 - val_loss: 2.9090\n",
      "Epoch 2646/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7053 - val_loss: 3.1259\n",
      "Epoch 2647/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7256 - val_loss: 3.5704\n",
      "[0.5033528  0.40025026 0.36453137]\n",
      "[0.51694185 0.499651   0.500146  ]\n",
      "[1.        0.6062137 0.539763 ]\n",
      "Epoch 2648/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0061 - val_loss: 2.9071\n",
      "Epoch 2649/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7174 - val_loss: 5.3185\n",
      "Epoch 2650/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7366 - val_loss: 3.1603\n",
      "[0.500846   0.3993551  0.33407146]\n",
      "[0.5154176  0.49982837 0.50008184]\n",
      "[1.        0.6067878 0.5401274]\n",
      "Epoch 2651/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8881 - val_loss: 3.5952\n",
      "Epoch 2652/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7235 - val_loss: 2.8215\n",
      "Epoch 2653/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9280 - val_loss: 5.3961\n",
      "[0.4979471  0.39895833 0.33132583]\n",
      "[0.5124149 0.4992471 0.5000509]\n",
      "[1.         0.61378473 0.5399933 ]\n",
      "Epoch 2654/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8401 - val_loss: 3.7711\n",
      "Epoch 2655/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8093 - val_loss: 3.3751\n",
      "Epoch 2656/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8019 - val_loss: 3.8855\n",
      "[0.46179503 0.39399457 0.3436327 ]\n",
      "[0.51834697 0.4989684  0.50007087]\n",
      "[1.         0.61376053 0.5413841 ]\n",
      "Epoch 2657/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8854 - val_loss: 5.1521\n",
      "Epoch 2658/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6513 - val_loss: 3.0874\n",
      "Epoch 2659/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5840 - val_loss: 4.0832\n",
      "[0.49167272 0.39390236 0.26858515]\n",
      "[0.52104026 0.49869063 0.5000158 ]\n",
      "[1.         0.61155236 0.54119337]\n",
      "Epoch 2660/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7377 - val_loss: 2.9503\n",
      "Epoch 2661/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6493 - val_loss: 3.4587\n",
      "Epoch 2662/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8656 - val_loss: 4.0817\n",
      "[0.47634128 0.38642928 0.29400432]\n",
      "[0.5125737  0.49904585 0.5001387 ]\n",
      "[1.         0.6208105  0.54307336]\n",
      "Epoch 2663/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7311 - val_loss: 0.6252\n",
      "Epoch 2664/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7737 - val_loss: 3.0604\n",
      "Epoch 2665/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0312 - val_loss: 3.6845\n",
      "[0.5039712  0.3949476  0.35279197]\n",
      "[0.517492   0.49904042 0.50005585]\n",
      "[1.        0.6448395 0.543152 ]\n",
      "Epoch 2666/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7855 - val_loss: 2.6848\n",
      "Epoch 2667/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9469 - val_loss: 5.2929\n",
      "Epoch 2668/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6526 - val_loss: 2.6596\n",
      "[0.5007267  0.39413792 0.32858723]\n",
      "[0.5157677  0.49806383 0.5001532 ]\n",
      "[1.         0.66101605 0.54204154]\n",
      "Epoch 2669/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8184 - val_loss: 5.1340\n",
      "Epoch 2670/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8868 - val_loss: 3.7081\n",
      "Epoch 2671/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8173 - val_loss: 5.0579\n",
      "[0.49914795 0.40168694 0.34071153]\n",
      "[0.51350826 0.4983665  0.50018466]\n",
      "[1.         0.6549188  0.54192346]\n",
      "Epoch 2672/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7454 - val_loss: 3.4910\n",
      "Epoch 2673/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7955 - val_loss: 1.1367\n",
      "Epoch 2674/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6350 - val_loss: 3.3604\n",
      "[0.50159675 0.40207905 0.3278115 ]\n",
      "[0.5182489  0.49834737 0.5001555 ]\n",
      "[1.        0.6619178 0.541788 ]\n",
      "Epoch 2675/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7852 - val_loss: 4.8208\n",
      "Epoch 2676/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8094 - val_loss: 3.4182\n",
      "Epoch 2677/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7215 - val_loss: 2.9134\n",
      "[0.50067383 0.39631388 0.345191  ]\n",
      "[0.51643157 0.4984419  0.50014347]\n",
      "[1.         0.6097029  0.54495406]\n",
      "Epoch 2678/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7771 - val_loss: 2.9492\n",
      "Epoch 2679/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7798 - val_loss: 2.7196\n",
      "Epoch 2680/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7198 - val_loss: 3.0306\n",
      "[0.4981404  0.40124926 0.34254855]\n",
      "[0.51599437 0.49861294 0.5003973 ]\n",
      "[1.        0.6239032 0.547257 ]\n",
      "Epoch 2681/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6086 - val_loss: 2.8970\n",
      "Epoch 2682/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7000 - val_loss: 2.4018\n",
      "Epoch 2683/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6998 - val_loss: 2.3168\n",
      "[0.4919656  0.39866632 0.3416068 ]\n",
      "[0.5137942  0.49830753 0.500746  ]\n",
      "[1.        0.6276517 0.5498843]\n",
      "Epoch 2684/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7865 - val_loss: 2.9231\n",
      "Epoch 2685/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6252 - val_loss: 3.0114\n",
      "Epoch 2686/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7969 - val_loss: 3.0565\n",
      "[0.498968   0.39914322 0.32477632]\n",
      "[0.5161167  0.49881545 0.5002143 ]\n",
      "[1.         0.6336397  0.54609174]\n",
      "Epoch 2687/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6260 - val_loss: 5.2405\n",
      "Epoch 2688/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7055 - val_loss: 3.6347\n",
      "Epoch 2689/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9144 - val_loss: 3.5488\n",
      "[0.4949433  0.39989832 0.3219369 ]\n",
      "[0.51715314 0.49936697 0.50011986]\n",
      "[1.         0.6286666  0.54552025]\n",
      "Epoch 2690/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7554 - val_loss: 3.6182\n",
      "Epoch 2691/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6817 - val_loss: 3.6017\n",
      "Epoch 2692/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8466 - val_loss: 5.6880\n",
      "[0.48568308 0.40002552 0.31537482]\n",
      "[0.5087347  0.49921542 0.4999104 ]\n",
      "[1.        0.6247535 0.5428193]\n",
      "Epoch 2693/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7364 - val_loss: 3.3146\n",
      "Epoch 2694/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8305 - val_loss: 2.8605\n",
      "Epoch 2695/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6991 - val_loss: 3.4783\n",
      "[0.49893352 0.39646426 0.306397  ]\n",
      "[0.51768655 0.4993144  0.5000018 ]\n",
      "[1.         0.6381312  0.54426163]\n",
      "Epoch 2696/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7246 - val_loss: 3.2379\n",
      "Epoch 2697/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7101 - val_loss: 3.7375\n",
      "Epoch 2698/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7179 - val_loss: 2.9895\n",
      "[0.49656314 0.3977586  0.29808173]\n",
      "[0.5157342  0.49939373 0.49994758]\n",
      "[1.        0.6313302 0.5423368]\n",
      "Epoch 2699/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7853 - val_loss: 2.7264\n",
      "Epoch 2700/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5320 - val_loss: 3.5401\n",
      "Epoch 2701/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6424 - val_loss: 5.4881\n",
      "[0.4855945  0.39872754 0.28316265]\n",
      "[0.51282436 0.49936223 0.49988645]\n",
      "[1.        0.6401127 0.5418454]\n",
      "Epoch 2702/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7805 - val_loss: 3.6868\n",
      "Epoch 2703/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6821 - val_loss: 3.2601\n",
      "Epoch 2704/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6244 - val_loss: 3.3630\n",
      "[0.50036937 0.39747962 0.29755658]\n",
      "[0.5187737  0.4988124  0.50006235]\n",
      "[1.         0.6300019  0.54331785]\n",
      "Epoch 2705/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6444 - val_loss: 3.1153\n",
      "Epoch 2706/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8423 - val_loss: 4.9217\n",
      "Epoch 2707/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7987 - val_loss: 2.2999\n",
      "[0.49636996 0.38708526 0.311787  ]\n",
      "[0.51768994 0.49861777 0.5000979 ]\n",
      "[1.        0.6324636 0.5556623]\n",
      "Epoch 2708/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7102 - val_loss: 3.6565\n",
      "Epoch 2709/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8920 - val_loss: 3.0284\n",
      "Epoch 2710/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6612 - val_loss: 5.3001\n",
      "[0.49811223 0.39086646 0.2926729 ]\n",
      "[0.5146203  0.4986225  0.50008833]\n",
      "[1.         0.6313116  0.55674934]\n",
      "Epoch 2711/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9891 - val_loss: 3.7853\n",
      "Epoch 2712/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8003 - val_loss: 3.6072\n",
      "Epoch 2713/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6066 - val_loss: 3.1875\n",
      "[0.50184804 0.3935737  0.30959594]\n",
      "[0.5181348  0.49919614 0.50000066]\n",
      "[1.        0.6317239 0.5532528]\n",
      "Epoch 2714/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6704 - val_loss: 5.2912\n",
      "Epoch 2715/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8726 - val_loss: 5.2470\n",
      "Epoch 2716/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6064 - val_loss: 2.3186\n",
      "[0.495511   0.39640972 0.3135096 ]\n",
      "[0.51873434 0.4993671  0.49983254]\n",
      "[1.        0.6502747 0.5501257]\n",
      "Epoch 2717/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8399 - val_loss: 2.8698\n",
      "Epoch 2718/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7438 - val_loss: 3.0405\n",
      "Epoch 2719/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6701 - val_loss: 4.8324\n",
      "[0.4848262 0.3908964 0.3107965]\n",
      "[0.5182925  0.49925423 0.5004293 ]\n",
      "[1.         0.64909714 0.557424  ]\n",
      "Epoch 2720/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8452 - val_loss: 4.5094\n",
      "Epoch 2721/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8522 - val_loss: 5.4572\n",
      "Epoch 2722/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6880 - val_loss: 2.9319\n",
      "[0.4887692  0.39408848 0.30321047]\n",
      "[0.5205003  0.4996148  0.50002134]\n",
      "[1.        0.6594285 0.5581908]\n",
      "Epoch 2723/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6490 - val_loss: 4.4597\n",
      "Epoch 2724/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7235 - val_loss: 5.4253\n",
      "Epoch 2725/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6309 - val_loss: 3.4327\n",
      "[0.5010947  0.3945578  0.30486274]\n",
      "[0.52232707 0.49967635 0.5001086 ]\n",
      "[1.         0.6814843  0.55617535]\n",
      "Epoch 2726/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8106 - val_loss: 3.3206\n",
      "Epoch 2727/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8220 - val_loss: 3.1340\n",
      "Epoch 2728/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9286 - val_loss: 3.7547\n",
      "[0.50562304 0.3905459  0.28537637]\n",
      "[0.52540076 0.4992383  0.5000158 ]\n",
      "[1.        0.6870735 0.5597141]\n",
      "Epoch 2729/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7451 - val_loss: 3.4709\n",
      "Epoch 2730/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7549 - val_loss: 4.8555\n",
      "Epoch 2731/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6694 - val_loss: 4.6824\n",
      "[0.49730104 0.39137083 0.2966101 ]\n",
      "[0.5203819  0.49965656 0.4994303 ]\n",
      "[1.         0.69732225 0.5584163 ]\n",
      "Epoch 2732/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8882 - val_loss: 3.1089\n",
      "Epoch 2733/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7719 - val_loss: 3.3082\n",
      "Epoch 2734/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6942 - val_loss: 2.9320\n",
      "[0.5002322  0.39303958 0.30738652]\n",
      "[0.5196696  0.49982032 0.49964577]\n",
      "[1.         0.6880971  0.55075675]\n",
      "Epoch 2735/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.8440 - val_loss: 3.7687\n",
      "Epoch 2736/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7455 - val_loss: 3.1684\n",
      "Epoch 2737/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9926 - val_loss: 2.8601\n",
      "[0.5002052  0.39505866 0.3116647 ]\n",
      "[0.5190258  0.50113094 0.49916148]\n",
      "[1.        0.7108584 0.5509847]\n",
      "Epoch 2738/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6524 - val_loss: 3.6641\n",
      "Epoch 2739/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7766 - val_loss: 5.5312\n",
      "Epoch 2740/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7537 - val_loss: 5.4865\n",
      "[0.49653357 0.3960834  0.31000805]\n",
      "[0.5181675 0.5012037 0.4990758]\n",
      "[1.         0.70643157 0.549967  ]\n",
      "Epoch 2741/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8712 - val_loss: 3.0834\n",
      "Epoch 2742/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.5936 - val_loss: 2.6150\n",
      "Epoch 2743/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6836 - val_loss: 5.9350\n",
      "[0.49694538 0.39567727 0.27991864]\n",
      "[0.5175789  0.50144684 0.4993624 ]\n",
      "[1.         0.71836233 0.554771  ]\n",
      "Epoch 2744/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8084 - val_loss: 3.7530\n",
      "Epoch 2745/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6915 - val_loss: 2.3285\n",
      "Epoch 2746/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8710 - val_loss: 3.6478\n",
      "[0.50155044 0.39450744 0.256591  ]\n",
      "[0.5205154  0.5007529  0.49950773]\n",
      "[1.         0.7075584  0.55380625]\n",
      "Epoch 2747/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7916 - val_loss: 3.0403\n",
      "Epoch 2748/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8895 - val_loss: 5.9892\n",
      "Epoch 2749/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8403 - val_loss: 3.6758\n",
      "[0.4977784  0.3941982  0.24877736]\n",
      "[0.51860964 0.5009573  0.49969515]\n",
      "[1.         0.69354665 0.5526009 ]\n",
      "Epoch 2750/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6868 - val_loss: 3.1764\n",
      "Epoch 2751/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7362 - val_loss: 4.2391\n",
      "Epoch 2752/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8618 - val_loss: 4.3694\n",
      "[0.4963511  0.39400142 0.24789247]\n",
      "[0.51809096 0.5010155  0.49984848]\n",
      "[1.        0.6954382 0.5610767]\n",
      "Epoch 2753/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5856 - val_loss: 4.1072\n",
      "Epoch 2754/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6877 - val_loss: 3.6366\n",
      "Epoch 2755/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8384 - val_loss: 5.6197\n",
      "[0.4878523  0.396388   0.16860762]\n",
      "[0.5120243  0.5016712  0.49941918]\n",
      "[1.         0.77163476 0.54974246]\n",
      "Epoch 2756/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7886 - val_loss: 3.3331\n",
      "Epoch 2757/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7319 - val_loss: 4.0802\n",
      "Epoch 2758/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7169 - val_loss: 3.6313\n",
      "[0.5003149  0.39534467 0.22765845]\n",
      "[0.51710117 0.5011227  0.49979708]\n",
      "[1.         0.7244845  0.55301064]\n",
      "Epoch 2759/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7439 - val_loss: 3.8394\n",
      "Epoch 2760/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8050 - val_loss: 2.7767\n",
      "Epoch 2761/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7849 - val_loss: 4.5806\n",
      "[0.49966404 0.39569345 0.16138297]\n",
      "[0.5147671  0.50149506 0.49942002]\n",
      "[1.        0.7518104 0.558205 ]\n",
      "Epoch 2762/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8914 - val_loss: 5.7417\n",
      "Epoch 2763/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8431 - val_loss: 3.7579\n",
      "Epoch 2764/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8665 - val_loss: 3.7417\n",
      "[0.50018245 0.39678124 0.20284906]\n",
      "[0.51689416 0.50142103 0.49938527]\n",
      "[1.        0.7622615 0.5669086]\n",
      "Epoch 2765/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7005 - val_loss: 3.1519\n",
      "Epoch 2766/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8206 - val_loss: 5.6613\n",
      "Epoch 2767/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7567 - val_loss: 3.2834\n",
      "[0.50003093 0.39939913 0.25613093]\n",
      "[0.51517487 0.5008526  0.4999028 ]\n",
      "[1.         0.6753623  0.56714034]\n",
      "Epoch 2768/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8312 - val_loss: 2.2070\n",
      "Epoch 2769/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6091 - val_loss: 4.7265\n",
      "Epoch 2770/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7004 - val_loss: 3.6266\n",
      "[0.49984142 0.39740875 0.24364668]\n",
      "[0.51653105 0.50004584 0.4993289 ]\n",
      "[1.        0.6576827 0.5681231]\n",
      "Epoch 2771/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6613 - val_loss: 3.2243\n",
      "Epoch 2772/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6472 - val_loss: 2.5482\n",
      "Epoch 2773/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8180 - val_loss: 3.2820\n",
      "[0.5010429  0.4014996  0.25387883]\n",
      "[0.5161646  0.5007166  0.49979988]\n",
      "[1.         0.6482326  0.57361084]\n",
      "Epoch 2774/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5632 - val_loss: 3.8504\n",
      "Epoch 2775/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6615 - val_loss: 4.8353\n",
      "Epoch 2776/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6135 - val_loss: 3.6219\n",
      "[0.5022296  0.40081632 0.25004244]\n",
      "[0.5193746  0.50036836 0.4997902 ]\n",
      "[1.         0.66411835 0.5691523 ]\n",
      "Epoch 2777/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8666 - val_loss: 2.3090\n",
      "Epoch 2778/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7322 - val_loss: 3.4449\n",
      "Epoch 2779/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7426 - val_loss: 3.3950\n",
      "[0.5013145  0.39512533 0.2543629 ]\n",
      "[0.5193058  0.4994736  0.49993768]\n",
      "[1.        0.7229219 0.5667371]\n",
      "Epoch 2780/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8987 - val_loss: 2.6078\n",
      "Epoch 2781/10000\n",
      "2268/2268 [==============================] - 24s 11ms/step - loss: 0.6862 - val_loss: 5.4605\n",
      "Epoch 2782/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8490 - val_loss: 3.3486\n",
      "[0.49793744 0.3952009  0.24555776]\n",
      "[0.5176973  0.4996717  0.49953452]\n",
      "[1.        0.7047888 0.5755706]\n",
      "Epoch 2783/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7363 - val_loss: 3.2696\n",
      "Epoch 2784/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7660 - val_loss: 5.4575\n",
      "Epoch 2785/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6733 - val_loss: 2.7285\n",
      "[0.49860445 0.39292562 0.2416724 ]\n",
      "[0.5170163  0.49977103 0.49963012]\n",
      "[1.         0.71331584 0.57293516]\n",
      "Epoch 2786/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8411 - val_loss: 3.8661\n",
      "Epoch 2787/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7957 - val_loss: 2.8192\n",
      "Epoch 2788/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7138 - val_loss: 3.9712\n",
      "[0.5036192  0.399656   0.24697232]\n",
      "[0.5190424  0.50042963 0.4998305 ]\n",
      "[1.         0.6894484  0.57226443]\n",
      "Epoch 2789/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8046 - val_loss: 3.0377\n",
      "Epoch 2790/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8173 - val_loss: 3.1563\n",
      "Epoch 2791/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7952 - val_loss: 3.8089\n",
      "[0.5013813  0.39492014 0.24549243]\n",
      "[0.5178939  0.50072026 0.49910462]\n",
      "[1.         0.72421885 0.5703931 ]\n",
      "Epoch 2792/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7059 - val_loss: 3.6490\n",
      "Epoch 2793/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5142 - val_loss: 3.4675\n",
      "Epoch 2794/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7763 - val_loss: 3.5279\n",
      "[0.50030684 0.39284292 0.2473304 ]\n",
      "[0.51645625 0.5011818  0.49861637]\n",
      "[1.         0.74329937 0.56862986]\n",
      "Epoch 2795/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7420 - val_loss: 3.9132\n",
      "Epoch 2796/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8031 - val_loss: 3.7399\n",
      "Epoch 2797/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8470 - val_loss: 3.2113\n",
      "[0.4788728  0.39322925 0.2472333 ]\n",
      "[0.5167661  0.5016733  0.49758217]\n",
      "[1.         0.71175826 0.5731603 ]\n",
      "Epoch 2798/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8439 - val_loss: 3.9053\n",
      "Epoch 2799/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6856 - val_loss: 4.8382\n",
      "Epoch 2800/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7660 - val_loss: 3.3635\n",
      "[0.45998824 0.39103162 0.248016  ]\n",
      "[0.51824063 0.500612   0.49819377]\n",
      "[1.         0.70551366 0.5811935 ]\n",
      "Epoch 2801/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6419 - val_loss: 3.0949\n",
      "Epoch 2802/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6899 - val_loss: 3.5989\n",
      "Epoch 2803/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6961 - val_loss: 2.7652\n",
      "[0.46362603 0.39217415 0.24847004]\n",
      "[0.5149994  0.5001923  0.49886414]\n",
      "[1.        0.7171655 0.5815871]\n",
      "Epoch 2804/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7140 - val_loss: 5.5345\n",
      "Epoch 2805/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7433 - val_loss: 4.8903\n",
      "Epoch 2806/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8489 - val_loss: 3.4682\n",
      "[0.47134787 0.39047098 0.24878353]\n",
      "[0.51892304 0.5001069  0.49908996]\n",
      "[1.         0.72883594 0.6035786 ]\n",
      "Epoch 2807/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6608 - val_loss: 3.7192\n",
      "Epoch 2808/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8256 - val_loss: 3.3425\n",
      "Epoch 2809/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7515 - val_loss: 5.1809\n",
      "[0.4754821  0.39073774 0.24823114]\n",
      "[0.5182664  0.5013854  0.49722826]\n",
      "[1.         0.69754833 0.5865459 ]\n",
      "Epoch 2810/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6796 - val_loss: 5.6853\n",
      "Epoch 2811/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6911 - val_loss: 4.7801\n",
      "Epoch 2812/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7180 - val_loss: 3.9227\n",
      "[0.49387515 0.39079657 0.24866495]\n",
      "[0.5179574  0.50068533 0.49839175]\n",
      "[1.         0.6930088  0.59593505]\n",
      "Epoch 2813/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6838 - val_loss: 5.3016\n",
      "Epoch 2814/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6298 - val_loss: 3.7442\n",
      "Epoch 2815/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7638 - val_loss: 3.6668\n",
      "[0.5011727  0.38949937 0.26627463]\n",
      "[0.52038455 0.49982938 0.5003386 ]\n",
      "[1.         0.7189394  0.59698844]\n",
      "Epoch 2816/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6713 - val_loss: 4.0182\n",
      "Epoch 2817/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7401 - val_loss: 3.2005\n",
      "Epoch 2818/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7272 - val_loss: 3.6808\n",
      "[0.50119394 0.3897735  0.25715014]\n",
      "[0.5208077  0.50044745 0.50024205]\n",
      "[1.        0.6954805 0.5904684]\n",
      "Epoch 2819/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.9431 - val_loss: 3.2841\n",
      "Epoch 2820/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7173 - val_loss: 3.9831\n",
      "Epoch 2821/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7215 - val_loss: 4.7021\n",
      "[0.4908483  0.3879257  0.25349945]\n",
      "[0.51609534 0.50085276 0.49987948]\n",
      "[1.        0.6966555 0.6078664]\n",
      "Epoch 2822/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7216 - val_loss: 5.1705\n",
      "Epoch 2823/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6766 - val_loss: 3.8310\n",
      "Epoch 2824/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7484 - val_loss: 4.1042\n",
      "[0.48555195 0.39337593 0.29957467]\n",
      "[0.5214851 0.5007634 0.5002024]\n",
      "[1.        0.6943399 0.6026798]\n",
      "Epoch 2825/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7056 - val_loss: 3.4539\n",
      "Epoch 2826/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.8536 - val_loss: 2.9629\n",
      "Epoch 2827/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7991 - val_loss: 4.1263\n",
      "[0.49929857 0.38905013 0.30337182]\n",
      "[0.5168745  0.50046057 0.50004447]\n",
      "[1.         0.70152676 0.60315424]\n",
      "Epoch 2828/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7727 - val_loss: 5.7518\n",
      "Epoch 2829/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8956 - val_loss: 2.0024\n",
      "Epoch 2830/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7348 - val_loss: 3.4055\n",
      "[0.45766324 0.3895386  0.24633372]\n",
      "[0.517697   0.500884   0.49934533]\n",
      "[1.         0.66009074 0.5812438 ]\n",
      "Epoch 2831/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9244 - val_loss: 2.2165\n",
      "Epoch 2832/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7953 - val_loss: 2.6810\n",
      "Epoch 2833/10000\n",
      "2268/2268 [==============================] - 22s 9ms/step - loss: 0.7502 - val_loss: 2.7342\n",
      "[0.47976735 0.39124775 0.2461671 ]\n",
      "[0.5160797  0.50065947 0.4995158 ]\n",
      "[1.         0.66867036 0.5734573 ]\n",
      "Epoch 2834/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7864 - val_loss: 2.5198\n",
      "Epoch 2835/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.8970 - val_loss: 3.4114\n",
      "Epoch 2836/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7732 - val_loss: 3.6441\n",
      "[0.50289226 0.38657627 0.24895456]\n",
      "[0.5198637 0.5002079 0.4994049]\n",
      "[1.         0.66899085 0.593379  ]\n",
      "Epoch 2837/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.6948 - val_loss: 3.2571\n",
      "Epoch 2838/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.6985 - val_loss: 2.4536\n",
      "Epoch 2839/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.8732 - val_loss: 4.8840\n",
      "[0.49597126 0.3843827  0.2507171 ]\n",
      "[0.5154474 0.4996472 0.4998671]\n",
      "[1.         0.6833671  0.60907185]\n",
      "Epoch 2840/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7524 - val_loss: 4.8616\n",
      "Epoch 2841/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.8540 - val_loss: 2.8485\n",
      "Epoch 2842/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.8446 - val_loss: 2.7377\n",
      "[0.49550056 0.38530904 0.24733335]\n",
      "[0.5182073  0.49994558 0.49920726]\n",
      "[1.         0.67077136 0.5827887 ]\n",
      "Epoch 2843/10000\n",
      "2268/2268 [==============================] - 21s 9ms/step - loss: 0.7853 - val_loss: 3.7322\n",
      "Epoch 2844/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6989 - val_loss: 3.6901\n",
      "Epoch 2845/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.9284 - val_loss: 3.6253\n",
      "[0.496376   0.388915   0.24873304]\n",
      "[0.51972806 0.50010383 0.49965608]\n",
      "[1.         0.684636   0.57674736]\n",
      "Epoch 2846/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8983 - val_loss: 3.2166\n",
      "Epoch 2847/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7605 - val_loss: 3.7352\n",
      "Epoch 2848/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6853 - val_loss: 3.7107\n",
      "[0.49861437 0.39227414 0.25890326]\n",
      "[0.5183693  0.49989963 0.5001128 ]\n",
      "[1.        0.6928731 0.5825153]\n",
      "Epoch 2849/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6902 - val_loss: 3.3919\n",
      "Epoch 2850/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7497 - val_loss: 3.5855\n",
      "Epoch 2851/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6386 - val_loss: 5.2478\n",
      "[0.4969506  0.39180323 0.24924546]\n",
      "[0.51458293 0.500211   0.4997453 ]\n",
      "[1.         0.68921435 0.5768969 ]\n",
      "Epoch 2852/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7414 - val_loss: 3.0552\n",
      "Epoch 2853/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7836 - val_loss: 3.7676\n",
      "Epoch 2854/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7076 - val_loss: 3.6228\n",
      "[0.5026499  0.39086828 0.24817333]\n",
      "[0.52026534 0.5000059  0.49949983]\n",
      "[1.         0.68068725 0.5851201 ]\n",
      "Epoch 2855/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8328 - val_loss: 4.7551\n",
      "Epoch 2856/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.5482 - val_loss: 5.0720\n",
      "Epoch 2857/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7466 - val_loss: 4.1065\n",
      "[0.49841464 0.38935757 0.24464768]\n",
      "[0.51736563 0.5003275  0.49914688]\n",
      "[1.        0.6734042 0.5805225]\n",
      "Epoch 2858/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6803 - val_loss: 3.8763\n",
      "Epoch 2859/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7310 - val_loss: 2.2672\n",
      "Epoch 2860/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7348 - val_loss: 5.4871\n",
      "[0.49333623 0.38921726 0.24478945]\n",
      "[0.51322824 0.500525   0.49923006]\n",
      "[1.         0.66920984 0.5785992 ]\n",
      "Epoch 2861/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7509 - val_loss: 5.3717\n",
      "Epoch 2862/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7376 - val_loss: 5.4606\n",
      "Epoch 2863/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6880 - val_loss: 5.1119\n",
      "[0.4976134  0.3916368  0.25208732]\n",
      "[0.51597905 0.5005108  0.49944624]\n",
      "[1.        0.6800854 0.5833917]\n",
      "Epoch 2864/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6983 - val_loss: 5.4334\n",
      "Epoch 2865/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6646 - val_loss: 5.3787\n",
      "Epoch 2866/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8214 - val_loss: 5.6836\n",
      "[0.49383262 0.3904664  0.2462981 ]\n",
      "[0.51275796 0.5006849  0.49933514]\n",
      "[1.        0.6766758 0.5720016]\n",
      "Epoch 2867/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.5861 - val_loss: 3.8580\n",
      "Epoch 2868/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6865 - val_loss: 4.9378\n",
      "Epoch 2869/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7576 - val_loss: 3.0032\n",
      "[0.49897578 0.3925841  0.2533472 ]\n",
      "[0.5163707  0.50072145 0.4994521 ]\n",
      "[1.         0.67294616 0.5739713 ]\n",
      "Epoch 2870/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8092 - val_loss: 5.8110\n",
      "Epoch 2871/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8811 - val_loss: 5.6109\n",
      "Epoch 2872/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.8433 - val_loss: 3.7972\n",
      "[0.50172067 0.39268136 0.2578358 ]\n",
      "[0.5171321  0.50038075 0.4996598 ]\n",
      "[1.         0.6706707  0.57562315]\n",
      "Epoch 2873/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7644 - val_loss: 4.7797\n",
      "Epoch 2874/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7394 - val_loss: 5.3968\n",
      "Epoch 2875/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7615 - val_loss: 3.9010\n",
      "[0.50336236 0.38948703 0.25527012]\n",
      "[0.5193411 0.5006645 0.4995169]\n",
      "[1.         0.67600214 0.56885093]\n",
      "Epoch 2876/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7238 - val_loss: 5.1790\n",
      "Epoch 2877/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7160 - val_loss: 3.6093\n",
      "Epoch 2878/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.9010 - val_loss: 2.7710\n",
      "[0.49964714 0.3873454  0.24333206]\n",
      "[0.5159042 0.5009653 0.4993839]\n",
      "[1.        0.6737698 0.5808713]\n",
      "Epoch 2879/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6637 - val_loss: 3.4810\n",
      "Epoch 2880/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8498 - val_loss: 3.5884\n",
      "Epoch 2881/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7503 - val_loss: 3.9199\n",
      "[0.49855646 0.38828525 0.24459735]\n",
      "[0.51764905 0.5011877  0.49969637]\n",
      "[1.        0.6826565 0.5692798]\n",
      "Epoch 2882/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6972 - val_loss: 3.5967\n",
      "Epoch 2883/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7088 - val_loss: 2.8987\n",
      "Epoch 2884/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7120 - val_loss: 3.8807\n",
      "[0.50398296 0.3891156  0.2574861 ]\n",
      "[0.52012163 0.50200474 0.49984697]\n",
      "[1.         0.6881125  0.56977654]\n",
      "Epoch 2885/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7813 - val_loss: 5.4223\n",
      "Epoch 2886/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.6766 - val_loss: 3.1248\n",
      "Epoch 2887/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7855 - val_loss: 3.4114\n",
      "[0.50029397 0.39066315 0.24674556]\n",
      "[0.5141694  0.5017214  0.49975628]\n",
      "[1.        0.6823022 0.5662743]\n",
      "Epoch 2888/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7386 - val_loss: 4.0371\n",
      "Epoch 2889/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7495 - val_loss: 5.8815\n",
      "Epoch 2890/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.8584 - val_loss: 3.6569\n",
      "[0.50144833 0.38715333 0.23534554]\n",
      "[0.51655066 0.5016174  0.4991407 ]\n",
      "[1.         0.67723316 0.57183385]\n",
      "Epoch 2891/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7243 - val_loss: 2.9000\n",
      "Epoch 2892/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7982 - val_loss: 5.8805\n",
      "Epoch 2893/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.8207 - val_loss: 2.3801\n",
      "[0.49002647 0.38615173 0.23354048]\n",
      "[0.51369584 0.50119066 0.49929345]\n",
      "[1.        0.6835642 0.5704904]\n",
      "Epoch 2894/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6831 - val_loss: 3.6080\n",
      "Epoch 2895/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.5911 - val_loss: 1.9030\n",
      "Epoch 2896/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6026 - val_loss: 4.9983\n",
      "[0.49894533 0.3848194  0.20704877]\n",
      "[0.5156116  0.50163734 0.49915075]\n",
      "[1.         0.68535805 0.56813765]\n",
      "Epoch 2897/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.4819 - val_loss: 2.8846\n",
      "Epoch 2898/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7151 - val_loss: 3.4103\n",
      "Epoch 2899/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7593 - val_loss: 2.6225\n",
      "[0.4984729  0.38693976 0.24939343]\n",
      "[0.51616794 0.50248533 0.50000304]\n",
      "[1.         0.68352586 0.57242715]\n",
      "Epoch 2900/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.5918 - val_loss: 3.9720\n",
      "Epoch 2901/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6487 - val_loss: 3.6713\n",
      "Epoch 2902/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7580 - val_loss: 3.8637\n",
      "[0.49995303 0.385786   0.254731  ]\n",
      "[0.5180953 0.5021096 0.5001113]\n",
      "[1.        0.6821979 0.5818465]\n",
      "Epoch 2903/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.5506 - val_loss: 3.9251\n",
      "Epoch 2904/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8003 - val_loss: 3.9716\n",
      "Epoch 2905/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7556 - val_loss: 3.6185\n",
      "[0.5005301  0.38613153 0.26007998]\n",
      "[0.51936567 0.50225824 0.4998885 ]\n",
      "[1.         0.6860581  0.57954836]\n",
      "Epoch 2906/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6711 - val_loss: 5.4075\n",
      "Epoch 2907/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8460 - val_loss: 5.5110\n",
      "Epoch 2908/10000\n",
      "2268/2268 [==============================] - 24s 11ms/step - loss: 0.8161 - val_loss: 5.6337\n",
      "[0.4814425  0.38697562 0.26456347]\n",
      "[0.5135135  0.50185907 0.50020206]\n",
      "[1.         0.69844127 0.57563156]\n",
      "Epoch 2909/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7715 - val_loss: 2.9283\n",
      "Epoch 2910/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.8349 - val_loss: 3.6984\n",
      "Epoch 2911/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.8239 - val_loss: 3.0525\n",
      "[0.4819018 0.3903321 0.2616618]\n",
      "[0.5171135  0.5020198  0.49993765]\n",
      "[1.         0.70770216 0.5764372 ]\n",
      "Epoch 2912/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.5812 - val_loss: 3.4886\n",
      "Epoch 2913/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.9380 - val_loss: 5.7627\n",
      "Epoch 2914/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7804 - val_loss: 3.7890\n",
      "[0.468623   0.38860705 0.2628131 ]\n",
      "[0.5201383  0.5025138  0.49986672]\n",
      "[1.         0.7084347  0.58438516]\n",
      "Epoch 2915/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.5372 - val_loss: 3.8766\n",
      "Epoch 2916/10000\n",
      "2268/2268 [==============================] - 24s 11ms/step - loss: 0.8432 - val_loss: 2.9629\n",
      "Epoch 2917/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.7411 - val_loss: 3.6577\n",
      "[0.49237332 0.3860827  0.25768352]\n",
      "[0.51866716 0.50310844 0.4998877 ]\n",
      "[1.         0.71129495 0.57689965]\n",
      "Epoch 2918/10000\n",
      "2268/2268 [==============================] - 24s 11ms/step - loss: 0.7301 - val_loss: 3.0027\n",
      "Epoch 2919/10000\n",
      "2268/2268 [==============================] - 24s 11ms/step - loss: 0.7958 - val_loss: 5.8124\n",
      "Epoch 2920/10000\n",
      "2268/2268 [==============================] - 24s 11ms/step - loss: 1.0065 - val_loss: 4.5826\n",
      "[0.49283484 0.38730818 0.21316493]\n",
      "[0.51822025 0.50173354 0.4996142 ]\n",
      "[1.        0.7030571 0.5772263]\n",
      "Epoch 2921/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.6893 - val_loss: 3.6656\n",
      "Epoch 2922/10000\n",
      "2268/2268 [==============================] - 24s 11ms/step - loss: 0.6924 - val_loss: 3.6159\n",
      "Epoch 2923/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.7624 - val_loss: 3.0315\n",
      "[0.49119732 0.38719025 0.20735458]\n",
      "[0.5199092  0.5009216  0.49958652]\n",
      "[1.         0.7085967  0.58163553]\n",
      "Epoch 2924/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8253 - val_loss: 5.0638\n",
      "Epoch 2925/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6837 - val_loss: 3.4629\n",
      "Epoch 2926/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7917 - val_loss: 3.6686\n",
      "[0.50077456 0.3863386  0.22269157]\n",
      "[0.52279186 0.50097406 0.49947146]\n",
      "[1.         0.711177   0.58639765]\n",
      "Epoch 2927/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.8333 - val_loss: 5.1417\n",
      "Epoch 2928/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8144 - val_loss: 3.6834\n",
      "Epoch 2929/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8358 - val_loss: 3.5551\n",
      "[0.49180806 0.38135552 0.21326533]\n",
      "[0.5211781  0.50053334 0.4994439 ]\n",
      "[1.       0.754768 0.59558 ]\n",
      "Epoch 2930/10000\n",
      "2268/2268 [==============================] - 24s 11ms/step - loss: 0.7687 - val_loss: 2.9249\n",
      "Epoch 2931/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7659 - val_loss: 2.7976\n",
      "Epoch 2932/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7793 - val_loss: 3.1002\n",
      "[0.49882773 0.36762694 0.21197003]\n",
      "[0.5214157  0.50009817 0.49915603]\n",
      "[1.         0.77495706 0.60319227]\n",
      "Epoch 2933/10000\n",
      "2268/2268 [==============================] - 24s 11ms/step - loss: 0.6936 - val_loss: 3.3734\n",
      "Epoch 2934/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7035 - val_loss: 3.3633\n",
      "Epoch 2935/10000\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 0.7178 - val_loss: 3.6553\n",
      "[0.5016211  0.3678061  0.21072638]\n",
      "[0.52405393 0.5000958  0.49911088]\n",
      "[1.        0.7577971 0.5979933]\n",
      "Epoch 2936/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6705 - val_loss: 5.4511\n",
      "Epoch 2937/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7011 - val_loss: 3.0703\n",
      "Epoch 2938/10000\n",
      "2268/2268 [==============================] - 24s 11ms/step - loss: 0.8149 - val_loss: 2.8994\n",
      "[0.4952022  0.33839712 0.19676432]\n",
      "[0.5265604 0.4991599 0.4974084]\n",
      "[1.         0.76940465 0.612622  ]\n",
      "Epoch 2939/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8279 - val_loss: 2.7911\n",
      "Epoch 2940/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.5116 - val_loss: 3.5611\n",
      "Epoch 2941/10000\n",
      "2268/2268 [==============================] - 24s 11ms/step - loss: 0.9366 - val_loss: 5.2699\n",
      "[0.43741408 0.34886873 0.19490778]\n",
      "[0.52440524 0.49880642 0.49692592]\n",
      "[1.         0.7444763  0.60539234]\n",
      "Epoch 2942/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6564 - val_loss: 3.5916\n",
      "Epoch 2943/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7991 - val_loss: 3.2437\n",
      "Epoch 2944/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7241 - val_loss: 4.4933\n",
      "[0.32189375 0.3348198  0.16062596]\n",
      "[0.53132725 0.49635902 0.4925264 ]\n",
      "[1.        0.7332007 0.6204995]\n",
      "Epoch 2945/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8110 - val_loss: 4.0854\n",
      "Epoch 2946/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7563 - val_loss: 2.5425\n",
      "Epoch 2947/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.7694 - val_loss: 3.2883\n",
      "[0.162386   0.33418226 0.16495997]\n",
      "[0.5391953  0.49220887 0.49240023]\n",
      "[1.         0.7490329  0.62089735]\n",
      "Epoch 2948/10000\n",
      "2268/2268 [==============================] - 24s 11ms/step - loss: 0.8632 - val_loss: 4.9830\n",
      "Epoch 2949/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.9412 - val_loss: 2.4241\n",
      "Epoch 2950/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8994 - val_loss: 2.4113\n",
      "[0.18954718 0.3369177  0.16610932]\n",
      "[0.53923273 0.49121857 0.49185485]\n",
      "[1.        0.7269052 0.6211548]\n",
      "Epoch 2951/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7866 - val_loss: 5.0216\n",
      "Epoch 2952/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.9237 - val_loss: 3.6810\n",
      "Epoch 2953/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6687 - val_loss: 3.0058\n",
      "[0.3450601  0.32731122 0.16465324]\n",
      "[0.5332526  0.49395376 0.49519724]\n",
      "[1.         0.75658274 0.6220979 ]\n",
      "Epoch 2954/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.7012 - val_loss: 2.6681\n",
      "Epoch 2955/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8768 - val_loss: 2.0338\n",
      "Epoch 2956/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7599 - val_loss: 4.7081\n",
      "[0.41646963 0.3362743  0.20131138]\n",
      "[0.523014   0.4916817  0.49786308]\n",
      "[1.         0.75982714 0.6256493 ]\n",
      "Epoch 2957/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8972 - val_loss: 1.9151\n",
      "Epoch 2958/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8351 - val_loss: 4.9990\n",
      "Epoch 2959/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.5311 - val_loss: 2.7877\n",
      "[0.3813566  0.34191304 0.20861524]\n",
      "[0.5280985  0.48950353 0.49796525]\n",
      "[1.         0.75741255 0.6147453 ]\n",
      "Epoch 2960/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8076 - val_loss: 2.3148\n",
      "Epoch 2961/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8407 - val_loss: 2.3192\n",
      "Epoch 2962/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.8567 - val_loss: 2.7789\n",
      "[0.41911855 0.34392184 0.2042329 ]\n",
      "[0.529664   0.48826173 0.49818408]\n",
      "[1.        0.7671015 0.6202939]\n",
      "Epoch 2963/10000\n",
      "2268/2268 [==============================] - 25s 11ms/step - loss: 0.7567 - val_loss: 1.7225\n",
      "Epoch 2964/10000\n",
      "2268/2268 [==============================] - 25s 11ms/step - loss: 0.7366 - val_loss: 2.2402\n",
      "Epoch 2965/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8439 - val_loss: 2.5796\n",
      "[0.3264473  0.33421946 0.19167706]\n",
      "[0.5330698  0.48520693 0.49594608]\n",
      "[1.         0.75494653 0.6148242 ]\n",
      "Epoch 2966/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8079 - val_loss: 3.7663\n",
      "Epoch 2967/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7885 - val_loss: 4.2230\n",
      "Epoch 2968/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7384 - val_loss: 1.7848\n",
      "[0.41690814 0.31895903 0.16626066]\n",
      "[0.53675437 0.4809697  0.49280912]\n",
      "[1.         0.73433197 0.61602134]\n",
      "Epoch 2969/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7940 - val_loss: 2.2791\n",
      "Epoch 2970/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7327 - val_loss: 4.8374\n",
      "Epoch 2971/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8151 - val_loss: 2.3490\n",
      "[0.39445704 0.3318498  0.16286063]\n",
      "[0.53541607 0.48490605 0.49508646]\n",
      "[1.         0.74443066 0.6142993 ]\n",
      "Epoch 2972/10000\n",
      "2268/2268 [==============================] - 24s 11ms/step - loss: 0.8943 - val_loss: 4.7413\n",
      "Epoch 2973/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.5805 - val_loss: 2.3606\n",
      "Epoch 2974/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.5730 - val_loss: 2.5948\n",
      "[0.49571943 0.32774845 0.19190058]\n",
      "[0.5356644  0.48495114 0.4983211 ]\n",
      "[1.         0.7533972  0.61337286]\n",
      "Epoch 2975/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.9174 - val_loss: 2.3149\n",
      "Epoch 2976/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7315 - val_loss: 2.8185\n",
      "Epoch 2977/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8756 - val_loss: 2.5260\n",
      "[0.38153297 0.31426522 0.19793943]\n",
      "[0.5341841  0.48244673 0.49873462]\n",
      "[1.        0.7560259 0.6129986]\n",
      "Epoch 2978/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.9348 - val_loss: 2.4726\n",
      "Epoch 2979/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.9325 - val_loss: 2.7797\n",
      "Epoch 2980/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7442 - val_loss: 2.5463\n",
      "[0.4320335  0.30633044 0.19503269]\n",
      "[0.5349526  0.48224694 0.4983114 ]\n",
      "[1.        0.7559897 0.6204054]\n",
      "Epoch 2981/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8138 - val_loss: 1.9009\n",
      "Epoch 2982/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7107 - val_loss: 2.8204\n",
      "Epoch 2983/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6303 - val_loss: 2.3617\n",
      "[0.39360383 0.31431773 0.20004061]\n",
      "[0.53654706 0.48308143 0.4986939 ]\n",
      "[1.         0.75630736 0.6209968 ]\n",
      "Epoch 2984/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8787 - val_loss: 3.9076\n",
      "Epoch 2985/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7944 - val_loss: 4.6607\n",
      "Epoch 2986/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7919 - val_loss: 1.1821\n",
      "[0.36973196 0.31590843 0.19534445]\n",
      "[0.5377151  0.4859872  0.49800274]\n",
      "[1.         0.75292265 0.6268233 ]\n",
      "Epoch 2987/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.7765 - val_loss: 2.5938\n",
      "Epoch 2988/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.7416 - val_loss: 4.1729\n",
      "Epoch 2989/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6839 - val_loss: 2.6718\n",
      "[0.43234506 0.3209594  0.19231293]\n",
      "[0.5438997  0.48799798 0.49734917]\n",
      "[1.         0.75601506 0.623804  ]\n",
      "Epoch 2990/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.6226 - val_loss: 2.1863\n",
      "Epoch 2991/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8569 - val_loss: 2.6895\n",
      "Epoch 2992/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.7893 - val_loss: 2.1832\n",
      "[0.36190388 0.30002928 0.1957699 ]\n",
      "[0.54083    0.48280728 0.49801672]\n",
      "[1.         0.74565876 0.60486144]\n",
      "Epoch 2993/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8099 - val_loss: 1.5606\n",
      "Epoch 2994/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.6791 - val_loss: 2.9514\n",
      "Epoch 2995/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8115 - val_loss: 2.3222\n",
      "[0.4352702  0.3062938  0.18900415]\n",
      "[0.53540045 0.4836632  0.5003807 ]\n",
      "[1.         0.75484765 0.61080587]\n",
      "Epoch 2996/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8464 - val_loss: 3.4876\n",
      "Epoch 2997/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.6858 - val_loss: 2.6935\n",
      "Epoch 2998/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.8800 - val_loss: 2.9652\n",
      "[0.41598082 0.2925509  0.19102338]\n",
      "[0.53128237 0.48224828 0.5004065 ]\n",
      "[1.        0.7528691 0.6112423]\n",
      "Epoch 2999/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.7208 - val_loss: 2.3920\n",
      "Epoch 3000/10000\n",
      "2268/2268 [==============================] - 23s 10ms/step - loss: 0.8166 - val_loss: 2.5224\n",
      "Epoch 3001/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.8093 - val_loss: 2.3701\n",
      "[0.48232612 0.2866237  0.19856647]\n",
      "[0.5330546  0.48265743 0.5002304 ]\n",
      "[1.         0.75246155 0.61091423]\n",
      "Epoch 3002/10000\n",
      "2268/2268 [==============================] - 24s 11ms/step - loss: 0.7229 - val_loss: 3.0742\n",
      "Epoch 3003/10000\n",
      "2268/2268 [==============================] - 24s 11ms/step - loss: 0.7157 - val_loss: 2.9625\n",
      "Epoch 3004/10000\n",
      "2268/2268 [==============================] - 24s 11ms/step - loss: 0.7236 - val_loss: 2.6057\n",
      "[0.43822712 0.26490587 0.188764  ]\n",
      "[0.53671026 0.48533642 0.49830619]\n",
      "[1.        0.7405213 0.6195264]\n",
      "Epoch 3005/10000\n",
      "2268/2268 [==============================] - 25s 11ms/step - loss: 0.6499 - val_loss: 3.7260\n",
      "Epoch 3006/10000\n",
      "2268/2268 [==============================] - 24s 11ms/step - loss: 0.8224 - val_loss: 3.0041\n",
      "Epoch 3007/10000\n",
      "2268/2268 [==============================] - 24s 11ms/step - loss: 0.8831 - val_loss: 2.4783\n",
      "[0.47602248 0.26887524 0.19042647]\n",
      "[0.53696233 0.4843172  0.4987081 ]\n",
      "[1.        0.7429852 0.6103322]\n",
      "Epoch 3008/10000\n",
      "2268/2268 [==============================] - 24s 11ms/step - loss: 0.8861 - val_loss: 3.2780\n",
      "Epoch 3009/10000\n",
      "2268/2268 [==============================] - 24s 11ms/step - loss: 0.8240 - val_loss: 3.4886\n",
      "Epoch 3010/10000\n",
      "2268/2268 [==============================] - 24s 11ms/step - loss: 0.8215 - val_loss: 2.5415\n",
      "[0.4836104 0.2509911 0.1580073]\n",
      "[0.5402151 0.4857091 0.4962904]\n",
      "[1.         0.72957027 0.64051914]\n",
      "Epoch 3011/10000\n",
      "2268/2268 [==============================] - 24s 11ms/step - loss: 0.9927 - val_loss: 4.1180\n",
      "Epoch 3012/10000\n",
      "2268/2268 [==============================] - 24s 10ms/step - loss: 0.7636 - val_loss: 2.5635\n",
      "Epoch 3013/10000\n",
      "1028/2268 [============>.................] - ETA: 11s - loss: 0.7686"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-cc0f7c4e27fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m                     \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                     \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                    \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                    )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(tf.convert_to_tensor(inputs_train[:-buffer-(len(inputs_train)-buffer)%batch_size]), \n",
    "                    tf.convert_to_tensor([[0, i] for i in range(len(train)-buffer-(len(inputs_train)-buffer)%batch_size)]), \n",
    "                    validation_data=(tf.convert_to_tensor(inputs_test[:-buffer-(len(inputs_test)-buffer)%batch_size]), tf.convert_to_tensor([[1, i] for i in range(len(test)-buffer-(len(inputs_test)-buffer)%batch_size)])),\n",
    "                    epochs=10000, shuffle=True,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[ival],\n",
    "                   use_multiprocessing=True, verbose=1, \n",
    "                    validation_freq=1,\n",
    "                    workers=32,\n",
    "                   initial_epoch=model.history.epoch[-1],\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "focused-recall",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: profit_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: profit_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('profit_model_fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "classified-mineral",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = {'train': model.predict(inputs_train[:-buffer]), 'test': model.predict(inputs_test[:-buffer])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aggregate-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "profits = {'train': get_profit(df[0], y_preds['train'], 0), 'test': get_profit(df[1], y_preds['test'], 0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "reasonable-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = {'train': train.iloc[:-buffer-1].copy(), 'test': test.iloc[:-buffer-1].copy()}\n",
    "temp['train']['profit'] = profits['train']\n",
    "temp['test']['profit'] = profits['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "standard-marijuana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp['train']['profit'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "considerable-certificate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp['test']['profit'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "younger-invitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAtdUlEQVR4nO3deXxV1bn/8c+TOQGSEAhhCGGQGRSFCDhUUSqDtqKtUrW3otVyVbxtb++vLVqr1qqldrBq1ZZaKrTWobZeuYoiItYRMIDKDAFBggwBAgQSMp31++OshBNISCAJ5yT5vl+v88rea6+995PpPGevtfZe5pxDRERat6hwByAiIuGnZCAiIkoGIiKiZCAiIigZiIgIEBPuAE5Wx44dXc+ePcMdhohIs7F06dLdzrn0mrY122TQs2dPcnJywh2GiEizYWZbatumZiIREVEyEBERJQMREUHJQEREUDIQERGUDEREBCUDERFByUBEJOLtKyrlHzlbKS0PNNk5mu1NZyIiLdGyzwsY1CWZhNho9hws4fqZS1j1xQEAYqKNK8/KbJLz6spARFq9ioDjN2+sY+W2/WGNo/BwGV974gMG/PR1PsjdzfD736xKBAD//fwnjP/dO01ybl0ZiEirt/zzAh57K5fH3solNSmWfUVlmMEzN43k3D4dKasIcPOsHAqKSvnT9dlkJCc0SRwHS8qrlq97ajEA3VITmTZhAEs+28tfF22hV8c2TXLuOpOBmfUHng8p6g3cDcz25T2BzcAk51yBmRnwCHApUATc4Jxb5o81GbjLH+d+59wsXz4ceBpIBOYC33Oaj1NEmljh4TLaJcSyv7gMgO5piew5WAqAc8E35OSEGA4cPvImPfLBBTx45elMys4kJrpxG1eKSisAuOXC01j1xX5G9krj9ov7AjBmYCfGDs7gS31rfM5cg9WZDJxz64AzAcwsGtgGvARMAxY456ab2TS//mNgAtDXv0YCTwIjzSwNuAfIBhyw1MzmOOcKfJ3vAIsJJoPxwGuN922KiBwx452NHCqp4JEFG6qVz7pxBL3T21JUWs4Dr64h4Bwfb93Pge0HuLBfOl8e2ImfvryKO19awd+XbOHRa86id3pb3l63izO7p5KaFFev83++p4guqQnEHpVMin0yOCsrlWkTBlTblhQX02SJAE68mWgMsNE5t8XMJgKjffks4G2CyWAiMNt/sl9kZqlm1sXXne+c2wtgZvOB8Wb2NpDsnFvky2cDV6BkICINsHLbfm59ZinDstrTLiGGd9bvZl9RKef16chrK3fUuE9KYiwQfON94MrTj9keCDiG90hj9fYDPPDqar762HtcfmZXnl2ylTZx0fzt5pGcldW+2j6/f2sDjyzYUHXsPYdKqWz3mPXtEVzY78gb/OGyCn/+6AZ//yfqRJPBNcCzfjnDObfdL+8AMvxyN2BryD55vux45Xk1lB/DzKYAUwCysrJOMHQRaS2cc1w7YxGFJeVs3VtcbVtoIujZIYnpXz+D0vIAOw8cpkPb+OMeNyrKGNQ1mUFdkzkjM4X7/m81zy4Jvq0dKq3gyic+4KrhmZyRmcIVZ3Vj14ESfv3GegB2++anUJNnLuGCfuk8cMUQbpr1Eet3HgQiPBmYWRxwOXDH0ducc87MmryN3zk3A5gBkJ2drT4FEalRzpYCCkvK6dg2npduO5fFn+3l4gGdSIiN4t45q5h8bk/S2sTRJj6G5ITYkzpHv4x2zP72CN7N3c3+4jJG9krj56+s5sWleby4NI+7X15VVfc3Vw/l68ODQ0IPlZRjBh/k7uHm2Tm8sz6fLz20sNqxm6qD+nhO5MpgArDMObfTr+80sy7Oue2+GWiXL98GdA/ZL9OXbeNIs1Jl+du+PLOG+iIiJ+WQH5Xzm0lD6Z6WRPe0pKptD101tNHOExVl1Zp5fn/dMG65cD8Pz1/PgrXBt8QL+qXztWFHGjvaxAffdr88KIMld45hxIMLADgjM4WXp57HgeJyUpJOLkE1xIkkg2s50kQEMAeYDEz3X18OKb/dzJ4j2IG83yeMecCDZlbZoDYWuMM5t9fMDpjZKIIdyNcDj530dyQirV6Jv1O3Q5v6deg2piHdUvjzDWezMf8gr63Yzn9eeBrBQZbH6pScwBPfHEZ+YQnfGtUDMwtLIoB6JgMzawNcAvxnSPF04AUzuwnYAkzy5XMJDivNJTi09EYA/6b/c+AjX+++ys5k4DaODC19DXUei0gDVHbEJsSe+rb3Sqelt60aFno8l57e5RREU7d6JQPn3CGgw1FlewiOLjq6rgOm1nKcmcDMGspzgCH1iUVEpC4lZcErg4RYPWShvnQHsohEvEDA8dR7m9hfXMbFAzIY3qP9cesfLg//lUFzo2QgIhFvY/5BHpy7FoCn3v2M1feNJzrK2H2whDG/+TfDslLpnpZEYmw03dOSWPJZsAVayaD+lAxEJOLl7QveK3B+n468l7ub/3p2GXd/ZTDvbshnf3EZC9fl0y4+hsKQZ/u0T4olScmg3pQMRCSs8gtL+HxvES8tz6NHWhuuP7cH8THBN/Hlnxfw7obd7D5YAsAVZ3XjvdzdzF2xg7krjtw8tvjOMWQkJ3CopJxXV2xn8aa9TJswgKiomkfxyLGsuT4PLjs72+Xk5IQ7DBFpgB37DzPqFwuqlfXq2IZ7Lx/Mc0s+P+axEbkPTCDg4K21u3h4/nrat4llygW9uXhABlI3M1vqnMuuaZuuDEQkbBZ/tgeAdvExjB/SmddX7eCz3YeYPHNJVZ2rh2fSs2MbstKSqp4SOn5IZ8YP6RyWmFsqJQMRCZvK5/e/+T8XkpGcwK+uHsqm/IOs/OIABlzYP/2kHxchJ0bJQETCpvKxEZWPaADond6W3ultwxVSq6VkICJhcd2fFvHBxmAzkUb9hJ9uzxORU27PwZKqRABo1E8E0JWBiJxyi/1NYU/feDZdUxPDHI2AkoGIhEFBUXCilwGdk+mccuqf3S/HUjIQkVNi/c5Clm4pYFhW+6qO47YJeguKFPpNiEiTKC0PsL+4jDfX7OTsnml87YkPqoaSVlLHceRQMhCRJnHr35ZWzfZVaWSvNA6WlLPqiwOAOo4jiZKBiDS6rz/5AUu3FBAXHUVyYgwd28Yzun8n/uviPrSJj2HJZ3vZVXg43GFKCCUDEWlUzjmWbikAYNndl9A2/ti3mRG90k51WFIHJQMROWm5uwr5aHMBXVMTeSFnK+3iY9iUfwiAuy4bWGMikMhU3zmQU4GnCE5N6YBvA+uA54GewGZgknOuwIIzPz9CcB7kIuAG59wyf5zJwF3+sPc752b58uEcmQN5LvA911wfpyrSSry+cju3/G1Zrdu/ObLHKYxGGqq+afsR4HXn3FVmFgckAXcCC5xz081sGjAN+DEwAejrXyOBJ4GRZpYG3ANkE0woS81sjnOuwNf5DrCYYDIYD7zWSN+jiDSSQMBReLicZZ8XVCWC8/t05JoR3RncNYXUxFjey93N2T3TSIzTSKHmpM5kYGYpwAXADQDOuVKg1MwmAqN9tVnA2wSTwURgtv9kv8jMUs2si6873zm31x93PjDezN4Gkp1zi3z5bOAKlAxEGkUg4Bpt1M4zi7fw05dXVa1PmzCAWy48rVqdrw7t2ijnklOrPs8m6gXkA38xs+Vm9pSZtQEynHPbfZ0dQOXsEt2ArSH75/my45Xn1VB+DDObYmY5ZpaTn59fj9BFWrfHFmyg951zeeGjraz6Yn+Dj/fZ7iIgOKXkn67PPiYRSPNVn2aiGGAY8F/OucVm9gjBJqEqzjlnZk3exu+cmwHMgOBMZ019PpHGVBFwlAcClFc4KpwjPiaKaLOqCVuawiufBj+v/eifnwLw++vOIrtH2kk/AqJNfDRmsOynlxDsHpSWoj7JIA/Ic84t9usvEkwGO82si3Nuu28Gqry7ZBvQPWT/TF+2jSPNSpXlb/vyzBrqizRbM97ZyJNvb+TW0aexbsdB/rksr8Z6PTokseAHFzZJQigurWBItxTW7SzknN4d+HDTHm7/+3LS2sRx64WnMbhrMuf26XjcY+zYf5grHn+fb53Tg9tGn8bhsgoSYqKVCFqgOpOBc26HmW01s/7OuXXAGGC1f00GpvuvL/td5gC3m9lzBDuQ9/uEMQ940Mza+3pjgTucc3vN7ICZjSLYgXw98Fgjfo8ip9xba3dRUFTGg3PXHrfelj1F/PTlVfzia6fX67jFpRVsLSiiX0Y7AHYVHuaH//iU09Lb8vneIgqKSrnz0oHkFRTxvec+BqBbaiLPThlFXkERcz75gicWbuSBuWuIi45i/QMTjnu+vy7azI4Dh/nVvHV8sa+YKDMSYvXk+5aovqOJ/gt4xo8k2gTcSLC/4QUzuwnYAkzydecSHFaaS3Bo6Y0A/k3/58BHvt59lZ3JwG0cGVr6Guo8lmauQ9t4Tktvw19uGMHcldu5dEgXsjokVW1fsGYnf1u0hZLyAP9cmsedlw6gXT2md/z9wg08vnAjd102kI35B3l2SbAb7t/rj/Sh/eSlFaQkHjnWhf3TAchsn8Rto/vw7fN6MeY3/2bbvmLyC0tIbxdf6/kSYoIjgkb2SuOZxZ8D0LFt7fWl+apXMnDOfUxwSOjRxtRQ1wFTaznOTGBmDeU5BO9hEGkRSssDxEZHkdUhqcZO1jEDMxgzMINPtu5j4uPv86t56/ifsf3JLzxMalJcrW+463YUAnD/q2uqys7v05FbR5/GxvyDPLpgA2t9nS8P7MTj3xxGfEz1IZ4JsdGM7J3Gv5Zt4+wH3mRSdib/fUk/uqQcO69AWSDYNXfNiO5VcxCUllecxE9EIp1uDxRpAmUVAeJj6m5OGdo9lQlDOjP7wy3M/nBLVflj157F3kOlXH9Oj2rt84dKKujYNo7dB4PzAWx4YAKxvr/hvD4duah/J7700EI6to3j4W+ceUwiqPTTywaRkZzAF/uKeSEnj50HSnj6xrNZvnUfpeUBnnh7Iz3SkkiMiyYhNoorz8pkaGYql//+fX599dCG/GgkQllzvdE3Ozvb5eTkhDsMkRpd96dFlJYHePHWc+usu/tgCdn3vwlQ7Y0eoHtaIl2SE3n622dTUhbgrJ/P51ujevDD8f1pFx/TKB25v5q3lscXbqx1e0piLJ/cM7bB55HwM7OlzrmaWnl0ZSDSFMoqAsTV48oAgm3wm6dfxuGyCuJjolizvZBfvLaGdzfsZuveYrbuLeZvi7YQHRU83gX90kmuR/9Cfd06ug8fb93HJ1v3M35IZ15cmkd0lFHhm4j2F5c12rkkcikZiDSB0vIAbU7wIW0JfqKXQV2T+etNI5n0hw9ZsjnYTl85Kikmyrig3/GHg56otvExPHPzqKr1B688nZgooywQoP9drzfquSRyKRmINLLyigBFpRV0Sm7YEMznpoziF6+toaCojOE92vNp3j6GdEuptR+gsVRe0cRHRfPmDy7kwGFdGbQGSgYiJ2nr3iKeencTt4w+jS4pieTuKuTDjXuqnt1zvCGb9REVZfzkskFV69eOyGrQ8U5Gn05tT/k5JTyUDEROwsK1u7jx6eAtM2u2F/LAlUO47NH3KK0IVNWJ0l260owoGYichCl/PTKSbcnmvVzy8DsAfKlvR64bkUVCbDTd044dty8SqZQMRE7C0MxUcvzUjhAc4dOhTRy/nTRUz+2RZknJQOQknXtaB2becDa7D5aQ2T6p7h1EIpieOCVST2UVAYpKywEoKq0gKS6ahNhoJQJpEXRlIFJP505/i4OHy3nim8MoKi0nMU7/PtJy6MpApB7uf2U1+YUlFJdVcOPTH7F5TxFt4zXHr7Qc+mgjUg8v+slp3vzBBcxdsYM12w/w7fN6hTkqkcajZCBSDwM6tyMQgD6d2vHdMe3CHY5Io1MzkUg9FJcFSIhTs5C0XEoGIvVQUlZBoqZ7lBZMzUQiwPb9xfzkpZUYsGn3Ib45Mos/vrOJ09Lb8I2zu7N2RyH9O6t5SFqueiUDM9sMFAIVQLlzLtvM0oDngZ7AZmCSc67AgrdfPkJwHuQi4Abn3DJ/nMnAXf6w9zvnZvny4RyZA3ku8D3XXGfdkWbprpdW8tbaXVXrldNK5heWsGhT8DHSMVG6MpCW60SuDC5yzu0OWZ8GLHDOTTezaX79x8AEoK9/jQSeBEb65HEPwbmUHbDUzOY45wp8ne8Aiwkmg/HAaw36zkROQHFZcF7fl6eeR1qbODbtPsScj79g4pld+e389Rwuq+CiAelhjlKk6TSkmWgiMNovzwLeJpgMJgKz/Sf7RWaWamZdfN35zrm9AGY2HxhvZm8Dyc65Rb58NnAFSgZyCpRVBLh5Vg4fbNzD2EEZDO2eCkD3tCQu7Bd887+gn5KAtHz1ve51wBtmttTMpviyDOfcdr+8A8jwy92ArSH75vmy45Xn1VB+DDObYmY5ZpaTn59fz9BFavfImxv49/rg31J2z/ZhjkYkfOp7ZXC+c26bmXUC5pvZ2tCNzjlnZk3exu+cmwHMAMjOzlafgjTYF/uKAXjnhxeR1UHPGJLWq15XBs65bf7rLuAlYASw0zf/4L9W9r5tA7qH7J7py45XnllDuUiT+TRvH/e/spp/Ld/G4K7JSgTS6tWZDMysjZm1q1wGxgIrgTnAZF9tMvCyX54DXG9Bo4D9vjlpHjDWzNqbWXt/nHl+2wEzG+VHIl0fciyRJnHPnFU89d5nABwsKQ9zNCLhV59mogzgJT9hRwzwd+fc62b2EfCCmd0EbAEm+fpzCQ4rzSU4tPRGAOfcXjP7OfCRr3dfZWcycBtHhpa+hjqPpYklxUUzpFsyN5zbi2FZqeEORyTs6kwGzrlNwNAayvcAY2ood8DUWo41E5hZQ3kOMKQe8Yo0igPF5aS3jeeq4Zl1VxZpBXQXjbRKew+VkpwYG+4wRCKGkoG0Kh9t3kvPaa+ybV8xSZqcRqSKkoG0Klf/4cOq5bN1X4FIFX00klald8c2bNp9iE/vHUtygpqJRCrpykBaldjoKMYNzlAiEDmKkoG0SDsPHOaMe+fx4xc/5cDhsqryorJy9RWI1EDJQFqcJZ/tZeSDCzhwuJznc7Zyxr1v8EHubjblH2Tr3mISNWOZyDH0EUlalIJDpUz6Y7CT+BvZ3XE4XsjJ47qnFlfV+fjzfWGKTiRyKRlIixEIOH7+ymoA4mOi+OVVZwDw5YEZTPnrUgBSEmOZNmFA2GIUiVRKBtKsLf+8gJioKE7PTGHkLxaQX1gSLL/7kqo6Ywd3ZvP0y8IVokizoGQgzdqVT3xwTNk9Xx2kTmKRE6T/GGlRHvr6GUw6u3vdFUWkGo0mkhZj6kWnKRGInCRdGUiL8N6PLyKzvSaoETlZSgbSrHVsG8e4wZ2VCEQaSM1E0qyVlAWIj9FNZCINpWQgzZZzjkOl5cTF6M9YpKH0XyTN1sNvbiDgoKhUcxiLNFS9k4GZRZvZcjN7xa/3MrPFZpZrZs+bWZwvj/fruX57z5Bj3OHL15nZuJDy8b4s18ymNeL3Jy3Yows2ADCiV1qYIxFp/k7kyuB7wJqQ9V8CDzvn+gAFwE2+/CagwJc/7OthZoOAa4DBwHjgCZ9gooHHgQnAIOBaX1ekVlv2HALghnN78pUzuoY5GpHmr17JwMwygcuAp/y6ARcDL/oqs4Ar/PJEv47fPsbXnwg855wrcc59BuQCI/wr1zm3yTlXCjzn64rU6u9LPgfgG7qvQKRR1PfK4HfAj4CAX+8A7HPOVTbW5gHd/HI3YCuA377f168qP2qf2sqPYWZTzCzHzHLy8/PrGbq0JF/sK+b1ldv50zubABjYJTnMEYm0DHXeZ2BmXwF2OeeWmtnoJo/oOJxzM4AZANnZ2S6csUh4nDv9rarlkeorEGk09bnp7DzgcjO7FEgAkoFHgFQzi/Gf/jOBbb7+NqA7kGdmMUAKsCekvFLoPrWVi1TTJi6aQ6UVdElJ4NdXDw13OCItRp3NRM65O5xzmc65ngQ7gN9yzn0TWAhc5atNBl72y3P8On77W84558uv8aONegF9gSXAR0BfPzopzp9jTqN8d9LinJXVnuE92vPhHWPonqa7jkUaS0MeR/Fj4Dkzux9YDvzZl/8Z+KuZ5QJ7Cb6545xbZWYvAKuBcmCqc64CwMxuB+YB0cBM59yqBsQlLVhpeYB43WQm0uhOKBk4594G3vbLmwiOBDq6zmHg6lr2fwB4oIbyucDcE4lFWqeS8gqS4uPCHYZIi6OPWNKslOjKQKRJ6L9KmpVgMtCD6UQam5KBNCslZRV6MJ1IE9B/lTQrpRVqJhJpCvqvkmZF8xeINA0lA2lWSsoDxMfqz1aksem/SpqF4tIKfvD8x5RWBIiL1p+tSGPTf5U0C798fS3/Wh58Skn+wZIwRyPS8jTkDmSRU+K0O+dSEQg+lzA22vj2eT3DG5BIC6RkIBFt14HDVYmgd8c2vPX/Roc3IJEWSs1EEtHmfPIFAJcP7apEINKElAwkot3/anCm1d9948zwBiLSwikZSMTK3VVYtRwVZWGMRKTlUzKQiFRSXsGXf/sOAD8a3z/M0Yi0fEoGEnE25h+k/12vA5DZPpHrz+kZ3oBEWgGNJpKI89S7wcnuu6Yk8O6PLsJMTUQiTU1XBhJRFm/aw7NLtgLw/rSLlQhEThElA4koU/++DICHvn6GEoHIKVRnMjCzBDNbYmafmNkqM/uZL+9lZovNLNfMnveT2eMnvH/ely82s54hx7rDl68zs3Eh5eN9Wa6ZTWuC71Oaid0HSxnaPZWrhmeGOxSRVqU+VwYlwMXOuaHAmcB4MxsF/BJ42DnXBygAbvL1bwIKfPnDvh5mNgi4BhgMjAeeMLNoM4sGHgcmAIOAa31daWUq7zQe3S9dQ0lFTrE6k4ELOuhXY/3LARcDL/ryWcAVfnmiX8dvH2PB6/2JwHPOuRLn3GdALjDCv3Kdc5ucc6XAc76utGDLPy/gzPve4PGFuTgXTAKvrdwOQHJibDhDE2mV6jWayH96Xwr0IfgpfiOwzzlX7qvkAd38cjdgK4BzrtzM9gMdfPmikMOG7rP1qPKRtcQxBZgCkJWVVZ/QJUI9umAD+4rK+NW8dewvLiMrLYm7/nclAFee1a2OvUWksdUrGTjnKoAzzSwVeAkY0JRBHSeOGcAMgOzsbBeOGKRxrN95kLbxMRwsKWfGO5uqyrulJpLWJi6MkYm0Tic0msg5tw9YCJwDpJpZZTLJBLb55W1AdwC/PQXYE1p+1D61lUsLtSn/INv2FXPdyCx+ffVQenZIAiC7R3ven3ZxmKMTaZ3qvDIws3SgzDm3z8wSgUsIdgovBK4i2MY/GXjZ7zLHr3/ot7/lnHNmNgf4u5n9FugK9AWWAAb0NbNeBJPANcB1jfctSiT5NG8fl//+fQAGdG7H14ZlauSQSASoTzNRF2CW7zeIAl5wzr1iZquB58zsfmA58Gdf/8/AX80sF9hL8M0d59wqM3sBWA2UA1N98xNmdjswD4gGZjrnVjXadyinREl5BdFmxPgpKQ+XVfDPZXkM6ZrC5j2HyCsoZupFfbjzpRVV+0w8U30DIpGizmTgnPsUOKuG8k0ERwIdXX4YuLqWYz0APFBD+Vxgbj3ilQjV/67XSYiNonNyAkO7p9KrYxt+9+aGanXaxsewbkfwSaQv3nIO0Ro+KhIx9GwiaTSHywJs3lPE5j1FAHRJSWDsoAxeXJrHodIK7pkTvOC767KBZPdMC2eoInIUJQNpFCmJsZzftyPfGtWD4rIKVn9xgHGDO9OnU1t+NnEI81bt4GdzVuGArw9TH4FIpFEykEYRCDg6tYtnVO8OAFzUv1O17eMGd2bc4M7hCE1E6kEPqpNGUeEc0XqwnEizpWQgjaIi4NQhLNKMKRlIowg4p4fLiTRjSgbSKCoCaiYSac6UDKTBnHMEHLoyEGnGlAykwfw0BLoyEGnGlAykwSonpYnWX5NIs6V/X2mwgJ+cRs1EIs2XkoE0WNWVgZqJRJotJQNpsApX2UykZCDSXCkZSINVVCgZiDR3SgbSYLoyEGn+lAykwQK+zyBKfQYizZaSgTSYrgxEmj8lA2kwjSYSaf7qTAZm1t3MFprZajNbZWbf8+VpZjbfzDb4r+19uZnZo2aWa2afmtmwkGNN9vU3mNnkkPLhZrbC7/Oomd5VmpNAIPhV9xmINF/1uTIoB/7HOTcIGAVMNbNBwDRggXOuL7DArwNMAPr61xTgSQgmD+AeYCTBuZPvqUwgvs53QvYb3/BvTU6FO19awQW/WghAjJKBSLNVZzJwzm13zi3zy4XAGqAbMBGY5avNAq7wyxOB2S5oEZBqZl2AccB859xe51wBMB8Y77clO+cWOeccMDvkWBIB9heX4Xy/wNFeW7EdgEsGZXBen46nMiwRaUQnNO2lmfUEzgIWAxnOue1+0w4gwy93A7aG7Jbny45XnldDeU3nn0LwaoOsrKwTCV1O0qQ/fMiSzXsBuHhAJ742rBsThnSp6iw2M745MosHrjw9nGGKSAPVuwPZzNoC/wS+75w7ELrNf6Kv+aNjI3LOzXDOZTvnstPT05v6dAJViWBA53a8tXYXt/99Oa/6qwHnHPuLy0hNig1niCLSCOqVDMwslmAieMY59y9fvNM38eC/7vLl24DuIbtn+rLjlWfWUC4RICkumpvP78Xr37+A9fdPAOC7zy7n9ZXb2V9cRkXAkZKoZCDS3NVnNJEBfwbWOOd+G7JpDlA5Imgy8HJI+fV+VNEoYL9vTpoHjDWz9r7jeCwwz287YGaj/LmuDzmWhFl5wBEdHWwSiouJ4j8v7E2buGhu+dsyzrxvPoCSgUgLUJ8+g/OAbwErzOxjX3YnMB14wcxuArYAk/y2ucClQC5QBNwI4Jzba2Y/Bz7y9e5zzu31y7cBTwOJwGv+JREgEHDVRgndMWEg/29sf95YtZOH5q2lpCzAsKz2xzmCiDQHdSYD59x7QG1jBsfUUN8BU2s51kxgZg3lOcCQumKRU6+8hrmNY6OjuOyMLlx6emd0S4hIy6A7kKVWgaoZzGr+M1EiEGk5lAykVuWazlKk1dC/udQq4I5/ZSAiLYf+y6VWujIQaT30by61qqijz0BEWg79l0utjjyaOsyBiEiTUzKQWlUlA7UTibR4+i+XWmnSGpHWQ8lAalXuZ63RPAUiLZ+SQSt11ZMf8K0/L6a0PFBrncoZzDS3sUjLd0LzGUjLkbOlAIBBd7/OwC7JTP/66QzsnFxt6srKKwMlA5GWT8mgFXJVN5MZ/TLasWLbfi579D0ALuqfzuRzexIfE01lV4GSgUjLp2TQClXeTPb9MX25dfRpfLhpD+t2FLJo017eXLOThevyq9VvnxQXjjBF5BRSMmiFKkcJxURHERMdxZf6pvOlvunc/KXevL1uF9NfW8v15/Tk/dzdOBzn9ekQ5ohFpKkpGbRCZRW1jxIa3b8To/t3AuC6kZpnWqS10GiiVujIYybUFyAiQUoGrVBln0GsnjMhIp6SQStUXqEH0IlIdXW+G5jZTDPbZWYrQ8rSzGy+mW3wX9v7cjOzR80s18w+NbNhIftM9vU3mNnkkPLhZrbC7/OoafqsJld1Z7GuDETEq89Hw6eB8UeVTQMWOOf6Agv8OsAEoK9/TQGehGDyAO4BRgIjgHsqE4iv852Q/Y4+lzSyyisDPWZCRCrVmQycc+8Ae48qngjM8suzgCtCyme7oEVAqpl1AcYB851ze51zBcB8YLzfluycW+SCd0LNDjmWNJHykKGlIiJw8n0GGc657X55B5Dhl7sBW0Pq5fmy45Xn1VBeIzObYmY5ZpaTn59fWzWpQ9V9BroyEBGvwR8N/Sd61wix1OdcM5xz2c657PT09FNxyhap8j4DDS0VkUonmwx2+iYe/Nddvnwb0D2kXqYvO155Zg3l0kQeXbCBrzwWfA6RhpaKSKWTTQZzgMoRQZOBl0PKr/ejikYB+31z0jxgrJm19x3HY4F5ftsBMxvlRxFdH3IsaWS5uwr57fz1AGT3aM+QrilhjkhEIkWdj6Mws2eB0UBHM8sjOCpoOvCCmd0EbAEm+epzgUuBXKAIuBHAObfXzH4OfOTr3eecq+yUvo3giKVE4DX/kka2YWchlzz8DgC/uuoMrs7uXsceItKa1JkMnHPX1rJpTA11HTC1luPMBGbWUJ4DDKkrDmmYh98MXhH84T+GMW5w5zBHIyKRRmMLW4Gi0nLmrtgBwLjBndF9fSJyND21tIVa8tleNuUfZH9xGb94bS0AD339DCUCEamRkkELVHColEl//PCY8quzM2uoLSKiZNDirNtRyK3PLK1a/+2koSTERjNmYCddFYhIrZQMmrmKgONQaTnzV+1k/uqdLFy3i5Ly4E1l/7z1XIb3aF/HEURElAyatT/8eyPTfX9ApQ5t4rh2RFf6ZbRjWFZqeAITkWZHyaCZ+njrvqpE8OWBGQzNTOGCfukM7Z4a3sBEpFlSMmiGiksruO//VgHw5g8uoE+ndmGOSESaOyWDZmJ/cRlPvJ3LFWd2Y8Ij7wLw1aFdlQhEpFEoGUSQldv28+s31pG76yBPfHMY7RJiSUuKIzEumqE/ewOAP/57ExB8ttAPLukXznBFpAVRMgizhWt30a9zO/77uY9ZsvnIHEKX//79GutfdkYXhmam8J0v9dZQURFpNEoGYbRtXzE3Pv1RtbK3/udCPsnbx93/u4rCknJG9EyrShLqHxCRpqJkEEa7DhyuWo6JMv536nn0Tm9L7/S2XD60GwZE+QloSsoriI+JDlOkItLSKRmEyT9ytvL6yuDD41685RxOz0yp9mZ/9CxkSgQi0pSUDMIgv7CEH774KQDt4mPo0aGN3uxFJKyUDMJgV2GweeiH4/rzHyN7kJIUG+aIRKS103wGp9jG/INc9mhwDuKRvdKUCEQkIujKoAncO2cVizbt4arhmYzu34mstCTiYqJwzjFldg4AZ/dsT//OGhkkIpEhYpKBmY0HHgGigaecc9PDHNJJmfrMMl5dsR2A+19dw/2vrqFTu3iuHZHF/uIyNuYf4geX9OO7Y/qGOVIRkSMiIhmYWTTwOHAJkAd8ZGZznHOrG/tcZRUBfvfmetZsL+T6c3owun+nkz5WeUWAq//4Ie2T4ujZoQ0X9OtYlQgW3zmGzbsPsbWgmMfe2sAjCzZU7TeiV1qDvw8RkcYUEckAGAHkOuc2AZjZc8BEoNGTwW3PLGP+6p0AvLV2FxPP7MoDV55O2/iafxTzV+9kWFYqf1v0ORWBAH/5YDMv3nIuPToksWjTHpZ/vq+q7sz3PwPgu2P6kpGcQEZyAiOBsYMzuOullXRNTSQpLpphWZpjQEQiS6Qkg27A1pD1PGDk0ZXMbAowBSArK+uET3LgcBkbdhZyQb90fjSuP1957D1e/vgL9hWV0atjG4pLK/jK0C6c36cjZsa6HYV8x7fxhxr3u3eqrb/63fPZsf8wN80K1r309M7VticnxPLotWedcLwiIqeKOefCHQNmdhUw3jl3s1//FjDSOXd7bftkZ2e7nJxj36jrUl4RoDzgSIiN5lBJOUPuncfRP4JuqYk8+R/DePqDzfxr2bZq2/5200g+3LSbBWt20aNDEhf0S+e6EVmYGY8vzCXKjFsu1HODRCTymNlS51x2jdsiJBmcA9zrnBvn1+8AcM79orZ9TjYZHG1fUSln3jcfCH7CX7algF++vo6DJeVVdVbfN459RWWs21HIRQNOvo9BRCScjpcMIqWZ6COgr5n1ArYB1wDXnYoTpybF8fHdl7BuRyGDu6YwuGsKYwZm8Id/b2TplgJ+8bXTSYqLISkuhq6piaciJBGRUy4ikoFzrtzMbgfmERxaOtM5t+pUnT81KY6RvTtUrXdNTeS+iUNO1elFRMIuIpIBgHNuLjA33HGIiLRGehyFiIgoGYiIiJKBiIigZCAiIigZiIgISgYiIoKSgYiIECGPozgZZpYPbDnJ3TsCuxsxnKbQHGIExdnYFGfjUpzV9XDOpde0odkmg4Yws5zans8RKZpDjKA4G5vibFyKs/7UTCQiIkoGIiLSepPBjHAHUA/NIUZQnI1NcTYuxVlPrbLPQEREqmutVwYiIhJCyUBERFpXMjCz8Wa2zsxyzWzaKTrnTDPbZWYrQ8rSzGy+mW3wX9v7cjOzR318n5rZsJB9Jvv6G8xsckj5cDNb4fd51E5i8mUz625mC81stZmtMrPvRWicCWa2xMw+8XH+zJf3MrPF/tjPm1mcL4/367l+e8+QY93hy9eZ2biQ8kb7GzGzaDNbbmavRGqcZrbZ/14+NrMcXxZRv3d/nFQze9HM1prZGjM7J9LiNLP+/udY+TpgZt+PtDhr5ZxrFS+CM6htBHoDccAnwKBTcN4LgGHAypCyh4Bpfnka8Eu/fCnwGmDAKGCxL08DNvmv7f1ye79tia9rft8JJxFjF2CYX24HrAcGRWCcBrT1y7HAYn/MF4BrfPkfgFv98m3AH/zyNcDzfnmQ//3HA73830V0Y/+NAD8A/g684tcjLk5gM9DxqLKI+r3748wCbvbLcUBqJMYZEm80sAPoEclxVou5sQ4U6S/gHGBeyPodwB2n6Nw9qZ4M1gFd/HIXYJ1f/iNw7dH1gGuBP4aU/9GXdQHWhpRXq9eAeF8GLonkOIEkYBkwkuCdmzFH/54JTqN6jl+O8fXs6N99Zb3G/BsBMoEFwMXAK/68kRjnZo5NBhH1ewdSgM/wA14iNc6jYhsLvB/pcYa+WlMzUTdga8h6ni8Lhwzn3Ha/vAPI8Mu1xXi88rwayk+ab6I4i+Cn7oiL0ze9fAzsAuYT/IS8zzlXXsOxq+Lx2/cDHU4i/pPxO+BHQMCvd4jQOB3whpktNbMpvizSfu+9gHzgL77Z7SkzaxOBcYa6BnjWL0dynFVaUzKISC6Y4iNifK+ZtQX+CXzfOXcgdFukxOmcq3DOnUnwk/cIYEB4IzqWmX0F2OWcWxruWOrhfOfcMGACMNXMLgjdGCG/9xiCTa1POufOAg4RbG6pEiFxAuD7gi4H/nH0tkiK82itKRlsA7qHrGf6snDYaWZdAPzXXb68thiPV55ZQ/kJM7NYgongGefcvyI1zkrOuX3AQoJNJqlmFlPDsavi8dtTgD0nEf+JOg+43Mw2A88RbCp6JALjxDm3zX/dBbxEMMFG2u89D8hzzi326y8STA6RFmelCcAy59xOvx6pcVbXWO1Nkf4i+OliE8FLzspOt8Gn6Nw9qd5n8Cuqdyg95Jcvo3qH0hJfnkawzbS9f30GpPltR3coXXoS8RkwG/jdUeWRFmc6kOqXE4F3ga8Q/AQW2jF7m1+eSvWO2Rf88mCqd8xuItjh1+h/I8BojnQgR1ScQBugXcjyB8D4SPu9++O8C/T3y/f6GCMuTn+s54AbI/X/qNa4G+tAzeFFsPd+PcF25p+conM+C2wHygh+wrmJYHvwAmAD8GbIL9qAx318K4DskON8G8j1r9A/tGxgpd/n9xzVyVbPGM8neOn6KfCxf10agXGeASz3ca4E7vblvf0/SS7BN9x4X57g13P99t4hx/qJj2UdISMyGvtvhOrJIKLi9PF84l+rKo8Tab93f5wzgRz/u/9fgm+SkRhnG4JXdSkhZREXZ00vPY5CRERaVZ+BiIjUQslARESUDERERMlARERQMhAREZQMREQEJQMREQH+PxILby7O/ifZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp['train']['profit'].cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ignored-frederick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp['test']['profit'].cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cloudy-pizza",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71683.21018249515"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(profits['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "color-buyer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6236.254349987728"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(profits['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "assumed-friend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.836031539659188"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(252 ** 0.5) * np.mean(profits['train']) / np.std(profits['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "announced-shock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8594396218016983"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(252 ** 0.5) * np.mean(profits['test']) / np.std(profits['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-flour",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
