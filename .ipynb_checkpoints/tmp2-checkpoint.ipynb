{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc3aafa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deed5985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 4GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "weighted-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cosmetic-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc2ba2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "106afdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, models, optimizers\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv2D, Flatten, Dense, LSTM, ConvLSTM2D, MaxPool2D, Dropout, Conv1D, Activation, MaxPooling1D, CuDNNLSTM\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db33269f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "refined-engineering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6b3f7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a1a7683",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 6*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3fb9ce9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_crypt.csv')\n",
    "test = pd.read_csv('test_crypt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ahead-halifax",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['symbol'] == 'btcusd.csv']\n",
    "test = test[test['symbol'] == 'btcusd.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "extraordinary-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "induced-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def normalize(data, window, step):\n",
    "    ohlc = data[step - window + 1:step + 1, :].copy()\n",
    "    min_low = ohlc[:, :4].min()\n",
    "    ohlc[:, :4] = ohlc[:, :4] - min_low\n",
    "\n",
    "    max_high = ohlc[:, :4].max()\n",
    "    ohlc[:, :4] = ohlc[:, :4] / max_high\n",
    "\n",
    "    min_low = ohlc[:, 5:].min(axis=0)\n",
    "    ohlc[:, 5:] = ohlc[:, 5:] - min_low\n",
    "\n",
    "    max_high = ohlc[:, 5:].max(axis=0)\n",
    "    ohlc[:, 5:] = ohlc[:, 5:] / max_high\n",
    "\n",
    "    return ohlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "british-kinase",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "490000\n",
      "500000\n",
      "510000\n",
      "520000\n",
      "530000\n",
      "540000\n",
      "550000\n",
      "560000\n",
      "570000\n",
      "580000\n",
      "590000\n",
      "600000\n",
      "610000\n",
      "620000\n",
      "630000\n",
      "640000\n",
      "650000\n",
      "660000\n",
      "670000\n",
      "680000\n",
      "690000\n",
      "700000\n",
      "710000\n",
      "720000\n",
      "730000\n",
      "740000\n",
      "750000\n",
      "760000\n",
      "770000\n",
      "780000\n",
      "790000\n",
      "800000\n",
      "810000\n",
      "820000\n",
      "830000\n",
      "840000\n",
      "850000\n",
      "860000\n",
      "870000\n",
      "880000\n",
      "890000\n",
      "900000\n",
      "910000\n",
      "920000\n",
      "930000\n",
      "940000\n",
      "950000\n",
      "960000\n",
      "970000\n",
      "980000\n",
      "990000\n",
      "1000000\n",
      "1010000\n",
      "1020000\n",
      "1030000\n",
      "1040000\n",
      "1050000\n",
      "1060000\n",
      "1070000\n",
      "1080000\n",
      "1090000\n",
      "1100000\n",
      "1110000\n",
      "1120000\n",
      "1130000\n",
      "1140000\n",
      "1150000\n",
      "1160000\n",
      "1170000\n",
      "1180000\n",
      "1190000\n",
      "1200000\n",
      "1210000\n",
      "1220000\n",
      "1230000\n",
      "1240000\n",
      "1250000\n",
      "1260000\n",
      "1270000\n",
      "1280000\n",
      "1290000\n",
      "1300000\n",
      "1310000\n",
      "1320000\n",
      "1330000\n",
      "1340000\n",
      "1350000\n",
      "1360000\n",
      "1370000\n",
      "1380000\n",
      "1390000\n",
      "1400000\n",
      "1410000\n",
      "1420000\n",
      "1430000\n",
      "1440000\n",
      "1450000\n",
      "1460000\n",
      "1470000\n",
      "1480000\n",
      "1490000\n",
      "1500000\n",
      "1510000\n",
      "1520000\n",
      "1530000\n",
      "1540000\n",
      "1550000\n",
      "1560000\n",
      "1570000\n",
      "1580000\n",
      "1590000\n",
      "1600000\n",
      "1610000\n",
      "1620000\n",
      "1630000\n",
      "1640000\n",
      "1650000\n",
      "1660000\n",
      "1670000\n",
      "1680000\n",
      "1690000\n",
      "1700000\n",
      "1710000\n",
      "1720000\n",
      "1730000\n",
      "1740000\n",
      "1750000\n",
      "1760000\n",
      "1770000\n",
      "1780000\n",
      "1790000\n",
      "1800000\n",
      "1810000\n",
      "1820000\n",
      "1830000\n",
      "1840000\n",
      "1850000\n",
      "1860000\n",
      "1870000\n",
      "1880000\n",
      "1890000\n",
      "1900000\n",
      "1910000\n",
      "1920000\n",
      "1930000\n",
      "1940000\n",
      "1950000\n",
      "1960000\n",
      "1970000\n",
      "1980000\n",
      "1990000\n",
      "2000000\n",
      "2010000\n",
      "2020000\n",
      "2030000\n",
      "2040000\n",
      "2050000\n",
      "2060000\n",
      "2070000\n",
      "2080000\n",
      "2090000\n",
      "2100000\n",
      "2110000\n",
      "2120000\n",
      "2130000\n",
      "2140000\n",
      "2150000\n",
      "2160000\n",
      "2170000\n",
      "2180000\n",
      "2190000\n",
      "2200000\n",
      "2210000\n",
      "2220000\n",
      "2230000\n",
      "2240000\n",
      "2250000\n",
      "2260000\n",
      "2270000\n",
      "2280000\n",
      "2290000\n",
      "2300000\n",
      "2310000\n",
      "2320000\n",
      "2330000\n",
      "2340000\n",
      "2350000\n",
      "2360000\n",
      "2370000\n",
      "2380000\n",
      "2390000\n",
      "2400000\n",
      "2410000\n",
      "2420000\n",
      "2430000\n",
      "2440000\n",
      "2450000\n",
      "2460000\n",
      "2470000\n",
      "2480000\n",
      "2490000\n",
      "2500000\n",
      "2510000\n",
      "2520000\n",
      "2530000\n",
      "2540000\n",
      "2550000\n",
      "2560000\n",
      "2570000\n",
      "2580000\n",
      "2590000\n",
      "2600000\n",
      "2610000\n",
      "2620000\n",
      "2630000\n",
      "2640000\n",
      "2650000\n",
      "2660000\n",
      "2670000\n",
      "2680000\n",
      "2690000\n",
      "2700000\n",
      "2710000\n",
      "2720000\n",
      "2730000\n",
      "2740000\n",
      "2750000\n",
      "2760000\n",
      "2770000\n",
      "2780000\n",
      "2790000\n",
      "2800000\n",
      "2810000\n",
      "2820000\n",
      "2830000\n",
      "2840000\n",
      "2850000\n",
      "2860000\n",
      "2870000\n",
      "2880000\n",
      "2890000\n",
      "2900000\n",
      "2910000\n",
      "2920000\n",
      "2930000\n",
      "2940000\n",
      "2950000\n",
      "2960000\n",
      "2970000\n",
      "2980000\n",
      "2990000\n",
      "3000000\n",
      "3010000\n",
      "3020000\n",
      "3030000\n",
      "3040000\n",
      "3050000\n",
      "3060000\n",
      "3070000\n",
      "3080000\n",
      "3090000\n",
      "3100000\n",
      "3110000\n",
      "3120000\n",
      "3130000\n",
      "3140000\n",
      "CPU times: user 7min 13s, sys: 35.6 s, total: 7min 48s\n",
      "Wall time: 7min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "frame = '_1min'\n",
    "candlestick_c = ['open_1min', 'high_1min', 'low_1min', 'close_1min']\n",
    "values = candlestick_c + [c for c in train.columns if c not in candlestick_c and frame in c]\n",
    "ohlc = train[values].values\n",
    "\n",
    "inputs_train = np.empty(shape=(len(ohlc) - window_size-1,) + normalize(ohlc, window_size , window_size-1).shape)\n",
    "for i in range(len(ohlc) - window_size-1):\n",
    "    if i % 10000 == 0:\n",
    "        print(i)\n",
    "    inputs_train[i] = normalize(ohlc, window_size , i+window_size-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cordless-minimum",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "CPU times: user 29.5 s, sys: 2.42 s, total: 32 s\n",
      "Wall time: 31.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "frame = '_1min'\n",
    "candlestick_c = ['open_1min', 'high_1min', 'low_1min', 'close_1min']\n",
    "values = candlestick_c + [c for c in test.columns if c not in candlestick_c and frame in c]\n",
    "ohlc = test[values].values\n",
    "\n",
    "inputs_test = np.empty(shape=(len(ohlc) - window_size-1,) + normalize(ohlc, window_size , window_size-1).shape)\n",
    "for i in range(len(ohlc) - window_size-1):\n",
    "    if i % 10000 == 0:\n",
    "        print(i)\n",
    "    inputs_test[i] = normalize(ohlc, window_size , i+window_size-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "occupied-environment",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_crypt.csv').iloc[window_size-1:]\n",
    "test = pd.read_csv('test_crypt.csv').iloc[window_size-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "wicked-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.iloc[window_size-1:]\n",
    "test = test.iloc[window_size-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "duplicate-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"inputs_train_crypt_{window_size}.npy\", inputs_train)\n",
    "np.save(f\"inputs_test_crypt_{window_size}.npy\", inputs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "sudden-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = np.load(f\"inputs_train_{window_size}.npy\")\n",
    "inputs_test = np.load(f\"inputs_test_{window_size}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b19933fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_size = 50\n",
    "time_limit = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bridal-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([train['close_1min'].values[:-time_limit], train['close_1min'].values[time_limit:]]).T\n",
    "y_true_pred = np.array([test['close_1min'].values[:-time_limit], test['close_1min'].values[time_limit:]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "auburn-grant",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = inputs_train[:len(y_true)]\n",
    "inputs_test = inputs_test[:len(y_true_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "academic-adventure",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = []\n",
    "for i in range(time_limit):\n",
    "    idxs.extend(list(range(i, len(inputs_train), time_limit)))\n",
    "idxs = np.array(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "magnetic-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs_test = []\n",
    "for i in range(time_limit):\n",
    "    idxs_test.extend(list(range(i, len(inputs_test), time_limit)))\n",
    "idxs_test = np.array(idxs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "flexible-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = inputs_train[idxs]\n",
    "inputs_test = inputs_test[idxs_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "adolescent-powell",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_true[idxs]\n",
    "y_true_pred = y_true_pred[idxs_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7c382044",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = inputs_train[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "187a2689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 13)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "60e413db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3146208, 360, 13), (3146223, 16))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train.shape, train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3bd587f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((213458, 360, 13), (213473, 16))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "reasonable-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanm(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_pred)\n",
    "def absmeanm(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.abs(y_pred))\n",
    "def minm(y_true, y_pred):\n",
    "    return tf.reduce_min(y_pred)\n",
    "def maxm(y_true, y_pred):\n",
    "    return tf.reduce_max(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "useful-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_metric_wrapper(margin_size):  \n",
    "    def profit(y_true, y_pred):\n",
    "        margin = y_pred[:,:1] \n",
    "        \n",
    "        close1 = y_true[:,:1]\n",
    "        close2 = y_true[:,1:2]\n",
    "        diff = close2 - close1\n",
    "\n",
    "        profit = 100 * margin * ((diff/close1))\n",
    "        x = tf.reduce_mean(profit)\n",
    "        return x\n",
    "    return profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "58d2407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_wrapper(margin_size):  \n",
    "    def custom_loss(y_true, y_pred):\n",
    "        margin = y_pred[:,:1]\n",
    "        \n",
    "        close1 = y_true[:,:1]\n",
    "        close2 = y_true[:,1:2]\n",
    "        diff = close2 - close1\n",
    "\n",
    "        profit = 100 * margin * ((diff/close1))\n",
    "        mean = tf.reduce_mean(profit)\n",
    "        idx_downside = profit < 0\n",
    "#         downside_std = tf.math.reduce_std(tf.boolean_mask(profit, idx_downside))\n",
    "        downside_std = tf.math.reduce_std(profit)\n",
    "#         downside_std = tf.where(downside_std < 0.01, 0.01, downside_std)\n",
    "        cond = tf.logical_and(tf.abs(mean) < 0.001, tf.abs(downside_std) < 0.001)\n",
    "#         sharpe = tf.cond(cond, lambda: 0*tf.ones_like(downside_std), lambda: ((252*24*60/time_limit) ** 0.5) * mean / downside_std)\n",
    "        sharpe = ((252*24*60/time_limit) ** 0.5) * mean / downside_std\n",
    "        x = tf.where(tf.abs(sharpe) < 0.01, 0*tf.ones_like(sharpe), -tf.sign(sharpe)*tf.log(tf.abs(sharpe)))\n",
    "#         x = -tf.sign(sharpe)*tf.log(tf.abs(sharpe))\n",
    "#         x = -sharpe\n",
    "#         x = tf.where(tf.abs(profit) < 0.01, 0*tf.ones_like(profit), -tf.sign(profit)*tf.log(tf.abs(profit)))\n",
    "#         x = -tf.sign(profit)*tf.log(tf.abs(profit))\n",
    "#         x = -profit\n",
    "        return tf.reduce_mean(x)\n",
    "    return custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "resident-canada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213832, 13)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohlc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "subtle-paint",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_features = ohlc.shape[1]\n",
    "n_seq = 12\n",
    "n_steps = 30\n",
    "X = inputs_train.reshape((inputs_train.shape[0], n_seq, n_steps, n_features, 1))\n",
    "X_test = inputs_test.reshape((inputs_test.shape[0], n_seq, n_steps, n_features, 1))\n",
    "def get_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(ConvLSTM2D(filters=32, kernel_size=(5,1), activation='relu', \n",
    "                         input_shape=(n_seq, n_steps, n_features, 1), dropout=0.5,))\n",
    "#                         kernel_regularizer='l1', recurrent_regularizer='l1'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "#     model = models.Sequential()\n",
    "#     model.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None, n_steps, n_features)))\n",
    "#     model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "#     model.add(TimeDistributed(Flatten()))\n",
    "#     model.add(LSTM(50, activation='relu'))\n",
    "#     model.add(Dense(1))\n",
    "    return model\n",
    "    \n",
    "model = get_model()\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001, clipnorm=1),\n",
    "    loss=custom_loss_wrapper(margin_size),\n",
    "    metrics=[custom_metric_wrapper(margin_size), absmeanm, meanm, minm, maxm],\n",
    "    run_eagerly=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "structured-adams",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3146207 samples, validate on 213457 samples\n",
      "Epoch 1/10000\n",
      "3146207/3146207 [==============================] - 753s 239us/sample - loss: -0.3722 - profit: 0.0081 - absmeanm: 0.9716 - meanm: 0.9716 - minm: 0.8190 - maxm: 1.0000 - val_loss: -0.1939 - val_profit: 0.0029 - val_absmeanm: 0.9601 - val_meanm: 0.9601 - val_minm: 0.0000e+00 - val_maxm: 1.0000\n",
      "Epoch 2/10000\n",
      "3146207/3146207 [==============================] - 756s 240us/sample - loss: -0.3402 - profit: 0.0078 - absmeanm: 0.7893 - meanm: 0.7893 - minm: 0.0488 - maxm: 1.0000 - val_loss: -0.1432 - val_profit: 0.0015 - val_absmeanm: 0.8586 - val_meanm: 0.8586 - val_minm: 0.0000e+00 - val_maxm: 1.0000\n",
      "Epoch 3/10000\n",
      "3146207/3146207 [==============================] - 755s 240us/sample - loss: -0.3898 - profit: 0.0082 - absmeanm: 0.9870 - meanm: 0.9870 - minm: 0.7283 - maxm: 1.0000 - val_loss: -0.2659 - val_profit: 0.0032 - val_absmeanm: 1.0000 - val_meanm: 1.0000 - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 4/10000\n",
      "3146207/3146207 [==============================] - 765s 243us/sample - loss: -0.3868 - profit: 0.0082 - absmeanm: 0.9999 - meanm: 0.9999 - minm: 0.9828 - maxm: 1.0000 - val_loss: -0.2121 - val_profit: 0.0031 - val_absmeanm: 1.0000 - val_meanm: 1.0000 - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 5/10000\n",
      "3146207/3146207 [==============================] - 760s 242us/sample - loss: -0.3861 - profit: 0.0082 - absmeanm: 1.0000 - meanm: 1.0000 - minm: 0.9997 - maxm: 1.0000 - val_loss: -0.2228 - val_profit: 0.0031 - val_absmeanm: 1.0000 - val_meanm: 1.0000 - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 6/10000\n",
      "3146207/3146207 [==============================] - 752s 239us/sample - loss: -0.3861 - profit: 0.0082 - absmeanm: 1.0000 - meanm: 1.0000 - minm: 1.0000 - maxm: 1.0000 - val_loss: -0.2248 - val_profit: 0.0031 - val_absmeanm: 1.0000 - val_meanm: 1.0000 - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 7/10000\n",
      "3146207/3146207 [==============================] - 759s 241us/sample - loss: -0.3862 - profit: 0.0082 - absmeanm: 0.9964 - meanm: 0.9964 - minm: 0.9235 - maxm: 1.0000 - val_loss: -0.2508 - val_profit: 0.0023 - val_absmeanm: 0.8931 - val_meanm: 0.8931 - val_minm: 0.0256 - val_maxm: 1.0000\n",
      "Epoch 8/10000\n",
      "3146207/3146207 [==============================] - 741s 235us/sample - loss: -0.3779 - profit: 0.0080 - absmeanm: 0.9117 - meanm: 0.9117 - minm: 0.0734 - maxm: 1.0000 - val_loss: -0.2913 - val_profit: 0.0026 - val_absmeanm: 0.7558 - val_meanm: 0.7558 - val_minm: 0.1076 - val_maxm: 1.0000\n",
      "Epoch 9/10000\n",
      "3146207/3146207 [==============================] - 740s 235us/sample - loss: -0.4162 - profit: 0.0078 - absmeanm: 0.8624 - meanm: 0.8624 - minm: 0.0153 - maxm: 1.0000 - val_loss: -0.0966 - val_profit: 0.0011 - val_absmeanm: 0.8202 - val_meanm: 0.8202 - val_minm: 0.0030 - val_maxm: 1.0000\n",
      "Epoch 10/10000\n",
      "3146207/3146207 [==============================] - 741s 235us/sample - loss: -0.4300 - profit: 0.0082 - absmeanm: 0.8984 - meanm: 0.8984 - minm: 0.0060 - maxm: 1.0000 - val_loss: -0.1475 - val_profit: 0.0014 - val_absmeanm: 0.8203 - val_meanm: 0.8203 - val_minm: 1.3040e-05 - val_maxm: 1.0000\n",
      "Epoch 11/10000\n",
      "3146207/3146207 [==============================] - 739s 235us/sample - loss: -0.4188 - profit: 0.0082 - absmeanm: 0.8877 - meanm: 0.8877 - minm: 0.0017 - maxm: 1.0000 - val_loss: -0.1015 - val_profit: 0.0015 - val_absmeanm: 0.8043 - val_meanm: 0.8043 - val_minm: 0.0000e+00 - val_maxm: 1.0000\n",
      "Epoch 12/10000\n",
      "3146207/3146207 [==============================] - 741s 235us/sample - loss: -0.4426 - profit: 0.0082 - absmeanm: 0.8741 - meanm: 0.8741 - minm: 0.0049 - maxm: 1.0000 - val_loss: -0.1201 - val_profit: 0.0011 - val_absmeanm: 0.7371 - val_meanm: 0.7371 - val_minm: 2.7949e-08 - val_maxm: 1.0000\n",
      "Epoch 13/10000\n",
      "3146207/3146207 [==============================] - 740s 235us/sample - loss: -0.4415 - profit: 0.0081 - absmeanm: 0.8612 - meanm: 0.8612 - minm: 3.3935e-04 - maxm: 1.0000 - val_loss: -0.1101 - val_profit: 0.0020 - val_absmeanm: 0.7101 - val_meanm: 0.7101 - val_minm: 9.9816e-10 - val_maxm: 1.0000\n",
      "Epoch 14/10000\n",
      "3146207/3146207 [==============================] - 741s 236us/sample - loss: -0.4635 - profit: 0.0080 - absmeanm: 0.7824 - meanm: 0.7824 - minm: 8.5149e-09 - maxm: 1.0000 - val_loss: -0.0614 - val_profit: 4.8157e-04 - val_absmeanm: 0.6890 - val_meanm: 0.6890 - val_minm: 0.0000e+00 - val_maxm: 1.0000\n",
      "Epoch 15/10000\n",
      "3146207/3146207 [==============================] - 740s 235us/sample - loss: -0.4526 - profit: 0.0069 - absmeanm: 0.8053 - meanm: 0.8053 - minm: 0.0000e+00 - maxm: 1.0000 - val_loss: 0.0489 - val_profit: 2.3215e-04 - val_absmeanm: 0.8444 - val_meanm: 0.8444 - val_minm: 5.7038e-10 - val_maxm: 1.0000\n",
      "Epoch 16/10000\n",
      "3146207/3146207 [==============================] - 740s 235us/sample - loss: -0.4582 - profit: 0.0083 - absmeanm: 0.8654 - meanm: 0.8654 - minm: 3.7823e-10 - maxm: 1.0000 - val_loss: -0.2302 - val_profit: 0.0029 - val_absmeanm: 0.4252 - val_meanm: 0.4252 - val_minm: 0.0000e+00 - val_maxm: 1.0000\n",
      "Epoch 17/10000\n",
      "3146207/3146207 [==============================] - 739s 235us/sample - loss: -0.4254 - profit: 0.0053 - absmeanm: 0.8259 - meanm: 0.8259 - minm: 0.0000e+00 - maxm: 1.0000 - val_loss: -0.0402 - val_profit: 9.8965e-04 - val_absmeanm: 0.8898 - val_meanm: 0.8898 - val_minm: 0.0000e+00 - val_maxm: 1.0000\n",
      "Epoch 18/10000\n",
      "3146207/3146207 [==============================] - 739s 235us/sample - loss: -0.4163 - profit: 0.0082 - absmeanm: 0.9308 - meanm: 0.9308 - minm: 0.0224 - maxm: 1.0000 - val_loss: -0.2638 - val_profit: 0.0037 - val_absmeanm: 0.7636 - val_meanm: 0.7636 - val_minm: 0.0000e+00 - val_maxm: 1.0000\n",
      "Epoch 19/10000\n",
      "3146207/3146207 [==============================] - 741s 236us/sample - loss: -0.2913 - profit: 0.0061 - absmeanm: 0.6583 - meanm: 0.6583 - minm: 0.0000e+00 - maxm: 1.0000 - val_loss: 0.1565 - val_profit: -2.7621e-04 - val_absmeanm: 0.6903 - val_meanm: 0.6903 - val_minm: 0.0000e+00 - val_maxm: 1.0000\n",
      "Epoch 20/10000\n",
      "3146207/3146207 [==============================] - 744s 236us/sample - loss: -0.3859 - profit: 0.0080 - absmeanm: 0.9741 - meanm: 0.9741 - minm: 0.4719 - maxm: 1.0000 - val_loss: -0.1667 - val_profit: 0.0031 - val_absmeanm: 0.9982 - val_meanm: 0.9982 - val_minm: 0.1914 - val_maxm: 1.0000\n",
      "Epoch 21/10000\n",
      "3146207/3146207 [==============================] - 743s 236us/sample - loss: -0.3769 - profit: 0.0053 - absmeanm: 0.9619 - meanm: 0.9619 - minm: 0.3781 - maxm: 1.0000 - val_loss: -0.2573 - val_profit: 0.0031 - val_absmeanm: 0.9985 - val_meanm: 0.9985 - val_minm: 0.2536 - val_maxm: 1.0000\n",
      "Epoch 22/10000\n",
      "3146207/3146207 [==============================] - 745s 237us/sample - loss: -0.3490 - profit: 0.0077 - absmeanm: 0.8039 - meanm: 0.8039 - minm: 0.1813 - maxm: 1.0000 - val_loss: 0.3733 - val_profit: -0.0037 - val_absmeanm: 0.2987 - val_meanm: 0.2987 - val_minm: 0.0000e+00 - val_maxm: 1.0000\n",
      "Epoch 23/10000\n",
      "3146207/3146207 [==============================] - 745s 237us/sample - loss: -0.1435 - profit: 0.0025 - absmeanm: 0.3304 - meanm: 0.3304 - minm: 3.2541e-04 - maxm: 1.0000 - val_loss: -0.0783 - val_profit: 1.1005e-04 - val_absmeanm: 0.0102 - val_meanm: 0.0102 - val_minm: 0.0000e+00 - val_maxm: 1.0000\n",
      "Epoch 24/10000\n",
      "3146207/3146207 [==============================] - 746s 237us/sample - loss: -0.2751 - profit: 0.0071 - absmeanm: 0.5490 - meanm: 0.5490 - minm: 0.0000e+00 - maxm: 1.0000 - val_loss: 0.2772 - val_profit: -0.0031 - val_absmeanm: 0.3715 - val_meanm: 0.3715 - val_minm: 0.0000e+00 - val_maxm: 1.0000\n",
      "Epoch 25/10000\n",
      "3146207/3146207 [==============================] - 744s 236us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 0.2704 - maxm: 0.9997 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 26/10000\n",
      "3146207/3146207 [==============================] - 742s 236us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 27/10000\n",
      "3146207/3146207 [==============================] - 742s 236us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/10000\n",
      "3146207/3146207 [==============================] - 741s 236us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 29/10000\n",
      "3146207/3146207 [==============================] - 741s 235us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 30/10000\n",
      "3146207/3146207 [==============================] - 741s 235us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 31/10000\n",
      "3146207/3146207 [==============================] - 740s 235us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 32/10000\n",
      "3146207/3146207 [==============================] - 741s 235us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 33/10000\n",
      "3146207/3146207 [==============================] - 740s 235us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 34/10000\n",
      "3146207/3146207 [==============================] - 740s 235us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 35/10000\n",
      "3146207/3146207 [==============================] - 740s 235us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 36/10000\n",
      "3146207/3146207 [==============================] - 741s 235us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 37/10000\n",
      "3146207/3146207 [==============================] - 740s 235us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 38/10000\n",
      "3146207/3146207 [==============================] - 741s 235us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 39/10000\n",
      "3146207/3146207 [==============================] - 740s 235us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 40/10000\n",
      "3146207/3146207 [==============================] - 740s 235us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 41/10000\n",
      "3146207/3146207 [==============================] - 740s 235us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 42/10000\n",
      "3146207/3146207 [==============================] - 741s 235us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 43/10000\n",
      "3146207/3146207 [==============================] - 740s 235us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 44/10000\n",
      "3146207/3146207 [==============================] - 742s 236us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 45/10000\n",
      "3146207/3146207 [==============================] - 740s 235us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 46/10000\n",
      "3146207/3146207 [==============================] - 741s 236us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 47/10000\n",
      "3146207/3146207 [==============================] - 740s 235us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 48/10000\n",
      "3146207/3146207 [==============================] - 741s 235us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 49/10000\n",
      "3146207/3146207 [==============================] - 740s 235us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 50/10000\n",
      "3146207/3146207 [==============================] - 740s 235us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 51/10000\n",
      "3146207/3146207 [==============================] - 740s 235us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 52/10000\n",
      "3146207/3146207 [==============================] - 741s 236us/sample - loss: nan - profit: nan - absmeanm: nan - meanm: nan - minm: 1.0000 - maxm: 1.0000 - val_loss: nan - val_profit: nan - val_absmeanm: nan - val_meanm: nan - val_minm: 1.0000 - val_maxm: 1.0000\n",
      "Epoch 53/10000\n",
      "2887680/3146207 [==========================>...] - ETA: 59s - loss: -0.3840 - profit: 0.0085 - absmeanm: 1.0000 - meanm: 1.0000 - minm: 1.0000 - maxm: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-757802d32ccb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#     use_multiprocessing=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#     workers=0,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m#     max_queue_size=100,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#     validation_freq=1000,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size=2**10\n",
    "\n",
    "buffer = 0\n",
    "buffer_test = 0\n",
    "leftover = X[:-buffer].shape[0] % batch_size\n",
    "leftover_test = X_test[:-buffer_test].shape[0] % batch_size\n",
    "\n",
    "history = model.fit(\n",
    "    X[:-1-leftover-buffer], \n",
    "    y_true[:-1-leftover-buffer], \n",
    "    validation_data=(X_test[:-1-leftover_test-buffer_test], y_true_pred[:-1-leftover_test-buffer_test]),\n",
    "#     validation_steps=32*5//batch_size,\n",
    "#     validation_data=(tf.convert_to_tensor(inputs_test[:32*5]), tf.convert_to_tensor([[1, i] for i in range(32*5)])),\n",
    "    epochs=10000, \n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    "#     callbacks=[callback],\n",
    "#     use_multiprocessing=True, \n",
    "#     workers=0,\n",
    "    verbose=1, \n",
    "#     max_queue_size=100,\n",
    "#     validation_freq=1000,\n",
    "#     initial_epoch=model.history.epoch[-1],\n",
    "#     initial_epoch=15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-illustration",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# model.evaluate(X_test, y_true_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-fence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-emergency",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-twist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, X, y, validation_data):\n",
    "        # Should be the label encoding of your classes\n",
    "        self.test_data, self.y_true = validation_data\n",
    "        \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        if batch != 0 and batch % 300 == 0:\n",
    "            print()\n",
    "            val_loss = self.model.evaluate(self.test_data, self.y_true)\n",
    "            print('validation loss: {}'.format(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "known-prague",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    model = models.Sequential()\n",
    "    # model.add(LSTM(64, input_shape = img.shape, return_sequences=True, dropout=0.2))\n",
    "    model.add(CuDNNLSTM(64, kernel_regularizer='l2', input_shape=img.shape))\n",
    "    # model.add(LSTM(32, dropout=0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "    return model\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "77b2e14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "77d24985",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-87-646089be221f>:18: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001, clipnorm=1),\n",
    "    loss=custom_loss_wrapper(margin_size),\n",
    "    metrics=[custom_metric_wrapper(margin_size), absmeanm, meanm, minm, maxm],\n",
    "    run_eagerly=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c3f26f0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3146207 samples, validate on 213457 samples\n",
      "Epoch 1/10000\n",
      "3146207/3146207 [==============================] - 180s 57us/sample - loss: -0.7801 - profit: 0.0013 - absmeanm: 0.0543 - meanm: 0.0543 - minm: 0.0077 - maxm: 0.4157 - val_loss: -0.9108 - val_profit: 2.0568e-04 - val_absmeanm: 0.0030 - val_meanm: 0.0030 - val_minm: 5.7424e-04 - val_maxm: 0.0807\n",
      "Epoch 2/10000\n",
      "3146207/3146207 [==============================] - 166s 53us/sample - loss: -1.0474 - profit: 0.0016 - absmeanm: 0.0409 - meanm: 0.0409 - minm: 0.0015 - maxm: 0.4774 - val_loss: -1.0695 - val_profit: 0.0022 - val_absmeanm: 0.0281 - val_meanm: 0.0281 - val_minm: 4.3936e-04 - val_maxm: 0.5770\n",
      "Epoch 3/10000\n",
      "3146207/3146207 [==============================] - 183s 58us/sample - loss: -1.1697 - profit: 0.0016 - absmeanm: 0.0231 - meanm: 0.0231 - minm: 1.8685e-04 - maxm: 0.4718 - val_loss: -0.6870 - val_profit: 0.0014 - val_absmeanm: 0.0274 - val_meanm: 0.0274 - val_minm: 7.9635e-05 - val_maxm: 0.7422\n",
      "Epoch 4/10000\n",
      "3146207/3146207 [==============================] - 165s 53us/sample - loss: -1.2237 - profit: 0.0019 - absmeanm: 0.0308 - meanm: 0.0308 - minm: 4.9984e-05 - maxm: 0.5635 - val_loss: -0.7156 - val_profit: 0.0011 - val_absmeanm: 0.0359 - val_meanm: 0.0359 - val_minm: 1.1267e-05 - val_maxm: 0.6140\n",
      "Epoch 5/10000\n",
      "3146207/3146207 [==============================] - 171s 54us/sample - loss: -1.3298 - profit: 0.0022 - absmeanm: 0.0307 - meanm: 0.0307 - minm: 1.1213e-05 - maxm: 0.5669 - val_loss: -0.9051 - val_profit: 9.5696e-04 - val_absmeanm: 0.0202 - val_meanm: 0.0202 - val_minm: 6.7206e-06 - val_maxm: 0.5062\n",
      "Epoch 6/10000\n",
      "3146207/3146207 [==============================] - 166s 53us/sample - loss: -1.3693 - profit: 0.0024 - absmeanm: 0.0350 - meanm: 0.0350 - minm: 7.3879e-06 - maxm: 0.5885 - val_loss: -0.8489 - val_profit: 0.0013 - val_absmeanm: 0.0277 - val_meanm: 0.0277 - val_minm: 2.2677e-06 - val_maxm: 0.5592\n",
      "Epoch 7/10000\n",
      "3146207/3146207 [==============================] - 171s 54us/sample - loss: -1.4300 - profit: 0.0025 - absmeanm: 0.0366 - meanm: 0.0366 - minm: 2.3857e-06 - maxm: 0.5920 - val_loss: -0.9002 - val_profit: 0.0024 - val_absmeanm: 0.0525 - val_meanm: 0.0525 - val_minm: 1.3470e-06 - val_maxm: 0.7884\n",
      "Epoch 8/10000\n",
      "3146207/3146207 [==============================] - 165s 52us/sample - loss: -1.5111 - profit: 0.0030 - absmeanm: 0.0434 - meanm: 0.0434 - minm: 2.8903e-06 - maxm: 0.6426 - val_loss: -1.0187 - val_profit: 0.0012 - val_absmeanm: 0.0199 - val_meanm: 0.0199 - val_minm: 1.2034e-06 - val_maxm: 0.4653\n",
      "Epoch 9/10000\n",
      "3146207/3146207 [==============================] - 184s 59us/sample - loss: -1.5795 - profit: 0.0024 - absmeanm: 0.0335 - meanm: 0.0335 - minm: 1.0030e-06 - maxm: 0.4984 - val_loss: -1.1091 - val_profit: 8.3156e-04 - val_absmeanm: 0.0158 - val_meanm: 0.0158 - val_minm: 3.9442e-07 - val_maxm: 0.4272\n",
      "Epoch 10/10000\n",
      "3146207/3146207 [==============================] - 165s 52us/sample - loss: -1.7070 - profit: 0.0023 - absmeanm: 0.0292 - meanm: 0.0292 - minm: 3.6046e-07 - maxm: 0.5094 - val_loss: -0.9574 - val_profit: 0.0011 - val_absmeanm: 0.0211 - val_meanm: 0.0211 - val_minm: 2.3671e-07 - val_maxm: 0.5667\n",
      "Epoch 11/10000\n",
      "3146207/3146207 [==============================] - 183s 58us/sample - loss: -1.6967 - profit: 0.0027 - absmeanm: 0.0356 - meanm: 0.0356 - minm: 2.4168e-07 - maxm: 0.5902 - val_loss: -0.7685 - val_profit: 9.0800e-04 - val_absmeanm: 0.0296 - val_meanm: 0.0296 - val_minm: 1.5999e-07 - val_maxm: 0.6097\n",
      "Epoch 12/10000\n",
      "3146207/3146207 [==============================] - 166s 53us/sample - loss: -1.8502 - profit: 0.0029 - absmeanm: 0.0340 - meanm: 0.0340 - minm: 1.7938e-07 - maxm: 0.6321 - val_loss: -0.6868 - val_profit: 0.0010 - val_absmeanm: 0.0461 - val_meanm: 0.0461 - val_minm: 1.6598e-07 - val_maxm: 0.7299\n",
      "Epoch 13/10000\n",
      "3146207/3146207 [==============================] - 166s 53us/sample - loss: -1.9257 - profit: 0.0029 - absmeanm: 0.0329 - meanm: 0.0329 - minm: 1.1320e-07 - maxm: 0.6289 - val_loss: -0.7050 - val_profit: 0.0011 - val_absmeanm: 0.0435 - val_meanm: 0.0435 - val_minm: 7.5718e-08 - val_maxm: 0.6703\n",
      "Epoch 14/10000\n",
      "3146207/3146207 [==============================] - 163s 52us/sample - loss: -2.0171 - profit: 0.0030 - absmeanm: 0.0304 - meanm: 0.0304 - minm: 5.9207e-08 - maxm: 0.6033 - val_loss: -0.4636 - val_profit: 5.8240e-04 - val_absmeanm: 0.0340 - val_meanm: 0.0340 - val_minm: 6.1886e-08 - val_maxm: 0.6007\n",
      "Epoch 15/10000\n",
      "3146207/3146207 [==============================] - 182s 58us/sample - loss: -2.0369 - profit: 0.0028 - absmeanm: 0.0301 - meanm: 0.0301 - minm: 5.6230e-08 - maxm: 0.5875 - val_loss: -0.9430 - val_profit: 0.0013 - val_absmeanm: 0.0304 - val_meanm: 0.0304 - val_minm: 2.1817e-08 - val_maxm: 0.6558\n",
      "Epoch 16/10000\n",
      "3146207/3146207 [==============================] - 165s 53us/sample - loss: -2.1721 - profit: 0.0027 - absmeanm: 0.0278 - meanm: 0.0278 - minm: 3.1538e-08 - maxm: 0.6002 - val_loss: -0.8970 - val_profit: 0.0012 - val_absmeanm: 0.0305 - val_meanm: 0.0305 - val_minm: 2.7378e-08 - val_maxm: 0.6739\n",
      "Epoch 17/10000\n",
      "3146207/3146207 [==============================] - 171s 54us/sample - loss: -2.2320 - profit: 0.0026 - absmeanm: 0.0263 - meanm: 0.0263 - minm: 2.4080e-08 - maxm: 0.5834 - val_loss: -0.8961 - val_profit: 0.0014 - val_absmeanm: 0.0377 - val_meanm: 0.0377 - val_minm: 5.1477e-08 - val_maxm: 0.6588\n",
      "Epoch 18/10000\n",
      "3146207/3146207 [==============================] - 166s 53us/sample - loss: -2.2941 - profit: 0.0026 - absmeanm: 0.0259 - meanm: 0.0259 - minm: 1.7903e-08 - maxm: 0.5873 - val_loss: -0.6216 - val_profit: 7.7369e-04 - val_absmeanm: 0.0307 - val_meanm: 0.0307 - val_minm: 2.4241e-09 - val_maxm: 0.6762\n",
      "Epoch 19/10000\n",
      "3146207/3146207 [==============================] - 168s 53us/sample - loss: -2.3325 - profit: 0.0028 - absmeanm: 0.0285 - meanm: 0.0285 - minm: 6.2165e-09 - maxm: 0.6170 - val_loss: -0.7204 - val_profit: 9.6455e-04 - val_absmeanm: 0.0349 - val_meanm: 0.0349 - val_minm: 2.8519e-10 - val_maxm: 0.6701\n",
      "Epoch 20/10000\n",
      "3146207/3146207 [==============================] - 165s 53us/sample - loss: -2.3692 - profit: 0.0031 - absmeanm: 0.0303 - meanm: 0.0303 - minm: 2.2403e-09 - maxm: 0.6371 - val_loss: -0.8286 - val_profit: 0.0012 - val_absmeanm: 0.0414 - val_meanm: 0.0414 - val_minm: 1.2834e-09 - val_maxm: 0.6905\n",
      "Epoch 21/10000\n",
      "3146207/3146207 [==============================] - 184s 58us/sample - loss: -2.4006 - profit: 0.0029 - absmeanm: 0.0283 - meanm: 0.0283 - minm: 3.1907e-09 - maxm: 0.6236 - val_loss: -0.5340 - val_profit: 0.0010 - val_absmeanm: 0.0499 - val_meanm: 0.0499 - val_minm: 7.1297e-10 - val_maxm: 0.7216\n",
      "Epoch 22/10000\n",
      "3146207/3146207 [==============================] - 168s 53us/sample - loss: -2.4545 - profit: 0.0032 - absmeanm: 0.0309 - meanm: 0.0309 - minm: 1.8814e-09 - maxm: 0.6560 - val_loss: -0.6000 - val_profit: 0.0011 - val_absmeanm: 0.0483 - val_meanm: 0.0483 - val_minm: 0.0000e+00 - val_maxm: 0.7702\n",
      "Epoch 23/10000\n",
      "3146207/3146207 [==============================] - 182s 58us/sample - loss: -2.5044 - profit: 0.0034 - absmeanm: 0.0313 - meanm: 0.0313 - minm: 1.7457e-09 - maxm: 0.6732 - val_loss: -0.6819 - val_profit: 8.7527e-04 - val_absmeanm: 0.0323 - val_meanm: 0.0323 - val_minm: 0.0000e+00 - val_maxm: 0.6580\n",
      "Epoch 24/10000\n",
      "3146207/3146207 [==============================] - 163s 52us/sample - loss: -2.5258 - profit: 0.0035 - absmeanm: 0.0321 - meanm: 0.0321 - minm: 6.3038e-10 - maxm: 0.6873 - val_loss: -0.2659 - val_profit: 5.7235e-04 - val_absmeanm: 0.0362 - val_meanm: 0.0362 - val_minm: 0.0000e+00 - val_maxm: 0.7656\n",
      "Epoch 25/10000\n",
      "3146207/3146207 [==============================] - 182s 58us/sample - loss: -2.5624 - profit: 0.0041 - absmeanm: 0.0359 - meanm: 0.0359 - minm: 8.1464e-10 - maxm: 0.7396 - val_loss: -0.4532 - val_profit: 0.0010 - val_absmeanm: 0.0566 - val_meanm: 0.0566 - val_minm: 0.0000e+00 - val_maxm: 0.7954\n",
      "Epoch 26/10000\n",
      "3146207/3146207 [==============================] - 163s 52us/sample - loss: -2.5614 - profit: 0.0040 - absmeanm: 0.0348 - meanm: 0.0348 - minm: 3.5883e-10 - maxm: 0.7188 - val_loss: -0.7265 - val_profit: 0.0014 - val_absmeanm: 0.0441 - val_meanm: 0.0441 - val_minm: 0.0000e+00 - val_maxm: 0.7676\n",
      "Epoch 27/10000\n",
      "3146207/3146207 [==============================] - 182s 58us/sample - loss: -2.5657 - profit: 0.0043 - absmeanm: 0.0378 - meanm: 0.0378 - minm: 3.6853e-10 - maxm: 0.7432 - val_loss: -0.5183 - val_profit: 0.0015 - val_absmeanm: 0.0679 - val_meanm: 0.0679 - val_minm: 0.0000e+00 - val_maxm: 0.8510\n",
      "Epoch 28/10000\n",
      "3146207/3146207 [==============================] - 166s 53us/sample - loss: -2.5873 - profit: 0.0041 - absmeanm: 0.0351 - meanm: 0.0351 - minm: 1.6487e-10 - maxm: 0.7155 - val_loss: -0.3683 - val_profit: 6.0508e-04 - val_absmeanm: 0.0325 - val_meanm: 0.0325 - val_minm: 0.0000e+00 - val_maxm: 0.7087\n",
      "Epoch 29/10000\n",
      "3146207/3146207 [==============================] - 169s 54us/sample - loss: -2.6118 - profit: 0.0043 - absmeanm: 0.0377 - meanm: 0.0377 - minm: 2.6185e-10 - maxm: 0.7485 - val_loss: -0.8242 - val_profit: 0.0022 - val_absmeanm: 0.0635 - val_meanm: 0.0635 - val_minm: 0.0000e+00 - val_maxm: 0.8469\n",
      "Epoch 30/10000\n",
      "3146207/3146207 [==============================] - 165s 52us/sample - loss: -2.6316 - profit: 0.0047 - absmeanm: 0.0406 - meanm: 0.0406 - minm: 1.9396e-10 - maxm: 0.7702 - val_loss: -0.7497 - val_profit: 0.0014 - val_absmeanm: 0.0499 - val_meanm: 0.0499 - val_minm: 0.0000e+00 - val_maxm: 0.7745\n",
      "Epoch 31/10000\n",
      "3146207/3146207 [==============================] - 179s 57us/sample - loss: -2.6535 - profit: 0.0046 - absmeanm: 0.0395 - meanm: 0.0395 - minm: 1.6487e-10 - maxm: 0.7478 - val_loss: -0.7225 - val_profit: 0.0014 - val_absmeanm: 0.0468 - val_meanm: 0.0468 - val_minm: 0.0000e+00 - val_maxm: 0.7808\n",
      "Epoch 32/10000\n",
      "3146207/3146207 [==============================] - 168s 53us/sample - loss: -2.6538 - profit: 0.0046 - absmeanm: 0.0385 - meanm: 0.0385 - minm: 1.3577e-10 - maxm: 0.7466 - val_loss: -0.5300 - val_profit: 0.0011 - val_absmeanm: 0.0562 - val_meanm: 0.0562 - val_minm: 0.0000e+00 - val_maxm: 0.7796\n",
      "Epoch 33/10000\n",
      "3146207/3146207 [==============================] - 166s 53us/sample - loss: -2.6818 - profit: 0.0047 - absmeanm: 0.0391 - meanm: 0.0391 - minm: 6.7887e-11 - maxm: 0.7513 - val_loss: -0.4994 - val_profit: 0.0012 - val_absmeanm: 0.0554 - val_meanm: 0.0554 - val_minm: 0.0000e+00 - val_maxm: 0.8251\n",
      "Epoch 34/10000\n",
      "3146207/3146207 [==============================] - 168s 53us/sample - loss: -2.6966 - profit: 0.0052 - absmeanm: 0.0429 - meanm: 0.0429 - minm: 8.7283e-11 - maxm: 0.7873 - val_loss: -0.6107 - val_profit: 0.0013 - val_absmeanm: 0.0550 - val_meanm: 0.0550 - val_minm: 0.0000e+00 - val_maxm: 0.7878\n",
      "Epoch 35/10000\n",
      "3146207/3146207 [==============================] - 164s 52us/sample - loss: -2.7003 - profit: 0.0048 - absmeanm: 0.0398 - meanm: 0.0398 - minm: 5.8189e-11 - maxm: 0.7655 - val_loss: -0.7473 - val_profit: 0.0018 - val_absmeanm: 0.0646 - val_meanm: 0.0646 - val_minm: 0.0000e+00 - val_maxm: 0.8138\n",
      "Epoch 36/10000\n",
      "3146207/3146207 [==============================] - 182s 58us/sample - loss: -2.7331 - profit: 0.0050 - absmeanm: 0.0419 - meanm: 0.0419 - minm: 2.9094e-11 - maxm: 0.7723 - val_loss: -0.7865 - val_profit: 0.0020 - val_absmeanm: 0.0698 - val_meanm: 0.0698 - val_minm: 0.0000e+00 - val_maxm: 0.8481\n",
      "Epoch 37/10000\n",
      "3146207/3146207 [==============================] - 165s 52us/sample - loss: -2.7163 - profit: 0.0052 - absmeanm: 0.0428 - meanm: 0.0428 - minm: 9.6981e-11 - maxm: 0.7944 - val_loss: -0.5296 - val_profit: 9.9130e-04 - val_absmeanm: 0.0472 - val_meanm: 0.0472 - val_minm: 0.0000e+00 - val_maxm: 0.8374\n",
      "Epoch 38/10000\n",
      "3146207/3146207 [==============================] - 183s 58us/sample - loss: -2.7202 - profit: 0.0053 - absmeanm: 0.0437 - meanm: 0.0437 - minm: 1.9396e-11 - maxm: 0.7953 - val_loss: -0.3878 - val_profit: 6.0639e-04 - val_absmeanm: 0.0488 - val_meanm: 0.0488 - val_minm: 0.0000e+00 - val_maxm: 0.7992\n",
      "Epoch 39/10000\n",
      "3146207/3146207 [==============================] - 165s 53us/sample - loss: -2.7100 - profit: 0.0053 - absmeanm: 0.0441 - meanm: 0.0441 - minm: 3.8792e-11 - maxm: 0.7947 - val_loss: -0.5753 - val_profit: 0.0014 - val_absmeanm: 0.0651 - val_meanm: 0.0651 - val_minm: 0.0000e+00 - val_maxm: 0.8306\n",
      "Epoch 40/10000\n",
      "3146207/3146207 [==============================] - 167s 53us/sample - loss: -2.7409 - profit: 0.0056 - absmeanm: 0.0458 - meanm: 0.0458 - minm: 9.6981e-12 - maxm: 0.8030 - val_loss: -1.0521 - val_profit: 0.0031 - val_absmeanm: 0.0722 - val_meanm: 0.0722 - val_minm: 0.0000e+00 - val_maxm: 0.8579\n",
      "Epoch 41/10000\n",
      "3146207/3146207 [==============================] - 159s 50us/sample - loss: -2.7827 - profit: 0.0059 - absmeanm: 0.0471 - meanm: 0.0471 - minm: 2.9094e-11 - maxm: 0.8169 - val_loss: -0.3172 - val_profit: 8.1162e-04 - val_absmeanm: 0.0619 - val_meanm: 0.0619 - val_minm: 0.0000e+00 - val_maxm: 0.8384\n",
      "Epoch 42/10000\n",
      "3146207/3146207 [==============================] - 168s 53us/sample - loss: -2.7940 - profit: 0.0059 - absmeanm: 0.0462 - meanm: 0.0462 - minm: 5.8189e-11 - maxm: 0.8062 - val_loss: -0.6542 - val_profit: 0.0016 - val_absmeanm: 0.0659 - val_meanm: 0.0659 - val_minm: 0.0000e+00 - val_maxm: 0.8776\n",
      "Epoch 43/10000\n",
      "3146207/3146207 [==============================] - 164s 52us/sample - loss: -2.8042 - profit: 0.0061 - absmeanm: 0.0484 - meanm: 0.0484 - minm: 5.8189e-11 - maxm: 0.8291 - val_loss: -0.5598 - val_profit: 0.0014 - val_absmeanm: 0.0551 - val_meanm: 0.0551 - val_minm: 0.0000e+00 - val_maxm: 0.8639\n",
      "Epoch 44/10000\n",
      "3146207/3146207 [==============================] - 182s 58us/sample - loss: -2.8194 - profit: 0.0065 - absmeanm: 0.0504 - meanm: 0.0504 - minm: 8.7283e-11 - maxm: 0.8423 - val_loss: -0.6317 - val_profit: 0.0019 - val_absmeanm: 0.0781 - val_meanm: 0.0781 - val_minm: 0.0000e+00 - val_maxm: 0.8774\n",
      "Epoch 45/10000\n",
      "3146207/3146207 [==============================] - 168s 53us/sample - loss: -2.8243 - profit: 0.0065 - absmeanm: 0.0500 - meanm: 0.0500 - minm: 3.8792e-11 - maxm: 0.8386 - val_loss: -0.7599 - val_profit: 0.0020 - val_absmeanm: 0.0629 - val_meanm: 0.0629 - val_minm: 0.0000e+00 - val_maxm: 0.8657\n",
      "Epoch 46/10000\n",
      "3146207/3146207 [==============================] - 169s 54us/sample - loss: -2.8184 - profit: 0.0065 - absmeanm: 0.0509 - meanm: 0.0509 - minm: 4.8491e-11 - maxm: 0.8376 - val_loss: -0.7500 - val_profit: 0.0019 - val_absmeanm: 0.0671 - val_meanm: 0.0671 - val_minm: 0.0000e+00 - val_maxm: 0.8588\n",
      "Epoch 47/10000\n",
      "3146207/3146207 [==============================] - 165s 52us/sample - loss: -2.8212 - profit: 0.0066 - absmeanm: 0.0516 - meanm: 0.0516 - minm: 9.6981e-12 - maxm: 0.8433 - val_loss: -0.6107 - val_profit: 0.0018 - val_absmeanm: 0.0814 - val_meanm: 0.0814 - val_minm: 0.0000e+00 - val_maxm: 0.8833\n",
      "Epoch 48/10000\n",
      "3146207/3146207 [==============================] - 184s 59us/sample - loss: -2.8578 - profit: 0.0070 - absmeanm: 0.0524 - meanm: 0.0524 - minm: 0.0000e+00 - maxm: 0.8522 - val_loss: -0.8192 - val_profit: 0.0024 - val_absmeanm: 0.0906 - val_meanm: 0.0906 - val_minm: 0.0000e+00 - val_maxm: 0.9111\n",
      "Epoch 49/10000\n",
      "3146207/3146207 [==============================] - 168s 53us/sample - loss: -2.8589 - profit: 0.0072 - absmeanm: 0.0545 - meanm: 0.0545 - minm: 0.0000e+00 - maxm: 0.8585 - val_loss: -0.4292 - val_profit: 0.0014 - val_absmeanm: 0.0907 - val_meanm: 0.0907 - val_minm: 0.0000e+00 - val_maxm: 0.8866\n",
      "Epoch 50/10000\n",
      "3146207/3146207 [==============================] - 171s 54us/sample - loss: -2.8630 - profit: 0.0069 - absmeanm: 0.0524 - meanm: 0.0524 - minm: 3.8792e-11 - maxm: 0.8544 - val_loss: -0.5329 - val_profit: 0.0018 - val_absmeanm: 0.0766 - val_meanm: 0.0766 - val_minm: 0.0000e+00 - val_maxm: 0.9022\n",
      "Epoch 51/10000\n",
      "3146207/3146207 [==============================] - 166s 53us/sample - loss: -2.8688 - profit: 0.0073 - absmeanm: 0.0543 - meanm: 0.0543 - minm: 0.0000e+00 - maxm: 0.8643 - val_loss: -0.4475 - val_profit: 0.0014 - val_absmeanm: 0.0973 - val_meanm: 0.0973 - val_minm: 0.0000e+00 - val_maxm: 0.9134\n",
      "Epoch 52/10000\n",
      "3146207/3146207 [==============================] - 171s 54us/sample - loss: -2.8762 - profit: 0.0072 - absmeanm: 0.0539 - meanm: 0.0539 - minm: 4.8491e-11 - maxm: 0.8606 - val_loss: -0.4286 - val_profit: 0.0010 - val_absmeanm: 0.0771 - val_meanm: 0.0771 - val_minm: 0.0000e+00 - val_maxm: 0.9153\n",
      "Epoch 53/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3146207/3146207 [==============================] - 168s 53us/sample - loss: -2.8720 - profit: 0.0070 - absmeanm: 0.0532 - meanm: 0.0532 - minm: 9.6981e-12 - maxm: 0.8580 - val_loss: -0.6913 - val_profit: 0.0018 - val_absmeanm: 0.0617 - val_meanm: 0.0617 - val_minm: 0.0000e+00 - val_maxm: 0.8502\n",
      "Epoch 54/10000\n",
      "3146207/3146207 [==============================] - 168s 53us/sample - loss: -2.8841 - profit: 0.0073 - absmeanm: 0.0544 - meanm: 0.0544 - minm: 3.8792e-11 - maxm: 0.8632 - val_loss: -0.4043 - val_profit: 0.0014 - val_absmeanm: 0.0739 - val_meanm: 0.0739 - val_minm: 0.0000e+00 - val_maxm: 0.9010\n",
      "Epoch 55/10000\n",
      "3146207/3146207 [==============================] - 167s 53us/sample - loss: -2.8950 - profit: 0.0075 - absmeanm: 0.0563 - meanm: 0.0563 - minm: 9.6981e-12 - maxm: 0.8706 - val_loss: -0.7712 - val_profit: 0.0023 - val_absmeanm: 0.0845 - val_meanm: 0.0845 - val_minm: 0.0000e+00 - val_maxm: 0.9311\n",
      "Epoch 56/10000\n",
      "3146207/3146207 [==============================] - 169s 54us/sample - loss: -2.9122 - profit: 0.0076 - absmeanm: 0.0561 - meanm: 0.0561 - minm: 9.6981e-12 - maxm: 0.8741 - val_loss: -0.4778 - val_profit: 0.0016 - val_absmeanm: 0.0717 - val_meanm: 0.0717 - val_minm: 0.0000e+00 - val_maxm: 0.9179\n",
      "Epoch 57/10000\n",
      "3146207/3146207 [==============================] - 164s 52us/sample - loss: -2.9083 - profit: 0.0078 - absmeanm: 0.0582 - meanm: 0.0582 - minm: 9.6981e-12 - maxm: 0.8838 - val_loss: -0.7179 - val_profit: 0.0020 - val_absmeanm: 0.0756 - val_meanm: 0.0756 - val_minm: 0.0000e+00 - val_maxm: 0.9071\n",
      "Epoch 58/10000\n",
      "3146207/3146207 [==============================] - 183s 58us/sample - loss: -2.8804 - profit: 0.0073 - absmeanm: 0.0553 - meanm: 0.0553 - minm: 0.0000e+00 - maxm: 0.8639 - val_loss: -0.6523 - val_profit: 0.0024 - val_absmeanm: 0.0874 - val_meanm: 0.0874 - val_minm: 0.0000e+00 - val_maxm: 0.9067\n",
      "Epoch 59/10000\n",
      "3146207/3146207 [==============================] - 166s 53us/sample - loss: -2.9153 - profit: 0.0075 - absmeanm: 0.0557 - meanm: 0.0557 - minm: 4.8491e-11 - maxm: 0.8644 - val_loss: -0.5125 - val_profit: 0.0015 - val_absmeanm: 0.0817 - val_meanm: 0.0817 - val_minm: 0.0000e+00 - val_maxm: 0.9029\n",
      "Epoch 60/10000\n",
      "3146207/3146207 [==============================] - 168s 53us/sample - loss: -2.9143 - profit: 0.0078 - absmeanm: 0.0572 - meanm: 0.0572 - minm: 1.9396e-11 - maxm: 0.8728 - val_loss: -0.7215 - val_profit: 0.0020 - val_absmeanm: 0.0808 - val_meanm: 0.0808 - val_minm: 0.0000e+00 - val_maxm: 0.9360\n",
      "Epoch 61/10000\n",
      "3146207/3146207 [==============================] - 166s 53us/sample - loss: -2.9000 - profit: 0.0077 - absmeanm: 0.0571 - meanm: 0.0571 - minm: 9.6981e-12 - maxm: 0.8689 - val_loss: -0.6402 - val_profit: 0.0021 - val_absmeanm: 0.0808 - val_meanm: 0.0808 - val_minm: 0.0000e+00 - val_maxm: 0.9138\n",
      "Epoch 62/10000\n",
      "3146207/3146207 [==============================] - 169s 54us/sample - loss: -2.9107 - profit: 0.0076 - absmeanm: 0.0571 - meanm: 0.0571 - minm: 0.0000e+00 - maxm: 0.8665 - val_loss: -0.5155 - val_profit: 0.0012 - val_absmeanm: 0.0698 - val_meanm: 0.0698 - val_minm: 0.0000e+00 - val_maxm: 0.8746\n",
      "Epoch 63/10000\n",
      "3146207/3146207 [==============================] - 166s 53us/sample - loss: -2.9179 - profit: 0.0074 - absmeanm: 0.0553 - meanm: 0.0553 - minm: 1.9396e-11 - maxm: 0.8612 - val_loss: -0.6883 - val_profit: 0.0020 - val_absmeanm: 0.0832 - val_meanm: 0.0832 - val_minm: 0.0000e+00 - val_maxm: 0.8945\n",
      "Epoch 64/10000\n",
      "3146207/3146207 [==============================] - 183s 58us/sample - loss: -2.9146 - profit: 0.0075 - absmeanm: 0.0557 - meanm: 0.0557 - minm: 2.9094e-11 - maxm: 0.8634 - val_loss: -0.3951 - val_profit: 0.0010 - val_absmeanm: 0.0624 - val_meanm: 0.0624 - val_minm: 0.0000e+00 - val_maxm: 0.8851\n",
      "Epoch 65/10000\n",
      "3146207/3146207 [==============================] - 166s 53us/sample - loss: -2.9361 - profit: 0.0078 - absmeanm: 0.0570 - meanm: 0.0570 - minm: 0.0000e+00 - maxm: 0.8652 - val_loss: -0.5855 - val_profit: 0.0023 - val_absmeanm: 0.1081 - val_meanm: 0.1081 - val_minm: 0.0000e+00 - val_maxm: 0.9294\n",
      "Epoch 66/10000\n",
      "3146207/3146207 [==============================] - 167s 53us/sample - loss: -2.9352 - profit: 0.0080 - absmeanm: 0.0576 - meanm: 0.0576 - minm: 3.8792e-11 - maxm: 0.8713 - val_loss: -0.9622 - val_profit: 0.0029 - val_absmeanm: 0.0797 - val_meanm: 0.0797 - val_minm: 0.0000e+00 - val_maxm: 0.9130\n",
      "Epoch 67/10000\n",
      "3146207/3146207 [==============================] - 166s 53us/sample - loss: -2.9158 - profit: 0.0077 - absmeanm: 0.0577 - meanm: 0.0577 - minm: 2.9094e-11 - maxm: 0.8731 - val_loss: -0.6550 - val_profit: 0.0021 - val_absmeanm: 0.0858 - val_meanm: 0.0858 - val_minm: 0.0000e+00 - val_maxm: 0.9075\n",
      "Epoch 68/10000\n",
      "3146207/3146207 [==============================] - 185s 59us/sample - loss: -2.9436 - profit: 0.0079 - absmeanm: 0.0578 - meanm: 0.0578 - minm: 9.6981e-12 - maxm: 0.8696 - val_loss: -0.7314 - val_profit: 0.0024 - val_absmeanm: 0.0881 - val_meanm: 0.0881 - val_minm: 0.0000e+00 - val_maxm: 0.9277\n",
      "Epoch 69/10000\n",
      "3146207/3146207 [==============================] - 165s 53us/sample - loss: -2.9481 - profit: 0.0078 - absmeanm: 0.0576 - meanm: 0.0576 - minm: 9.6981e-12 - maxm: 0.8685 - val_loss: -0.5481 - val_profit: 0.0019 - val_absmeanm: 0.0907 - val_meanm: 0.0907 - val_minm: 0.0000e+00 - val_maxm: 0.9102\n",
      "Epoch 70/10000\n",
      "3146207/3146207 [==============================] - 180s 57us/sample - loss: -2.9706 - profit: 0.0084 - absmeanm: 0.0600 - meanm: 0.0600 - minm: 1.9396e-11 - maxm: 0.8899 - val_loss: -0.2262 - val_profit: 9.3400e-04 - val_absmeanm: 0.0853 - val_meanm: 0.0853 - val_minm: 0.0000e+00 - val_maxm: 0.9259\n",
      "Epoch 71/10000\n",
      "3146207/3146207 [==============================] - 167s 53us/sample - loss: -2.9578 - profit: 0.0083 - absmeanm: 0.0578 - meanm: 0.0578 - minm: 0.0000e+00 - maxm: 0.8727 - val_loss: -0.8917 - val_profit: 0.0026 - val_absmeanm: 0.0781 - val_meanm: 0.0781 - val_minm: 0.0000e+00 - val_maxm: 0.9345\n",
      "Epoch 72/10000\n",
      "3146207/3146207 [==============================] - 167s 53us/sample - loss: -2.9508 - profit: 0.0081 - absmeanm: 0.0588 - meanm: 0.0588 - minm: 1.9396e-11 - maxm: 0.8786 - val_loss: -0.3179 - val_profit: 0.0012 - val_absmeanm: 0.0809 - val_meanm: 0.0809 - val_minm: 0.0000e+00 - val_maxm: 0.9128\n",
      "Epoch 73/10000\n",
      "3146207/3146207 [==============================] - 166s 53us/sample - loss: -2.9667 - profit: 0.0084 - absmeanm: 0.0598 - meanm: 0.0598 - minm: 9.6981e-12 - maxm: 0.8829 - val_loss: -0.3035 - val_profit: 8.7919e-04 - val_absmeanm: 0.0649 - val_meanm: 0.0649 - val_minm: 0.0000e+00 - val_maxm: 0.8798\n",
      "Epoch 74/10000\n",
      "3146207/3146207 [==============================] - 163s 52us/sample - loss: -2.9749 - profit: 0.0084 - absmeanm: 0.0600 - meanm: 0.0600 - minm: 2.9094e-11 - maxm: 0.8842 - val_loss: -0.5357 - val_profit: 0.0018 - val_absmeanm: 0.0948 - val_meanm: 0.0948 - val_minm: 0.0000e+00 - val_maxm: 0.9145\n",
      "Epoch 75/10000\n",
      "3146207/3146207 [==============================] - 168s 53us/sample - loss: -2.9500 - profit: 0.0081 - absmeanm: 0.0571 - meanm: 0.0571 - minm: 3.8792e-11 - maxm: 0.8745 - val_loss: -0.5851 - val_profit: 0.0018 - val_absmeanm: 0.0770 - val_meanm: 0.0770 - val_minm: 0.0000e+00 - val_maxm: 0.9139\n",
      "Epoch 76/10000\n",
      "3146207/3146207 [==============================] - 163s 52us/sample - loss: -2.9606 - profit: 0.0080 - absmeanm: 0.0583 - meanm: 0.0583 - minm: 9.6981e-12 - maxm: 0.8752 - val_loss: -0.1383 - val_profit: 7.9939e-04 - val_absmeanm: 0.0789 - val_meanm: 0.0789 - val_minm: 0.0000e+00 - val_maxm: 0.9360\n",
      "Epoch 77/10000\n",
      "3146207/3146207 [==============================] - 183s 58us/sample - loss: -2.9712 - profit: 0.0085 - absmeanm: 0.0609 - meanm: 0.0609 - minm: 0.0000e+00 - maxm: 0.8958 - val_loss: -0.6816 - val_profit: 0.0018 - val_absmeanm: 0.0784 - val_meanm: 0.0784 - val_minm: 0.0000e+00 - val_maxm: 0.9310\n",
      "Epoch 78/10000\n",
      "3146207/3146207 [==============================] - 167s 53us/sample - loss: -2.9732 - profit: 0.0086 - absmeanm: 0.0617 - meanm: 0.0617 - minm: 3.8792e-11 - maxm: 0.8981 - val_loss: -0.6088 - val_profit: 0.0018 - val_absmeanm: 0.0789 - val_meanm: 0.0789 - val_minm: 0.0000e+00 - val_maxm: 0.9261\n",
      "Epoch 79/10000\n",
      "3146207/3146207 [==============================] - 168s 53us/sample - loss: -2.9739 - profit: 0.0085 - absmeanm: 0.0612 - meanm: 0.0612 - minm: 5.8189e-11 - maxm: 0.8897 - val_loss: -0.6339 - val_profit: 0.0020 - val_absmeanm: 0.0825 - val_meanm: 0.0825 - val_minm: 0.0000e+00 - val_maxm: 0.9097\n",
      "Epoch 80/10000\n",
      "3146207/3146207 [==============================] - 164s 52us/sample - loss: -2.9864 - profit: 0.0088 - absmeanm: 0.0633 - meanm: 0.0633 - minm: 5.8189e-11 - maxm: 0.8974 - val_loss: -0.5333 - val_profit: 0.0017 - val_absmeanm: 0.0782 - val_meanm: 0.0782 - val_minm: 0.0000e+00 - val_maxm: 0.9255\n",
      "Epoch 81/10000\n",
      "3146207/3146207 [==============================] - 182s 58us/sample - loss: -2.9621 - profit: 0.0086 - absmeanm: 0.0620 - meanm: 0.0620 - minm: 2.9094e-11 - maxm: 0.8950 - val_loss: -0.7215 - val_profit: 0.0018 - val_absmeanm: 0.0697 - val_meanm: 0.0697 - val_minm: 0.0000e+00 - val_maxm: 0.8981\n",
      "Epoch 82/10000\n",
      "3146207/3146207 [==============================] - 165s 52us/sample - loss: -2.9440 - profit: 0.0082 - absmeanm: 0.0610 - meanm: 0.0610 - minm: 5.8189e-11 - maxm: 0.8948 - val_loss: -0.6044 - val_profit: 0.0018 - val_absmeanm: 0.0768 - val_meanm: 0.0768 - val_minm: 0.0000e+00 - val_maxm: 0.9003\n",
      "Epoch 83/10000\n",
      "3146207/3146207 [==============================] - 169s 54us/sample - loss: -2.9578 - profit: 0.0080 - absmeanm: 0.0592 - meanm: 0.0592 - minm: 6.7887e-11 - maxm: 0.8828 - val_loss: -0.5721 - val_profit: 0.0016 - val_absmeanm: 0.0754 - val_meanm: 0.0754 - val_minm: 0.0000e+00 - val_maxm: 0.9004\n",
      "Epoch 84/10000\n",
      "3146207/3146207 [==============================] - 170s 54us/sample - loss: -2.9490 - profit: 0.0082 - absmeanm: 0.0611 - meanm: 0.0611 - minm: 9.6981e-12 - maxm: 0.8898 - val_loss: -0.7469 - val_profit: 0.0023 - val_absmeanm: 0.0792 - val_meanm: 0.0792 - val_minm: 0.0000e+00 - val_maxm: 0.9264\n",
      "Epoch 85/10000\n",
      "3146207/3146207 [==============================] - 169s 54us/sample - loss: -2.9519 - profit: 0.0081 - absmeanm: 0.0602 - meanm: 0.0602 - minm: 4.8491e-11 - maxm: 0.8878 - val_loss: -0.7327 - val_profit: 0.0017 - val_absmeanm: 0.0680 - val_meanm: 0.0680 - val_minm: 0.0000e+00 - val_maxm: 0.8916\n",
      "Epoch 86/10000\n",
      "3146207/3146207 [==============================] - 166s 53us/sample - loss: -2.9808 - profit: 0.0086 - absmeanm: 0.0617 - meanm: 0.0617 - minm: 9.6981e-11 - maxm: 0.8937 - val_loss: -0.6279 - val_profit: 0.0022 - val_absmeanm: 0.0927 - val_meanm: 0.0927 - val_minm: 0.0000e+00 - val_maxm: 0.9446\n",
      "Epoch 87/10000\n",
      "3146207/3146207 [==============================] - 167s 53us/sample - loss: -2.9558 - profit: 0.0085 - absmeanm: 0.0626 - meanm: 0.0626 - minm: 2.0366e-10 - maxm: 0.9019 - val_loss: -0.6077 - val_profit: 0.0019 - val_absmeanm: 0.0694 - val_meanm: 0.0694 - val_minm: 0.0000e+00 - val_maxm: 0.9081\n",
      "Epoch 88/10000\n",
      "3146207/3146207 [==============================] - 164s 52us/sample - loss: -2.9906 - profit: 0.0087 - absmeanm: 0.0622 - meanm: 0.0622 - minm: 1.0668e-10 - maxm: 0.9040 - val_loss: -1.0352 - val_profit: 0.0029 - val_absmeanm: 0.0713 - val_meanm: 0.0713 - val_minm: 0.0000e+00 - val_maxm: 0.9108\n",
      "Epoch 89/10000\n",
      "3146207/3146207 [==============================] - 165s 52us/sample - loss: -2.9903 - profit: 0.0086 - absmeanm: 0.0623 - meanm: 0.0623 - minm: 4.8491e-11 - maxm: 0.9015 - val_loss: -0.8510 - val_profit: 0.0026 - val_absmeanm: 0.0696 - val_meanm: 0.0696 - val_minm: 0.0000e+00 - val_maxm: 0.9104\n",
      "Epoch 90/10000\n",
      "3146207/3146207 [==============================] - 180s 57us/sample - loss: -3.0044 - profit: 0.0089 - absmeanm: 0.0626 - meanm: 0.0626 - minm: 6.7887e-11 - maxm: 0.9014 - val_loss: -0.7735 - val_profit: 0.0027 - val_absmeanm: 0.0838 - val_meanm: 0.0838 - val_minm: 0.0000e+00 - val_maxm: 0.9314\n",
      "Epoch 91/10000\n",
      "3146207/3146207 [==============================] - 167s 53us/sample - loss: -2.9900 - profit: 0.0089 - absmeanm: 0.0637 - meanm: 0.0637 - minm: 5.8189e-11 - maxm: 0.9093 - val_loss: -0.6198 - val_profit: 0.0023 - val_absmeanm: 0.0712 - val_meanm: 0.0712 - val_minm: 0.0000e+00 - val_maxm: 0.9338\n",
      "Epoch 92/10000\n",
      "3146207/3146207 [==============================] - 170s 54us/sample - loss: -3.0002 - profit: 0.0088 - absmeanm: 0.0627 - meanm: 0.0627 - minm: 1.6487e-10 - maxm: 0.8975 - val_loss: -0.5060 - val_profit: 0.0016 - val_absmeanm: 0.0810 - val_meanm: 0.0810 - val_minm: 0.0000e+00 - val_maxm: 0.9326\n",
      "Epoch 93/10000\n",
      "3146207/3146207 [==============================] - 166s 53us/sample - loss: -2.9872 - profit: 0.0085 - absmeanm: 0.0620 - meanm: 0.0620 - minm: 1.4547e-10 - maxm: 0.8888 - val_loss: -0.1824 - val_profit: 0.0011 - val_absmeanm: 0.0880 - val_meanm: 0.0880 - val_minm: 0.0000e+00 - val_maxm: 0.9337\n",
      "Epoch 94/10000\n",
      "3146207/3146207 [==============================] - 168s 53us/sample - loss: -3.0032 - profit: 0.0087 - absmeanm: 0.0630 - meanm: 0.0630 - minm: 2.3275e-10 - maxm: 0.8995 - val_loss: -0.6886 - val_profit: 0.0023 - val_absmeanm: 0.0859 - val_meanm: 0.0859 - val_minm: 0.0000e+00 - val_maxm: 0.9361\n",
      "Epoch 95/10000\n",
      "3146207/3146207 [==============================] - 165s 52us/sample - loss: -3.0100 - profit: 0.0090 - absmeanm: 0.0642 - meanm: 0.0642 - minm: 1.6487e-10 - maxm: 0.9063 - val_loss: -0.5891 - val_profit: 0.0020 - val_absmeanm: 0.0809 - val_meanm: 0.0809 - val_minm: 0.0000e+00 - val_maxm: 0.9311\n",
      "Epoch 96/10000\n",
      "3146207/3146207 [==============================] - 169s 54us/sample - loss: -3.0194 - profit: 0.0089 - absmeanm: 0.0640 - meanm: 0.0640 - minm: 1.1638e-10 - maxm: 0.9009 - val_loss: -0.5604 - val_profit: 0.0017 - val_absmeanm: 0.0783 - val_meanm: 0.0783 - val_minm: 0.0000e+00 - val_maxm: 0.9231\n",
      "Epoch 97/10000\n",
      "3146207/3146207 [==============================] - 166s 53us/sample - loss: -3.0073 - profit: 0.0089 - absmeanm: 0.0641 - meanm: 0.0641 - minm: 2.0366e-10 - maxm: 0.8952 - val_loss: -0.5363 - val_profit: 0.0015 - val_absmeanm: 0.0592 - val_meanm: 0.0592 - val_minm: 0.0000e+00 - val_maxm: 0.8876\n",
      "Epoch 98/10000\n",
      "3146207/3146207 [==============================] - 168s 53us/sample - loss: -3.0138 - profit: 0.0092 - absmeanm: 0.0652 - meanm: 0.0652 - minm: 1.8426e-10 - maxm: 0.9039 - val_loss: -0.6917 - val_profit: 0.0028 - val_absmeanm: 0.1062 - val_meanm: 0.1062 - val_minm: 0.0000e+00 - val_maxm: 0.9321\n",
      "Epoch 99/10000\n",
      "3146207/3146207 [==============================] - 164s 52us/sample - loss: -2.9853 - profit: 0.0086 - absmeanm: 0.0626 - meanm: 0.0626 - minm: 7.7585e-11 - maxm: 0.8972 - val_loss: -0.4137 - val_profit: 0.0016 - val_absmeanm: 0.1058 - val_meanm: 0.1058 - val_minm: 0.0000e+00 - val_maxm: 0.9431\n",
      "Epoch 100/10000\n",
      "2070528/3146207 [==================>...........] - ETA: 56s - loss: -2.9847 - profit: 0.0087 - absmeanm: 0.0623 - meanm: 0.0623 - minm: 1.1791e-10 - maxm: 0.8972"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-5a0ff80547d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#     use_multiprocessing=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#     workers=0,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;31m#     max_queue_size=100,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#     validation_freq=1000,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# callback = MyCustomCallback(inputs_train[:-time_limit], y_true, validation_data=(inputs_test[:-time_limit], y_true_pred))\n",
    "batch_size=2**10\n",
    "\n",
    "buffer = 0\n",
    "buffer_test = 0\n",
    "leftover = inputs_train[:-buffer].shape[0] % batch_size\n",
    "leftover_test = inputs_test[:-buffer_test].shape[0] % batch_size\n",
    "\n",
    "history = model.fit(\n",
    "    inputs_train[:-1-leftover-buffer], \n",
    "    y_true[:-1-leftover-buffer], \n",
    "    validation_data=(inputs_test[:-1-leftover_test-buffer_test], y_true_pred[:-1-leftover_test-buffer_test]),\n",
    "#     validation_steps=32*5//batch_size,\n",
    "#     validation_data=(tf.convert_to_tensor(inputs_test[:32*5]), tf.convert_to_tensor([[1, i] for i in range(32*5)])),\n",
    "    epochs=10000, \n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    "#     callbacks=[callback],\n",
    "#     use_multiprocessing=True, \n",
    "#     workers=0,\n",
    "    verbose=1, \n",
    "#     max_queue_size=100,\n",
    "#     validation_freq=1000,\n",
    "#     initial_epoch=model.history.epoch[-1],\n",
    "#     initial_epoch=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "outdoor-salmon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213457/213457 [==============================] - 54s 253us/sample - loss: -1.2151 - profit: -0.4275 - absmeanm: 0.0214 - meanm: 0.0214 - minm: 1.7001e-05 - maxm: 0.1504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-1.215122196168675,\n",
       " -0.42751688,\n",
       " 0.021431627,\n",
       " 0.021431627,\n",
       " 1.7001401e-05,\n",
       " 0.15043464]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(inputs_test[:-1-leftover_test-buffer_test], y_true_pred[:-1-leftover_test-buffer_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c86fa0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('temp1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-phoenix",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('temp2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90d4896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "weights_list = model.get_weights()\n",
    "json.dump([w.tolist() for w in weights_list], open('profit_model_fast_QC_hourly_weights.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "electric-water",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99835014"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X[-4000:]).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "biblical-selection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "natural-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict((inputs_test*2-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fuzzy-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = y_pred[:,:1] \n",
    "direction = np.sign(margin)\n",
    "\n",
    "close1 = y_true_pred[:,:1]\n",
    "close2 = y_true_pred[:,1:2]\n",
    "diff = close2 - close1\n",
    "spread = y_true_pred[:,2:3]\n",
    "\n",
    "profit = 100 * (margin * margin_size * (diff - (spread*direction))/close1)\n",
    "x = np.mean(profit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "corporate-bidding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00345569,  0.00336057,  0.00595526, ...,  0.00164481,\n",
       "       -0.00483072, -0.00110413])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profit.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "second-flooring",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f78b239b908>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(list(range(len(profit))), profit.flatten(), alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "instrumental-detroit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.028728923, -0.027993169, -0.92990303, 0.056388892)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(y_pred).mean(), y_pred.mean(), y_pred.min(), y_pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "acting-perry",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = model.predict(X[:-1-leftover-buffer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "eligible-hindu",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09669923, -0.09057495, 0.31497744, 0.09925839)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(y_pred2).mean(), y_pred2.mean(), y_pred2.min(), y_pred2.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "descending-ideal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: Mean of empty slice.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-234-74b279863352>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mleftover\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mleftover\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mleftover\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mleftover\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     41\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n\u001b[1;32m     42\u001b[0m           initial=_NoValue, where=True):\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "y_pred2[buffer:-leftover].mean(), y_pred2[buffer:-leftover].min(), y_pred2[buffer:-leftover].max(), abs(y_pred2[buffer:-leftover]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "defensive-enlargement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.10084756, -0.08812471, 0.30822742, 0.10344847)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2[:buffer].mean(), y_pred2[:buffer].min(), y_pred2[:buffer].max(), abs(y_pred2[:buffer]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-commission",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = list(range(0, batch_size, 60))\n",
    "margin = y_pred[:,:1][idxs]\n",
    "direction = np.sign(margin)\n",
    "\n",
    "close1 = y_true_pred[:,:1][idxs]\n",
    "close2 = y_true_pred[:,1:2][idxs]\n",
    "diff = close2 - close1\n",
    "spread = y_true_pred[:,2:3][idxs]\n",
    "\n",
    "x = np.mean(100 * (margin * margin_size * (diff - (spread*direction))/close1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin.shape, close1.shape, close2.shape, diff.shape, spread.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b8d23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac07403",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.predict(inputs_train[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-beverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def normalize(data, window, step):\n",
    "    frame = '_1min'\n",
    "    values = [c for c in data.columns if frame in c]\n",
    "    ohlc = data.iloc[step - window + 1:step + 1][values].copy()\n",
    "\n",
    "    min_low = ohlc[values].min().min()\n",
    "    for c in ohlc.columns:\n",
    "        ohlc[c] -= min_low\n",
    "\n",
    "    max_high = ohlc[values].max().max()\n",
    "    for c in ohlc.columns:\n",
    "        ohlc[c] /= max_high\n",
    "\n",
    "    return ohlc.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(inputs_train[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('preds.json', y_preds['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb215f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "(((y_preds['test'][:,1] + 1) / 2)).mean(), (((y_preds['test'][:,2] + 1) / 2)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(train['close_1min'].values[:-60] - train['close_1min'].values[60:]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cb421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = {'train': model.predict(inputs_train[:-buffer_train]), 'test': model.predict(inputs_test[:-buffer_test])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2d5582",
   "metadata": {},
   "outputs": [],
   "source": [
    "profits = {'train': get_profit(df[0], y_preds['train'], 0), 'test': get_profit(df[1], y_preds['test'], 0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_limit = 120\n",
    "def get_profit(data, y_preds, times_spread=0):\n",
    "    preds = y_preds[:,0].flatten()[:-time_limit]\n",
    "    direction = np.sign(preds)\n",
    "    b = data.shape[0] - preds.shape[0]\n",
    "    close1 = data['close_1min'].values[:-b]\n",
    "    close2 = data['close_1min'].values[time_limit:-b+time_limit]\n",
    "    diff = close2 - close1\n",
    "    spread = data['spread'].values[:-b]\n",
    "    profit = 100 * (margin_size*direction * (diff - (spread*direction))) /  close1\n",
    "#     profit = [p for p, pred, s, c in zip(profit, preds, spread, close1) if abs(pred) > 100*margin_size*times_spread*s/c]\n",
    "    return profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profit(data, y_preds, margin_lower_limit=0):\n",
    "    idx = 0\n",
    "    profits = 0\n",
    "    margin = 0\n",
    "    account_value = [1]\n",
    "    old_date = data['date'].iloc[idx]\n",
    "    increase = 1\n",
    "    start_profit = profits\n",
    "    while idx < len(y_preds) - 2:\n",
    "        pred = y_preds[idx][0]\n",
    "        date = data['date'].iloc[idx]\n",
    "        direction = np.sign(margin)\n",
    "        close =  data.iloc[idx]['close_1min']\n",
    "        spread = data.iloc[idx]['spread']\n",
    "        if date != old_date:\n",
    "            profits += (margin * (close - (spread*direction)))\n",
    "            margin = 0\n",
    "            \n",
    "        if abs(pred + margin) < margin_size*account_value[-1]:\n",
    "            profits += (pred * (close - (spread*direction)))\n",
    "            margin += pred\n",
    "            \n",
    "        account_value.append(1 + (margin * (close - (spread*direction))) - profits)\n",
    "        idx += 1\n",
    "        \n",
    "    idx = -1\n",
    "    direction = np.sign(margin)\n",
    "    close =  data.iloc[idx]['close_1min']\n",
    "    spread = data.iloc[idx]['spread']\n",
    "    profits += (margin * (close - (spread*direction)))\n",
    "    margin = 0\n",
    "    return profits, margin, account_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-andrews",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, m, v = get_profit(df[1], y_preds['test'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-cologne",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profits_fixed = {'train': get_profit(df[0], y_preds['train'], 0), 'test': get_profit(df[1], y_preds['test'], 0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536ff360",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = {'train': train.iloc[:len(profits_fixed['train'])].copy(), 'test': test.iloc[:len(profits_fixed['test'])].copy()}\n",
    "temp['train']['profit'] = profits_fixed['train']\n",
    "temp['test']['profit'] = profits_fixed['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['train']['profit'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['test']['profit'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e7241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['train']['profit'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e03b4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['test']['profit'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a5da88",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['train']['profit'].cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345e7c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['test']['profit'].cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81161e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(temp['train']['profit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af3cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(temp['test']['profit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfe8f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(252 ** 0.5) * np.mean(temp['train']['profit']) / np.std(temp['train']['profit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af953a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "(252 ** 0.5) * np.mean(temp['test']['profit']) / np.std(temp['test']['profit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05e48b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-mauritius",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-brave",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-heritage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-examination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-diameter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-framing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-cartoon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-diary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-least",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-population",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-ordinary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-think",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-framework",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-declaration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-somalia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-organizer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-alloy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-bracelet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-writing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-apollo",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-indicator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-london",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-removal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-young",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-arkansas",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-freeze",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-october",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-porter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-buying",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-medline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-despite",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-variety",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-economics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-location",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
