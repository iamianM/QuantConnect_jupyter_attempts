{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lesbian-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41f459b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, models, optimizers\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv2D, Flatten, Dense, LSTM, ConvLSTM2D, MaxPool2D, Dropout, Conv1D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offensive-merchant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dae60f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86f4cad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = np.load(\"inputs_train.npy\")\n",
    "inputs_test = np.load(\"inputs_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "external-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = np.transpose(inputs_train, (0, 2,3,1))\n",
    "inputs_test = np.transpose(inputs_test, (0, 2,3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "royal-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = inputs_train.reshape(inputs_train.shape[:2] + (inputs_train.shape[2]*inputs_train.shape[3],))\n",
    "inputs_test = inputs_test.reshape(inputs_test.shape[:2] + (inputs_test.shape[2]*inputs_test.shape[3],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6052538",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_timeframes.csv').iloc[59:]\n",
    "test = pd.read_csv('test_timeframes.csv').iloc[59:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "assured-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = [train, test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9326d1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = inputs_train[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22b9f610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((73695, 60, 20), (73695, 23))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train.shape, train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "amateur-collins",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24365, 60, 20), (24365, 23))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e56c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "batch_size = 32\n",
    "stop_limit = 0.004\n",
    "price_limit = 0.004\n",
    "margin_size = 50\n",
    "time_limit = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hungry-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "# model.add(LSTM(64, input_shape = img.shape, return_sequences=True, dropout=0.2))\n",
    "model.add(LSTM(32, input_shape = img.shape, dropout=0.2))\n",
    "# model.add(LSTM(32, dropout=0.2))\n",
    "model.add(Dense(3, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "protective-medium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.Sequential()\n",
    "\n",
    "# model.add(Conv2D(32, (5, 1),padding ='Same', activation='relu', input_shape = img.shape))\n",
    "# model.add(Conv2D(32, (5, 1),padding = 'Same', activation ='relu'))\n",
    "# model.add(MaxPool2D((2, 1)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(64,(3, 1),padding = 'Same', activation ='relu'))\n",
    "# model.add(Conv2D(64, (3, 1),padding = 'Same', activation ='relu'))\n",
    "# model.add(MaxPool2D(pool_size=(2, 1), strides=(2, 1)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256, activation = \"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(3, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "convertible-gossip",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 32)                6784      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 6,883\n",
      "Trainable params: 6,883\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da4a290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_wrapper(idx, stop_limit, price_limit, margin_size, time_limit):    \n",
    "    def custom_loss(y_true, y_pred):\n",
    "#         print()\n",
    "        margin = ((y_pred[:,:1] - 0.5) * 2)\n",
    "        margin *= margin_size\n",
    "        direction = tf.sign(margin)\n",
    "        stop_loss = y_pred[:,1:2] * direction * -1 * stop_limit\n",
    "        price_target = y_pred[:,2:3] * direction * 1 * price_limit\n",
    "        \n",
    "        idx = y_true[0][1].numpy()\n",
    "        df_name = y_true[0][0].numpy()\n",
    "        batch_size = y_pred.shape[0]\n",
    "        closes = []\n",
    "        spread = []\n",
    "        i = tf.constant(0)\n",
    "        while_condition = lambda i: tf.less(i, tf.constant(batch_size))\n",
    "        def body(i):\n",
    "            closes.append(df[df_name].iloc[int(idx+i.numpy()):int(idx+i.numpy()+time_limit)]['close_1min'].tolist())\n",
    "            spread.append(df[df_name].iloc[int(idx+i.numpy()):int(idx+i.numpy()+time_limit)]['spread'].tolist())\n",
    "            return [tf.add(i, 1)]\n",
    "        r = tf.while_loop(while_condition, body, [i], parallel_iterations=batch_size, swap_memory=True)\n",
    "        closes = tf.convert_to_tensor(closes)\n",
    "        spread = tf.convert_to_tensor(spread)\n",
    "        close1 = closes[:,:1]\n",
    "        close2 = tf.zeros_like(closes[:,:1])\n",
    "        lower_bound = tf.minimum(stop_loss, price_target)\n",
    "        upper_bound = tf.maximum(stop_loss, price_target)\n",
    "        i = tf.constant(0)\n",
    "        while_condition = lambda i: tf.logical_and(tf.less(i, tf.constant(closes.shape[1])), tf.math.count_nonzero(close2).numpy() == close2.shape[0])\n",
    "        def body(i):\n",
    "            diff = (closes[:,i:i+1] - closes[:,:1]) * direction\n",
    "            cond = tf.logical_or(tf.less(diff, lower_bound), tf.greater(diff, upper_bound))\n",
    "            close2 = tf.where(tf.logical_and(tf.equal(close2, 0), cond), closes[:,i:i+1], close2)\n",
    "            return [tf.add(i, 1)]\n",
    "        r = tf.while_loop(while_condition, body, [i], parallel_iterations=closes.shape[1], swap_memory=True)\n",
    "            \n",
    "        close2 = tf.where(tf.equal(close2, 0), closes[:,-1:], close2)\n",
    "\n",
    "        diff = close2 - close1\n",
    "        profit = 100 * (margin * (diff - (spread*direction))) /  close1\n",
    "        return -profit\n",
    "    return custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "supreme-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profit(data, y_preds, margin_lower_limit=1):\n",
    "    idx = 0\n",
    "    profits = []\n",
    "    while idx < len(y_preds) - 1:\n",
    "        margin = ((y_preds[idx][0] - 0.5) * 2)\n",
    "        margin *= margin_size\n",
    "        if abs(margin) < margin_lower_limit:\n",
    "            idx += 1\n",
    "        else:\n",
    "            direction = np.sign(margin)\n",
    "            stop_loss = y_preds[idx][1] * direction * -1 * stop_limit\n",
    "            price_target = y_preds[idx][2] * direction * 1 * price_limit\n",
    "\n",
    "            df_name = 1\n",
    "            start_idx = idx\n",
    "            close1 =  data.iloc[idx]['close_1min']\n",
    "            idx += 1\n",
    "            while idx < len(df[df_name]) - 1 and idx - start_idx < time_limit:\n",
    "                close2 = df[df_name].iloc[idx]['close_1min']\n",
    "                diff = (close2 - close1) \n",
    "                spread = df[df_name].iloc[idx]['spread']\n",
    "                if min(stop_loss, price_limit) < diff * direction < max(stop_loss, price_limit):\n",
    "                    break\n",
    "                idx += 1\n",
    "\n",
    "            profits.append(100 * (margin * (diff - (spread*direction))) /  close1)\n",
    "    return np.sum(profits)\n",
    "\n",
    "# data = df[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "stone-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "\n",
    "class IntervalEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=10):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "#             score = np.mean(custom_metric_wrapper(idx, stop_limit, price_limit, margin_size, time_limit)(tf.convert_to_tensor(self.y_val), tf.convert_to_tensor(y_pred)))\n",
    "            profits = get_profit(df[1], y_pred)\n",
    "            profits_0 = get_profit(df[1], y_pred, 0)\n",
    "            print(np.min(y_pred, axis=0))\n",
    "            print(np.mean(y_pred, axis=0))\n",
    "            print(np.max(y_pred, axis=0))\n",
    "            print(\"interval evaluation - epoch: {:d} - score: {:.6f} -- score_0: {:.6f}\".format(epoch, profits, profits_0))\n",
    "           \n",
    "buffer = (batch_size+time_limit) + 1000\n",
    "ival = IntervalEvaluation(validation_data=(inputs_test[:-buffer], np.array([[1, i] for i in range(len(test)-buffer)])), interval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "instant-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "    loss=custom_loss_wrapper(idx, stop_limit, price_limit, margin_size, time_limit),\n",
    "#     metrics=[custom_metric_wrapper(idx, stop_limit, price_limit, margin_size, time_limit)],\n",
    "    run_eagerly=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452981fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000\n",
      "2269/2269 [==============================] - 228s 101ms/step - loss: 0.0216\n",
      "[0.49878776 0.48543292 0.482004  ]\n",
      "[0.5415889  0.5277125  0.49509847]\n",
      "[0.61667484 0.564729   0.52360046]\n",
      "interval evaluation - epoch: 2 - score: -991.136206 -- score_0: -991.148436\n",
      "Epoch 4/1000\n",
      "2269/2269 [==============================] - 230s 101ms/step - loss: 0.0144\n",
      "[0.4960488  0.49163377 0.49119744]\n",
      "[0.5358718  0.52357805 0.5003031 ]\n",
      "[0.6208601  0.5635424  0.52636087]\n",
      "interval evaluation - epoch: 3 - score: -854.962860 -- score_0: -859.130835\n",
      "Epoch 5/1000\n",
      "2269/2269 [==============================] - 230s 101ms/step - loss: 0.0121\n",
      "[0.49220797 0.5020343  0.49608016]\n",
      "[0.53206545 0.5245392  0.50481796]\n",
      "[0.62297535 0.56691504 0.5345451 ]\n",
      "interval evaluation - epoch: 4 - score: -758.252598 -- score_0: -761.920140\n",
      "Epoch 6/1000\n",
      " 620/2269 [=======>......................] - ETA: 2:48 - loss: 0.0313"
     ]
    }
   ],
   "source": [
    "history = model.fit(inputs_train[:-buffer], np.array([[0, i] for i in range(len(train)-buffer)]), \n",
    "#                     validation_data=(inputs_test[:-buffer], np.array([[1, i] for i in range(len(test)-buffer)])),\n",
    "                    epochs=1000, shuffle=False,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[ival],\n",
    "                   use_multiprocessing=True, verbose=1, \n",
    "#                     validation_freq=10,\n",
    "                    workers=32,\n",
    "                   initial_epoch=2,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "classified-mineral",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict(inputs_test[:-buffer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "numeric-communications",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.5053732, 0.4675086, 0.4687059], dtype=float32),\n",
       " array([0.5558962 , 0.53147197, 0.48632494], dtype=float32),\n",
       " array([0.6228617 , 0.5674309 , 0.51639897], dtype=float32))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(y_preds, axis=0), np.mean(y_preds, axis=0), np.max(y_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "given-collar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.8314004119648235\n",
      "-3.9286273011275643\n",
      "-5.778957895504035\n"
     ]
    }
   ],
   "source": [
    "profits_0 = get_profit(df[1], y_preds, 49.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "technological-patrol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12.538985608596423"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(profits_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "brave-voluntary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4145389 , 0.49969864, 0.485943  ],\n",
       "       [0.38938323, 0.5155748 , 0.48543483],\n",
       "       [0.380811  , 0.525066  , 0.48127612],\n",
       "       [0.35313964, 0.5333326 , 0.47300786],\n",
       "       [0.33992964, 0.53893375, 0.46911928],\n",
       "       [0.33632183, 0.5414081 , 0.46604148],\n",
       "       [0.35559687, 0.5366863 , 0.46333343],\n",
       "       [0.33308685, 0.5325679 , 0.45460093],\n",
       "       [0.29795402, 0.5304277 , 0.4447381 ],\n",
       "       [0.322084  , 0.5295993 , 0.44771975]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(inputs_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-invitation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
