{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.8.1+cu101', '0.9.1+cu101')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "torch.__version__, torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, models\n",
    "\n",
    "class CNN(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t  \n",
    "\t\t\"\"\"Initialize the model by setting up the layers\"\"\"\n",
    "\t\tsuper(CNN, self).__init__()\n",
    "\t\t\n",
    "\t\t# initial layer is resnet\n",
    "\t\tself.resnet = models.resnet18(pretrained=True, progress=False)\n",
    "\t\t\n",
    "\t\t# final fully connected layers\n",
    "\t\tself.dense1 = nn.Linear(1000, 500)\n",
    "\t\tself.dense2 = nn.Linear(500, 100)\n",
    "\t\tself.dense3 = nn.Linear(100, 12)\n",
    "\t\t\n",
    "\t\t# output layer\n",
    "\t\tself.dense4 = nn.Linear(12, 1)\n",
    "\t\n",
    "\tdef forward(self, x):\n",
    "\t  \n",
    "\t\t\"\"\"Perform a forward pass of our model on some input and hidden state\"\"\"\n",
    "\t\t\n",
    "\t\tx = self.resnet(x)\n",
    "\t\t\n",
    "\t\t # apply three fully-connected Linear layers with ReLU activation function\n",
    "\t\tx = self.dense1(x)\n",
    "\t\tx = relu(x)\n",
    "\t\t\n",
    "\t\tx = self.dense2(x)\n",
    "\t\tx = relu(x)\n",
    "\t\t\n",
    "\t\tx = self.dense3(x)\n",
    "\t\tx = relu(x)\n",
    "\t\t\n",
    "\t\t# output is a size 1 Tensor\n",
    "\t\tx = self.dense4(x)\n",
    "\t\t\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import relu\n",
    "import torchvision.models as models\n",
    "\n",
    "class GRUnet(nn.Module):\n",
    "\tdef __init__(self, num_features, num_rows, batch_size, hidden_size, num_layers):\n",
    "\t\t\"\"\"Initialize the model by setting up the layers\"\"\"\n",
    "\t\tsuper(GRUnet, self).__init__()\n",
    "\t\t\n",
    "\t\t# initialize information about model\n",
    "\t\tself.num_features = num_features\n",
    "\t\tself.num_rows = num_rows\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself.hidden_size = hidden_size\n",
    "\t\tself.num_layers = num_layers\n",
    "\t\t\n",
    "\t\t# RNN-GRU Layer\n",
    "\t\tself.rnn = nn.GRU(batch_first=True, input_size=self.num_features,\n",
    "\t\t\t\t\t\t  hidden_size=self.hidden_size, num_layers = self.n_layers)\n",
    "\t\t\n",
    "\t\t# init GRU hidden layer\n",
    "\t\tself.hidden = self.init_hidden(batch_size=self.batch_size, hidden_size=hidden_size)\n",
    "\t\t\n",
    "\t\t# dropout layer\n",
    "\t\t#self.dropout = nn.Dropout(0.3)\n",
    "\t\t\n",
    "\t\t# 3 fully-connected hidden layers - with an output of dim 1\n",
    "\t\tself.link_layer = nn.Linear(self.hidden_size, 1000)\n",
    "\t\tself.dense1 = nn.Linear(1000, 500)\n",
    "\t\tself.dense2 = nn.Linear(500, 100)\n",
    "\t\tself.dense3 = nn.Linear(100, 12)\n",
    "\t\t\n",
    "\t\t# output layer\n",
    "\t\tself.dense4 = nn.Linear(12, 1)\n",
    "\t\t\n",
    "\tdef forward(self, x):\n",
    "\t\t\"\"\"Perform a forward pass of our model on some input and hidden state\"\"\"\n",
    "\t\t# GRU layer\n",
    "\t\tx, self.hidden = self.rnn(x, self.hidden)\n",
    "\t\t\n",
    "\t\t# detatch the hidden layer to prevent further backpropagating. i.e. fix the vanishing gradient problem\n",
    "\t\tself.hidden = self.hidden.detach().cuda()\n",
    "\t\t\t\t\n",
    "\t\t# apply a Dropout layer \n",
    "\t\t#x = self.dropout(x)\n",
    "\t\t\n",
    "\t\t# pass through the link_layer\n",
    "\t\tx = self.link_layer(x)\n",
    "\t\tx = relu(x)\n",
    "\t\t\n",
    "\t\t# apply three fully-connected Linear layers with ReLU activation function\n",
    "\t\tx = self.dense1(x)\n",
    "\t\tx = relu(x)\n",
    "\t\t\n",
    "\t\tx = self.dense2(x)\n",
    "\t\tx = relu(x)\n",
    "\t\t\n",
    "\t\tx = self.dense3(x)\n",
    "\t\tx = relu(x)\n",
    "\t\t\n",
    "\t\t# output is a size 1 Tensor\n",
    "\t\tx = self.dense4(x)\n",
    "\t\treturn x\n",
    "\t\n",
    "\tdef init_hidden(self, batch_size, hidden_size):\n",
    "\t\t\"\"\"Initializes hidden state\"\"\"\n",
    "\t\t\n",
    "\t\t# Creates initial hidden state for GRU of zeroes\n",
    "\t\thidden = torch.ones(self.num_layers, self.num_rows, hidden_size).cuda()\n",
    "\t\treturn hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TabError",
     "evalue": "inconsistent use of tabs and spaces in indentation (<ipython-input-3-acf3905de687>, line 88)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-acf3905de687>\"\u001b[1;36m, line \u001b[1;32m88\u001b[0m\n\u001b[1;33m    cnn_params = cnn.named_parameters()\u001b[0m\n\u001b[1;37m                                       ^\u001b[0m\n\u001b[1;31mTabError\u001b[0m\u001b[1;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import relu\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "class GRUCNN(nn.Module):\n",
    "\tdef __init__(self, num_features, num_rows, batch_size, hidden_size, num_layers):\n",
    "\t\t\"\"\"Initialize the model by setting up the layers\"\"\"\n",
    "\t\tsuper(GRUCNN, self).__init__()\n",
    "\t\t\n",
    "\t\t# initialize gru and cnn - the full models\n",
    "\t\t\n",
    "\t\t# gru model params\n",
    "\t\tself.num_features = num_features\n",
    "\t\tself.num_rows = num_rows\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself.hidden_size = hidden_size\n",
    "\t\tself.n_layers = num_layers\n",
    "\t\t\n",
    "\t\t# resnet model\n",
    "\t\tself.cnn = models.resnet18(pretrained=True, progress=False)\n",
    "\t\t\t  \n",
    "\t\t# RNN-GRU model\n",
    "\t\tself.rnn = nn.GRU(batch_first=True, input_size=self.num_features,\n",
    "\t\t\t\t\t\t  hidden_size=self.hidden_size, num_layers=self.num_layers)\n",
    "\t\t\n",
    "\t\t# init GRU hidden layer\n",
    "\t\tself.hidden = self.init_hidden(batch_size=self.batch_size, hidden_size=hidden_size)\n",
    "\t\tself.gru_output = nn.Linear(self.hidden_size, 1000)\n",
    "\t\t\n",
    "\t\t# final fully connected layers\n",
    "\t\tself.dense1 = nn.Linear(1000, 500)\n",
    "\t\tself.dense2 = nn.Linear(500, 100)\n",
    "\t\tself.dense3 = nn.Linear(100, 12)\n",
    "\t\t\n",
    "\t\t# output layer\n",
    "\t\tself.dense4 = nn.Linear(12, 1)\n",
    "\t\n",
    "\n",
    "\tdef forward(self, m_input):\n",
    "\t\t\"\"\"Perform a forward pass of our model on some input and hidden state\"\"\"\n",
    "\n",
    "\t\t# input is in a tuple (gru_input, cnn_input)\n",
    "\t\tgru_input, cnn_input = m_input\n",
    "\n",
    "\t\t# gru\n",
    "\t\tgru_out, self.hidden = self.rnn(gru_input, self.hidden)\n",
    "\t\t\n",
    "\t\t# detatch the hidden layer to prevent further backpropagating. i.e. fix the vanishing gradient problem\n",
    "\t\tself.hidden = self.hidden.detach().cuda()\n",
    "\t\t\n",
    "\t\t# pass through linear layer\n",
    "\t\tgru_out = torch.squeeze(self.gru_output(gru_out))\n",
    "\t\t\t\t\n",
    "\t\t# cnn\n",
    "\t\tcnn_out = self.cnn(cnn_input)\n",
    "\t\t\n",
    "\t\t# add the outputs of grunet and cnn\n",
    "\t\tx = gru_out.add(cnn_out)\n",
    "\t\t\n",
    "\t\t# feed through final layers\n",
    "\n",
    "\t\t# apply three fully-connected Linear layers with ReLU activation function\n",
    "\t\tx = self.dense1(x)\n",
    "\t\tx = relu(x)\n",
    "\t\t\n",
    "\t\tx = self.dense2(x)\n",
    "\t\tx = relu(x)\n",
    "\t\t\n",
    "\t\tx = self.dense3(x)\n",
    "\t\tx = relu(x)\n",
    "\t\t\n",
    "\t\t# output is a size 1 Tensor\n",
    "\t\tx = self.dense4(x)\n",
    "\t\t\n",
    "\t\treturn x\n",
    "\t\n",
    "\tdef init_hidden(self, batch_size, hidden_size):\n",
    "\t\t\"\"\"Initializes hidden state\"\"\"\n",
    "\t\t\n",
    "\t\t# Creates initial hidden state for GRU of zeroes\n",
    "\t\thidden = torch.ones(self.num_layers, self.batch_size, hidden_size).cuda()\n",
    "            \n",
    "\t\treturn hidden\n",
    "\t\t\n",
    "\tdef load_cnn_weights(self, cnn):\n",
    "  \tcnn_params = cnn.named_parameters()\n",
    "  \tgru_cnn_params = dict(self.cnn.named_parameters())\n",
    "  \t\n",
    "  \tfor name, cnn_param in cnn_params:\n",
    "  \t\tif name in gru_cnn_params:\n",
    "  \t\t\tgru_cnn_params[name].data.copy_(cnn_param.data)\n",
    "\t\n",
    "\tdef load_gru_weights(self, gru):\n",
    "\t\tgru_params = gru.named_parameters()\n",
    "\t\tgru_cnn_params = dict(self.rnn.named_parameters())\n",
    "\t\t\n",
    "\t\tfor name, gru_param in gru_params:\n",
    "\t\t\tif name in gru_cnn_params:\n",
    "\t\t\t\tgru_cnn_params[name].data.copy_(gru_param.data)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e2ef701097be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mChartImageDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m         \u001b[1;34m\"\"\"Dataset with input of OCHLV+tech_inds DataFrames, output of ChartImage numpy arrays\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class ChartImageDataset(Dataset):\n",
    "\t\"\"\"Dataset with input of OCHLV+tech_inds DataFrames, output of ChartImage numpy arrays\"\"\"\n",
    "\n",
    "\tdef __init__(self, inputs, labels):\n",
    "\t\tself.inputs, self.labels = [], labels\n",
    "\n",
    "\t\tfor item in inputs:\n",
    "\t\t\tself.inputs.append( ChartImageDataset.format(item) )\n",
    "\n",
    "\t\tself.c = 1 # one label\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.inputs)\n",
    "\t\t\n",
    "\tdef __getitem__(self, i):\n",
    "\t\treturn self.inputs[i], self.labels[i]\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef df_to_chart_arr(df):\n",
    "\t\treturn chart_to_arr(df)\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef format(df):\n",
    "\t\t\"\"\"Combine all processing steps from dataframe input to output for training\"\"\"\n",
    "\t\tx = ChartImageDataset.df_to_chart_arr(df)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DFDataset(Dataset):\n",
    "\t\"\"\"Dataset with inputs of DataFrame of OCHLV+tech_inds, outputs of normalized np arrays\"\"\"\n",
    "\n",
    "\tdef __init__(self, inputs, labels):\n",
    "\t\tself.inputs, self.labels = [], labels\n",
    "\n",
    "\t\tfor item in inputs:\n",
    "\t\t\tself.inputs.append( DFDataset.format(item) )\n",
    "\n",
    "\t\tself.c = 1 # one label\n",
    "\t\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.inputs)\n",
    "\t\n",
    "\tdef __getitem__(self, i):\n",
    "\t\treturn self.inputs[i], self.labels[i]\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef df_to_arr(df):\n",
    "\t\treturn np.array(df)\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef normalize_df(df, norm_func):\n",
    "\t\t\"\"\"Normalize df with norm_func\"\"\"\n",
    "\t\t# apply norm_func on columns\n",
    "\t\tdf = df.apply(norm_func, axis=0)\n",
    "\t\treturn df\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef drop_time_col(df):\n",
    "\t\t# drop time column\n",
    "\t\treturn df.drop('time', axis=1)\n",
    "\t\n",
    "\t@staticmethod\n",
    "\tdef format(df):\n",
    "\t\t\"\"\"Combine all processing steps from dataframe input to output for training\"\"\"\n",
    "\n",
    "\t\t# normalize with minmax\n",
    "\t\tx = DFDataset.normalize_df(df, minmaxnorm)\n",
    "\t\tx = DFDataset.drop_time_col(x)\n",
    "\t\tx = DFDataset.df_to_arr(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, model_name, optim, num_epochs, train_gen, valid_gen, test_gen=None):\n",
    "    \"\"\"Train a PyTorch model with optim as optimizer strategy\"\"\"\n",
    "    \n",
    "    for epoch_i in range(num_epochs):\n",
    "        \n",
    "        def RMSE(x, y):\n",
    "            # have to squish x into a rank 1 tensor with batch_size length with\n",
    "            # the outputs we want\n",
    "            if model_name == 'resnet':\n",
    "                 # torch.Size([64, 1])\n",
    "                x = x.squeeze(1)\n",
    "            elif model_name == 'gru':\n",
    "                # torch.Size([64, 30, 1])\n",
    "                # take only the last prediction from the 30 time periods in our matrix\n",
    "                x = x[:, 29, :] \n",
    "                x = x.squeeze(1)\n",
    "                \n",
    "            mse = torch.nn.MSELoss()\n",
    "            return torch.sqrt(mse(x, y))\n",
    "        \n",
    "        \n",
    "        # forward and backward passes of all batches inside train_gen\n",
    "        train_loss = _train(train_gen, model, optim, RMSE)\n",
    "        valid_loss = _valid(valid_gen, model, optim, RMSE)\n",
    "        \n",
    "        # run on test set if provided\n",
    "        if test_gen: test_output = _test(test_gen, model, optim)\n",
    "        else: test_output = \"no test selected\"\n",
    "        print(\"train loss: {}, valid loss: {}, test output: {}\".format(\n",
    "          train_loss, valid_loss, test_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train(train_gen, model, optim, error_func):\n",
    "    losses = []\n",
    "    \n",
    "    for batch, labels in train_gen:\n",
    "        batch, labels = batch.cuda().float(), labels.cuda().float()\n",
    "        # set model to train mode\n",
    "        model.train()\n",
    "        \n",
    "        # clear gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        output = model(batch)\n",
    "        loss = error_func(output, labels)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "      \n",
    "        losses.append(loss)\n",
    "        \n",
    "    return round(float(sum(losses) / len(losses)), 4)\n",
    "\n",
    "def _valid(valid_gen, model, optim, error_func):\n",
    "    with torch.set_grad_enabled(False):\n",
    "        losses = []\n",
    "\n",
    "        for batch, labels in valid_gen:\n",
    "            batch, labels = batch.cuda().float(), labels.cuda().float()\n",
    "            \n",
    "            # set to eval mode\n",
    "            model.eval()\n",
    "            \n",
    "            # clear gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            output = model(batch)\n",
    "            loss = error_func(output, labels)\n",
    "\n",
    "            losses.append(loss)\n",
    "        \n",
    "    return round(float(sum(losses) / len(losses)), 4)\n",
    "    \n",
    "def _test(test_gen, model, optim, error_func):\n",
    "    with torch.set_grad_enabled(False):\n",
    "        losses = []\n",
    "\n",
    "        for batch, labels in valid_gen:\n",
    "            batch, labels = batch.cuda().float(), labels.cuda().float()\n",
    "            \n",
    "            # set to eval mode\n",
    "            model.eval()\n",
    "            \n",
    "            # clear gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            output = model(batch)\n",
    "            loss = error_func(output, labels)\n",
    "\n",
    "            losses.append(loss)\n",
    "        \n",
    "    return round(float(sum(losses) / len(losses)), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
